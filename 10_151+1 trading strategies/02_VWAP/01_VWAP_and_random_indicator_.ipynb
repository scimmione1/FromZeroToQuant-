{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f65e60",
   "metadata": {},
   "source": [
    "# Complete VWAP Trading Strategy Analysis\n",
    "## Comprehensive Backtesting and Optimization of VWAP + Candlestick Pattern Strategies\n",
    "\n",
    "This notebook implements a complete trading strategy analysis framework combining VWAP (Volume Weighted Average Price) with various candlestick patterns for systematic backtesting, optimization, and performance evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ff5072",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb36a767",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m display, HTML\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Optimization and statistics\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# from scipy import stats\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TimeSeriesSplit\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Configure warnings and display settings\u001b[39;00m\n\u001b[32m     33\u001b[39m warnings.filterwarnings(\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import concurrent.futures\n",
    "from pathlib import Path\n",
    "\n",
    "# Backtesting libraries\n",
    "from backtesting import Strategy, Backtest\n",
    "from backtesting.lib import crossover\n",
    "# from backtesting.test import random_ohlc_data\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Optimization and statistics\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# Configure warnings and display settings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… All libraries imported successfully\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ðŸ”¢ NumPy version: {np.__version__}\")\n",
    "print(f\"ðŸ“ˆ TA-Lib available: {hasattr(ta, 'CDLHAMMER')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a831ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ File not found: ../00_data/data_AAPL_MSFT_GOOGL_AMZN_TSLA_META_NVDA_2020-01-01_2025-10-26_raw.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../00_data/data_AAPL_MSFT_GOOGL_AMZN_TSLA_META_NVDA_2020-01-01_2025-10-26_raw.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[32m     33\u001b[39m data_path = \u001b[33m\"\u001b[39m\u001b[33m../00_data/data_AAPL_MSFT_GOOGL_AMZN_TSLA_META_NVDA_2020-01-01_2025-10-26_raw.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m df_raw = \u001b[43mload_market_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Display data info\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸ“‹ Data Overview:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mload_market_data\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mLoad market data from CSV with proper error handling\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Load the CSV with MultiIndex columns (Tickers, OHLCV)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Drop any rows that are completely NaN\u001b[39;00m\n\u001b[32m     11\u001b[39m     df = df.dropna(how=\u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../00_data/data_AAPL_MSFT_GOOGL_AMZN_TSLA_META_NVDA_2020-01-01_2025-10-26_raw.csv'"
     ]
    }
   ],
   "source": [
    "# Load and validate data\n",
    "def load_market_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load market data from CSV with proper error handling\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV with MultiIndex columns (Tickers, OHLCV)\n",
    "        df = pd.read_csv(file_path, header=[0,1], index_col=0)\n",
    "        \n",
    "        # Drop any rows that are completely NaN\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Convert all values to float\n",
    "        df = df.astype(float)\n",
    "        \n",
    "        # Convert index to datetime\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        \n",
    "        print(f\"âœ… Data loaded successfully: {df.shape}\")\n",
    "        print(f\"ðŸ“… Date range: {df.index.min()} to {df.index.max()}\")\n",
    "        print(f\"ðŸ¢ Tickers: {list(df.columns.levels[0])}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ File not found: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Load the data\n",
    "data_path = \"../00_data/data_AAPL_MSFT_GOOGL_AMZN_TSLA_META_NVDA_2020-01-01_2025-10-26_raw.csv\"\n",
    "df_raw = load_market_data(data_path)\n",
    "\n",
    "# Display data info\n",
    "print(\"\\nðŸ“‹ Data Overview:\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4646c44",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing and Ticker Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_ticker(df: pd.DataFrame, seed: Optional[int] = None) -> Tuple[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Select a random ticker and return cleaned data\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Get available tickers\n",
    "    tickers = list(df.columns.levels[0])\n",
    "    selected_ticker = random.choice(tickers)\n",
    "    \n",
    "    print(f\"ðŸŽ¯ Randomly selected ticker: {selected_ticker}\")\n",
    "    \n",
    "    # Extract data for selected ticker\n",
    "    ticker_data = df.xs(selected_ticker, level=0, axis=1)\n",
    "    \n",
    "    # Clean column names (lowercase)\n",
    "    ticker_data.columns = [col.lower() for col in ticker_data.columns]\n",
    "    \n",
    "    # Remove any remaining NaN values\n",
    "    ticker_data = ticker_data.dropna()\n",
    "    \n",
    "    print(f\"ðŸ“Š Clean data shape: {ticker_data.shape}\")\n",
    "    print(f\"ðŸ“… Date range: {ticker_data.index.min()} to {ticker_data.index.max()}\")\n",
    "    \n",
    "    return selected_ticker, ticker_data\n",
    "\n",
    "# Select ticker and prepare data\n",
    "RANDOM_SEED = 42  # For reproducibility\n",
    "ticker_name, df_clean = select_random_ticker(df_raw, seed=RANDOM_SEED)\n",
    "\n",
    "# Display cleaned data\n",
    "print(f\"\\nðŸ“ˆ Sample data for {ticker_name}:\")\n",
    "display(df_clean.head())\n",
    "print(f\"\\nðŸ“Š Data statistics:\")\n",
    "display(df_clean.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a2d0e",
   "metadata": {},
   "source": [
    "## 3. Indicator Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f68f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all indicator calculation functions\n",
    "def calculate_vwap(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Calculate VWAP (Volume Weighted Average Price)\"\"\"\n",
    "    try:\n",
    "        typical_price = (df['high'] + df['low'] + df['close']) / 3\n",
    "        vwap = (df['volume'] * typical_price).cumsum() / df['volume'].cumsum()\n",
    "        return vwap\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating VWAP: {e}\")\n",
    "        return pd.Series(index=df.index, dtype=float)\n",
    "\n",
    "def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
    "    \"\"\"Calculate ATR (Average True Range)\"\"\"\n",
    "    try:\n",
    "        high_low = df['high'] - df['low']\n",
    "        high_close = (df['high'] - df['close'].shift()).abs()\n",
    "        low_close = (df['low'] - df['close'].shift()).abs()\n",
    "        true_range = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "        atr = true_range.rolling(window=period).mean()\n",
    "        return atr\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating ATR: {e}\")\n",
    "        return pd.Series(index=df.index, dtype=float)\n",
    "\n",
    "def calculate_candlestick_pattern(df: pd.DataFrame, pattern_name: str) -> pd.Series:\n",
    "    \"\"\"Calculate a specific candlestick pattern\"\"\"\n",
    "    try:\n",
    "        pattern_func = getattr(ta, pattern_name)\n",
    "        result = pattern_func(df['open'], df['high'], df['low'], df['close'])\n",
    "        return pd.Series(result, index=df.index)\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error calculating {pattern_name}: {e}\")\n",
    "        return pd.Series(index=df.index, dtype=float)\n",
    "\n",
    "# Define all candlestick patterns\n",
    "CANDLESTICK_PATTERNS = [\n",
    "    # Bullish reversal patterns\n",
    "    'CDLHAMMER', 'CDLINVERTEDHAMMER', 'CDLMORNINGSTAR', 'CDLMORNINGDOJISTAR',\n",
    "    'CDLENGULFING', 'CDLPIERCING', 'CDLHARAMI', 'CDLHARAMICROSS', 'CDLTAKURI',\n",
    "    \n",
    "    # Bullish continuation patterns  \n",
    "    'CDL3WHITESOLDIERS', 'CDLRISEFALL3METHODS', 'CDLMATHOLD', \n",
    "    'CDLSEPARATINGLINES', 'CDLTASUKIGAP',\n",
    "    \n",
    "    # Bullish bottom patterns\n",
    "    'CDLABANDONEDBABY', 'CDLLADDERBOTTOM', 'CDLMATCHINGLOW', 'CDLUNIQUE3RIVER',\n",
    "    \n",
    "    # Bullish special patterns\n",
    "    'CDL3INSIDE', 'CDL3OUTSIDE', 'CDLBELTHOLD', 'CDLBREAKAWAY',\n",
    "    'CDLKICKING', 'CDLKICKINGBYLENGTH', 'CDLSTICKSANDWICH'\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“Š Available candlestick patterns: {len(CANDLESTICK_PATTERNS)}\")\n",
    "for i, pattern in enumerate(CANDLESTICK_PATTERNS, 1):\n",
    "    print(f\"{i:2d}. {pattern}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dedb2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test indicator calculations\n",
    "print(\"ðŸ§ª Testing indicator calculations...\")\n",
    "\n",
    "# Calculate VWAP\n",
    "df_clean['vwap'] = calculate_vwap(df_clean)\n",
    "print(f\"âœ… VWAP calculated - Valid values: {df_clean['vwap'].notna().sum()}/{len(df_clean)}\")\n",
    "\n",
    "# Calculate ATR\n",
    "df_clean['atr'] = calculate_atr(df_clean, period=14)\n",
    "print(f\"âœ… ATR calculated - Valid values: {df_clean['atr'].notna().sum()}/{len(df_clean)}\")\n",
    "\n",
    "# Test a few candlestick patterns\n",
    "test_patterns = ['CDLHAMMER', 'CDLENGULFING', 'CDLMORNINGSTAR']\n",
    "for pattern in test_patterns:\n",
    "    df_clean[pattern.lower()] = calculate_candlestick_pattern(df_clean, pattern)\n",
    "    valid_signals = (df_clean[pattern.lower()] != 0).sum()\n",
    "    print(f\"âœ… {pattern} calculated - Signals found: {valid_signals}\")\n",
    "\n",
    "# Display sample with indicators\n",
    "print(f\"\\nðŸ“Š Sample data with indicators:\")\n",
    "display(df_clean[['open', 'high', 'low', 'close', 'volume', 'vwap', 'atr']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37548e9",
   "metadata": {},
   "source": [
    "## 4. Strategy Configuration and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f95025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_strategy_configs(patterns: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate strategy configurations for all VWAP + candlestick combinations\n",
    "    \"\"\"\n",
    "    strategies = []\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        strategy_config = {\n",
    "            'name': f'VWAP_{pattern}',\n",
    "            'primary_indicator': 'VWAP',\n",
    "            'secondary_indicator': pattern,\n",
    "            'description': f'VWAP combined with {pattern} candlestick pattern',\n",
    "            'atr_period': 14,\n",
    "            'sl_multiplier': 1.5,\n",
    "            'tp_multiplier': 3.0,\n",
    "            'pattern_function': pattern\n",
    "        }\n",
    "        strategies.append(strategy_config)\n",
    "    \n",
    "    return strategies\n",
    "\n",
    "# Generate all strategy configurations\n",
    "strategy_configs = generate_strategy_configs(CANDLESTICK_PATTERNS)\n",
    "\n",
    "print(f\"ðŸŽ¯ Generated {len(strategy_configs)} strategy configurations:\")\n",
    "print(\"\\nðŸ“‹ Strategy List:\")\n",
    "for i, config in enumerate(strategy_configs[:10], 1):  # Show first 10\n",
    "    print(f\"{i:2d}. {config['name']} - {config['description']}\")\n",
    "\n",
    "if len(strategy_configs) > 10:\n",
    "    print(f\"    ... and {len(strategy_configs) - 10} more strategies\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Sample strategy configuration:\")\n",
    "display(pd.DataFrame([strategy_configs[0]]).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba070ca",
   "metadata": {},
   "source": [
    "## 5. Time Series Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e03be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_series_splits(df: pd.DataFrame, n_splits: int = 3) -> List[Tuple]:\n",
    "    \"\"\"\n",
    "    Create time series cross-validation splits\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    splits = []\n",
    "    \n",
    "    print(f\"ðŸ“Š Creating {n_splits} time series splits...\")\n",
    "    \n",
    "    for i, (train_idx, test_idx) in enumerate(tscv.split(df)):\n",
    "        train_start = df.index[train_idx[0]]\n",
    "        train_end = df.index[train_idx[-1]]\n",
    "        test_start = df.index[test_idx[0]]\n",
    "        test_end = df.index[test_idx[-1]]\n",
    "        \n",
    "        train_data = df.iloc[train_idx]\n",
    "        test_data = df.iloc[test_idx]\n",
    "        \n",
    "        split_info = {\n",
    "            'split_number': i + 1,\n",
    "            'train_data': train_data,\n",
    "            'test_data': test_data,\n",
    "            'train_period': (train_start, train_end),\n",
    "            'test_period': (test_start, test_end),\n",
    "            'train_size': len(train_data),\n",
    "            'test_size': len(test_data)\n",
    "        }\n",
    "        \n",
    "        splits.append(split_info)\n",
    "        \n",
    "        print(f\"Split {i+1}:\")\n",
    "        print(f\"  ðŸ“ˆ Train: {train_start.strftime('%Y-%m-%d')} to {train_end.strftime('%Y-%m-%d')} ({len(train_data)} days)\")\n",
    "        print(f\"  ðŸ§ª Test:  {test_start.strftime('%Y-%m-%d')} to {test_end.strftime('%Y-%m-%d')} ({len(test_data)} days)\")\n",
    "    \n",
    "    return splits\n",
    "\n",
    "# Create time series splits\n",
    "ts_splits = create_time_series_splits(df_clean, n_splits=3)\n",
    "\n",
    "# Use the last split for main analysis (largest training set)\n",
    "main_split = ts_splits[-1]\n",
    "train_data = main_split['train_data']\n",
    "test_data = main_split['test_data']\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Using split {main_split['split_number']} for main analysis:\")\n",
    "print(f\"ðŸ“Š Training data: {len(train_data)} days\")\n",
    "print(f\"ðŸ§ª Testing data: {len(test_data)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893f24a",
   "metadata": {},
   "source": [
    "## 6. Dynamic Strategy Class Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f95e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vwap_strategy_class(pattern_name: str, atr_period: int = 14, \n",
    "                              sl_multiplier: float = 1.5, tp_multiplier: float = 3.0):\n",
    "    \"\"\"\n",
    "    Dynamically create a VWAP + Candlestick strategy class\n",
    "    \"\"\"\n",
    "    \n",
    "    class VWAPCandlestickStrategy(Strategy):\n",
    "        # Strategy parameters\n",
    "        atr_period = atr_period\n",
    "        sl_multiplier = sl_multiplier\n",
    "        tp_multiplier = tp_multiplier\n",
    "        pattern_name = pattern_name\n",
    "        \n",
    "        def init(self):\n",
    "            # Calculate VWAP\n",
    "            typical_price = (self.data.High + self.data.Low + self.data.Close) / 3\n",
    "            volume_price = typical_price * self.data.Volume\n",
    "            self.vwap = self.I(lambda: volume_price.cumsum() / self.data.Volume.cumsum(), name='VWAP')\n",
    "            \n",
    "            # Calculate ATR\n",
    "            self.atr = self.I(ta.ATR, self.data.High, self.data.Low, self.data.Close, \n",
    "                             self.atr_period, name='ATR')\n",
    "            \n",
    "            # Calculate candlestick pattern\n",
    "            pattern_func = getattr(ta, self.pattern_name)\n",
    "            self.pattern = self.I(pattern_func, self.data.Open, self.data.High, \n",
    "                                 self.data.Low, self.data.Close, name=self.pattern_name)\n",
    "            \n",
    "            # Track entry levels\n",
    "            self.entry_price = None\n",
    "            self.stop_loss_level = None\n",
    "            self.take_profit_level = None\n",
    "        \n",
    "        def next(self):\n",
    "            # Entry conditions: Price above VWAP AND bullish candlestick pattern\n",
    "            if (not self.position and \n",
    "                self.data.Close[-1] > self.vwap[-1] and  # Price above VWAP\n",
    "                self.pattern[-1] > 0):  # Bullish pattern detected\n",
    "                \n",
    "                # Enter long position\n",
    "                self.buy()\n",
    "                \n",
    "                # Set stop loss and take profit levels\n",
    "                self.entry_price = self.data.Close[-1]\n",
    "                self.stop_loss_level = self.entry_price - (self.atr[-1] * self.sl_multiplier)\n",
    "                self.take_profit_level = self.entry_price + (self.atr[-1] * self.tp_multiplier)\n",
    "            \n",
    "            # Exit conditions\n",
    "            if self.position:\n",
    "                # Stop Loss\n",
    "                if self.data.Low[-1] <= self.stop_loss_level:\n",
    "                    self.position.close()\n",
    "                    self.entry_price = None\n",
    "                # Take Profit  \n",
    "                elif self.data.High[-1] >= self.take_profit_level:\n",
    "                    self.position.close()\n",
    "                    self.entry_price = None\n",
    "    \n",
    "    # Set class name dynamically\n",
    "    VWAPCandlestickStrategy.__name__ = f\"VWAP{pattern_name}Strategy\"\n",
    "    return VWAPCandlestickStrategy\n",
    "\n",
    "# Test strategy class creation\n",
    "print(\"ðŸ§ª Testing strategy class creation...\")\n",
    "TestStrategy = create_vwap_strategy_class('CDLHAMMER')\n",
    "print(f\"âœ… Created strategy class: {TestStrategy.__name__}\")\n",
    "print(f\"ðŸ“Š Strategy pattern: {TestStrategy.pattern_name}\")\n",
    "print(f\"âš™ï¸ Parameters: ATR={TestStrategy.atr_period}, SL={TestStrategy.sl_multiplier}, TP={TestStrategy.tp_multiplier}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a9428",
   "metadata": {},
   "source": [
    "## 7. Batch Backtesting Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b392535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_backtest(strategy_config: Dict, data: pd.DataFrame, \n",
    "                       cash: float = 10000, commission: float = 0.002) -> Dict:\n",
    "    \"\"\"\n",
    "    Run a single backtest for a strategy configuration\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Prepare data (backtesting library expects uppercase columns)\n",
    "        df_backtest = data.copy()\n",
    "        df_backtest.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        # Create strategy class\n",
    "        StrategyClass = create_vwap_strategy_class(\n",
    "            pattern_name=strategy_config['pattern_function'],\n",
    "            atr_period=strategy_config['atr_period'],\n",
    "            sl_multiplier=strategy_config['sl_multiplier'],\n",
    "            tp_multiplier=strategy_config['tp_multiplier']\n",
    "        )\n",
    "        \n",
    "        # Run backtest\n",
    "        bt = Backtest(df_backtest, StrategyClass, cash=cash, commission=commission)\n",
    "        results = bt.run()\n",
    "        \n",
    "        # Add strategy info to results\n",
    "        result_dict = results.to_dict()\n",
    "        result_dict['strategy_name'] = strategy_config['name']\n",
    "        result_dict['pattern'] = strategy_config['pattern_function']\n",
    "        result_dict['backtest_object'] = bt\n",
    "        result_dict['success'] = True\n",
    "        result_dict['error'] = None\n",
    "        \n",
    "        return result_dict\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'strategy_name': strategy_config['name'],\n",
    "            'pattern': strategy_config['pattern_function'],\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'Return [%]': 0,\n",
    "            '# Trades': 0\n",
    "        }\n",
    "\n",
    "def run_batch_backtests(strategy_configs: List[Dict], data: pd.DataFrame, \n",
    "                       max_strategies: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run backtests for multiple strategies\n",
    "    \"\"\"\n",
    "    if max_strategies:\n",
    "        configs_to_run = strategy_configs[:max_strategies]\n",
    "        print(f\"ðŸŽ¯ Running backtests for first {max_strategies} strategies...\")\n",
    "    else:\n",
    "        configs_to_run = strategy_configs\n",
    "        print(f\"ðŸŽ¯ Running backtests for all {len(configs_to_run)} strategies...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Run backtests sequentially with progress tracking\n",
    "    for i, config in enumerate(configs_to_run, 1):\n",
    "        print(f\"â³ ({i}/{len(configs_to_run)}) Testing {config['name']}...\", end=\" \")\n",
    "        \n",
    "        result = run_single_backtest(config, data)\n",
    "        results.append(result)\n",
    "        \n",
    "        if result['success']:\n",
    "            trades = result.get('# Trades', 0)\n",
    "            returns = result.get('Return [%]', 0)\n",
    "            print(f\"âœ… {trades} trades, {returns:.2f}% return\")\n",
    "        else:\n",
    "            print(f\"âŒ Failed: {result['error']}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Filter successful backtests\n",
    "    successful_results = results_df[results_df['success'] == True].copy()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Backtest Summary:\")\n",
    "    print(f\"âœ… Successful: {len(successful_results)}/{len(results_df)}\")\n",
    "    print(f\"âŒ Failed: {len(results_df) - len(successful_results)}\")\n",
    "    \n",
    "    if len(successful_results) > 0:\n",
    "        print(f\"ðŸ“ˆ Best performing strategy: {successful_results.loc[successful_results['Return [%]'].idxmax(), 'strategy_name']}\")\n",
    "        print(f\"ðŸŽ¯ Best return: {successful_results['Return [%]'].max():.2f}%\")\n",
    "    \n",
    "    return successful_results\n",
    "\n",
    "# Run backtests on training data (limit to first 10 strategies for demo)\n",
    "print(\"ðŸš€ Starting batch backtesting on training data...\")\n",
    "train_results = run_batch_backtests(strategy_configs, train_data, max_strategies=10)\n",
    "\n",
    "# Display top performing strategies\n",
    "if len(train_results) > 0:\n",
    "    print(f\"\\nðŸ† Top 5 Performing Strategies (Training Data):\")\n",
    "    top_strategies = train_results.nlargest(5, 'Return [%]')[\n",
    "        ['strategy_name', 'Return [%]', '# Trades', 'Win Rate [%]', 'Sharpe Ratio', 'Max Drawdown [%]']\n",
    "    ]\n",
    "    display(top_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4416a6d5",
   "metadata": {},
   "source": [
    "## 8. Out-of-Sample Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_out_of_sample_testing(top_results: pd.DataFrame, test_data: pd.DataFrame, \n",
    "                             top_n: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Run out-of-sample testing on top performing strategies\n",
    "    \"\"\"\n",
    "    # Get top N strategies\n",
    "    top_strategies = top_results.nlargest(top_n, 'Return [%]')\n",
    "    \n",
    "    print(f\"ðŸ§ª Running out-of-sample testing on top {top_n} strategies...\")\n",
    "    \n",
    "    oos_results = []\n",
    "    \n",
    "    for idx, strategy_row in top_strategies.iterrows():\n",
    "        strategy_name = strategy_row['strategy_name']\n",
    "        pattern = strategy_row['pattern']\n",
    "        \n",
    "        print(f\"â³ Testing {strategy_name} on out-of-sample data...\", end=\" \")\n",
    "        \n",
    "        # Find original strategy config\n",
    "        original_config = next(\n",
    "            (config for config in strategy_configs if config['name'] == strategy_name), \n",
    "            None\n",
    "        )\n",
    "        \n",
    "        if original_config:\n",
    "            # Run backtest on test data\n",
    "            oos_result = run_single_backtest(original_config, test_data)\n",
    "            \n",
    "            if oos_result['success']:\n",
    "                # Add in-sample performance for comparison\n",
    "                oos_result['in_sample_return'] = strategy_row['Return [%]']\n",
    "                oos_result['out_of_sample_return'] = oos_result['Return [%]']\n",
    "                oos_result['performance_degradation'] = (\n",
    "                    strategy_row['Return [%]'] - oos_result['Return [%]']\n",
    "                )\n",
    "                \n",
    "                oos_results.append(oos_result)\n",
    "                print(f\"âœ… OOS Return: {oos_result['Return [%]']:.2f}% (IS: {strategy_row['Return [%]']:.2f}%)\")\n",
    "            else:\n",
    "                print(f\"âŒ Failed: {oos_result['error']}\")\n",
    "        else:\n",
    "            print(\"âŒ Strategy config not found\")\n",
    "    \n",
    "    return pd.DataFrame(oos_results)\n",
    "\n",
    "# Run out-of-sample testing\n",
    "if len(train_results) > 0:\n",
    "    oos_results = run_out_of_sample_testing(train_results, test_data, top_n=5)\n",
    "    \n",
    "    if len(oos_results) > 0:\n",
    "        print(f\"\\nðŸ“Š Out-of-Sample Results:\")\n",
    "        oos_comparison = oos_results[[\n",
    "            'strategy_name', 'in_sample_return', 'out_of_sample_return', \n",
    "            'performance_degradation', '# Trades', 'Win Rate [%]'\n",
    "        ]].copy()\n",
    "        \n",
    "        display(oos_comparison)\n",
    "        \n",
    "        # Identify robust strategies (minimal performance degradation)\n",
    "        robust_strategies = oos_comparison[oos_comparison['performance_degradation'] < 10]\n",
    "        print(f\"\\nðŸŽ¯ Robust strategies (< 10% performance degradation): {len(robust_strategies)}\")\n",
    "        if len(robust_strategies) > 0:\n",
    "            display(robust_strategies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe88e8f",
   "metadata": {},
   "source": [
    "## 9. Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf661e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_strategy_parameters(strategy_config: Dict, data: pd.DataFrame, \n",
    "                               optimize_params: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Optimize strategy parameters using grid search\n",
    "    \"\"\"\n",
    "    print(f\"âš™ï¸ optimizing parameters for {strategy_config['name']}...\")\n",
    "    \n",
    "    try:\n",
    "        # Prepare data\n",
    "        df_backtest = data.copy()\n",
    "        df_backtest.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        # Create base strategy class\n",
    "        BaseStrategyClass = create_vwap_strategy_class(\n",
    "            pattern_name=strategy_config['pattern_function']\n",
    "        )\n",
    "        \n",
    "        # Create optimizable strategy class\n",
    "        class OptimizableStrategy(BaseStrategyClass):\n",
    "            # Make parameters optimizable\n",
    "            atr_period = optimize_params.get('atr_period', [14])\n",
    "            sl_multiplier = optimize_params.get('sl_multiplier', [1.5])\n",
    "            tp_multiplier = optimize_params.get('tp_multiplier', [3.0])\n",
    "        \n",
    "        # Run optimization\n",
    "        bt = Backtest(df_backtest, OptimizableStrategy, cash=10000, commission=0.002)\n",
    "        \n",
    "        optimization_result = bt.optimize(\n",
    "            atr_period=optimize_params.get('atr_period', [14]),\n",
    "            sl_multiplier=optimize_params.get('sl_multiplier', [1.5]), \n",
    "            tp_multiplier=optimize_params.get('tp_multiplier', [3.0]),\n",
    "            maximize='Sharpe Ratio',\n",
    "            max_tries=50\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'strategy_name': strategy_config['name'],\n",
    "            'optimization_success': True,\n",
    "            'optimized_params': {\n",
    "                'atr_period': optimization_result._strategy.atr_period,\n",
    "                'sl_multiplier': optimization_result._strategy.sl_multiplier,\n",
    "                'tp_multiplier': optimization_result._strategy.tp_multiplier\n",
    "            },\n",
    "            'optimized_results': optimization_result.to_dict(),\n",
    "            'backtest_object': bt\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Optimization failed: {str(e)}\")\n",
    "        return {\n",
    "            'strategy_name': strategy_config['name'],\n",
    "            'optimization_success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Define parameter ranges for optimization\n",
    "optimization_params = {\n",
    "    'atr_period': [10, 14, 20],\n",
    "    'sl_multiplier': [1.0, 1.5, 2.0],\n",
    "    'tp_multiplier': [2.0, 3.0, 4.0]\n",
    "}\n",
    "\n",
    "# Optimize top 3 strategies\n",
    "if len(train_results) >= 3:\n",
    "    top_3_strategies = train_results.nlargest(3, 'Return [%]')\n",
    "    \n",
    "    print(f\"âš™ï¸ Optimizing parameters for top 3 strategies...\")\n",
    "    optimized_results = []\n",
    "    \n",
    "    for idx, strategy_row in top_3_strategies.iterrows():\n",
    "        strategy_name = strategy_row['strategy_name']\n",
    "        \n",
    "        # Find original config\n",
    "        original_config = next(\n",
    "            (config for config in strategy_configs if config['name'] == strategy_name),\n",
    "            None\n",
    "        )\n",
    "        \n",
    "        if original_config:\n",
    "            opt_result = optimize_strategy_parameters(\n",
    "                original_config, train_data, optimization_params\n",
    "            )\n",
    "            optimized_results.append(opt_result)\n",
    "    \n",
    "    # Display optimization results\n",
    "    successful_optimizations = [r for r in optimized_results if r.get('optimization_success', False)]\n",
    "    \n",
    "    if successful_optimizations:\n",
    "        print(f\"\\nðŸŽ¯ Optimization Results:\")\n",
    "        for result in successful_optimizations:\n",
    "            print(f\"\\nðŸ“Š {result['strategy_name']}:\")\n",
    "            print(f\"   Parameters: {result['optimized_params']}\")\n",
    "            opt_return = result['optimized_results'].get('Return [%]', 0)\n",
    "            opt_sharpe = result['optimized_results'].get('Sharpe Ratio', 0)\n",
    "            print(f\"   Performance: {opt_return:.2f}% return, {opt_sharpe:.2f} Sharpe\")\n",
    "else:\n",
    "    print(\"âš ï¸ Not enough successful strategies for optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a00aba8",
   "metadata": {},
   "source": [
    "## 10. Performance Visualization and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d413d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_plots(results_df: pd.DataFrame, data: pd.DataFrame, \n",
    "                              ticker_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Create comprehensive performance visualization plots\n",
    "    \"\"\"\n",
    "    if len(results_df) == 0:\n",
    "        print(\"âš ï¸ No results to plot\")\n",
    "        return\n",
    "    \n",
    "    # Set up the plotting environment\n",
    "    plt.rcParams['figure.figsize'] = (15, 10)\n",
    "    plt.rcParams['font.size'] = 10\n",
    "    \n",
    "    # Create main figure with subplots\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    gs = fig.add_gridspec(4, 3, height_ratios=[2, 1, 1, 1], hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # 1. Strategy Performance Comparison\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    \n",
    "    # Get top 10 strategies for plotting\n",
    "    top_strategies = results_df.nlargest(10, 'Return [%]')\n",
    "    \n",
    "    # Create bar plot of returns\n",
    "    bars = ax1.bar(range(len(top_strategies)), top_strategies['Return [%]'], \n",
    "                   color='steelblue', alpha=0.7)\n",
    "    \n",
    "    # Color bars based on performance\n",
    "    for i, bar in enumerate(bars):\n",
    "        returns = top_strategies.iloc[i]['Return [%]']\n",
    "        if returns > 10:\n",
    "            bar.set_color('darkgreen')\n",
    "        elif returns > 0:\n",
    "            bar.set_color('lightgreen')\n",
    "        else:\n",
    "            bar.set_color('lightcoral')\n",
    "    \n",
    "    ax1.set_title(f'Top 10 Strategy Performance - {ticker_name}', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel('Return (%)', fontsize=12)\n",
    "    ax1.set_xlabel('Strategy', fontsize=12)\n",
    "    ax1.set_xticks(range(len(top_strategies)))\n",
    "    ax1.set_xticklabels([name.replace('VWAP_', '') for name in top_strategies['strategy_name']], \n",
    "                       rotation=45, ha='right')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    # 2. Risk-Return Scatter Plot\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    \n",
    "    # Filter out invalid values for scatter plot\n",
    "    valid_data = results_df[\n",
    "        (results_df['Return [%]'].notna()) & \n",
    "        (results_df['Max Drawdown [%]'].notna()) &\n",
    "        (results_df['Max Drawdown [%]'] != 0)\n",
    "    ].copy()\n",
    "    \n",
    "    if len(valid_data) > 0:\n",
    "        scatter = ax2.scatter(valid_data['Max Drawdown [%]'].abs(), \n",
    "                            valid_data['Return [%]'],\n",
    "                            c=valid_data['# Trades'], \n",
    "                            cmap='viridis', alpha=0.6, s=60)\n",
    "        \n",
    "        ax2.set_xlabel('Max Drawdown (%)', fontsize=10)\n",
    "        ax2.set_ylabel('Return (%)', fontsize=10)\n",
    "        ax2.set_title('Risk vs Return', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(scatter, ax=ax2)\n",
    "        cbar.set_label('Number of Trades', fontsize=9)\n",
    "    \n",
    "    # 3. Win Rate Distribution\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    \n",
    "    win_rates = results_df['Win Rate [%]'].dropna()\n",
    "    if len(win_rates) > 0:\n",
    "        ax3.hist(win_rates, bins=15, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "        ax3.axvline(win_rates.mean(), color='red', linestyle='--', \n",
    "                   label=f'Mean: {win_rates.mean():.1f}%')\n",
    "        ax3.set_xlabel('Win Rate (%)', fontsize=10)\n",
    "        ax3.set_ylabel('Frequency', fontsize=10)\n",
    "        ax3.set_title('Win Rate Distribution', fontsize=12, fontweight='bold')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Sharpe Ratio vs Return\n",
    "    ax4 = fig.add_subplot(gs[1, 2])\n",
    "    \n",
    "    sharpe_data = results_df[\n",
    "        (results_df['Sharpe Ratio'].notna()) & \n",
    "        (results_df['Return [%]'].notna())\n",
    "    ].copy()\n",
    "    \n",
    "    if len(sharpe_data) > 0:\n",
    "        ax4.scatter(sharpe_data['Sharpe Ratio'], sharpe_data['Return [%]'], \n",
    "                   alpha=0.6, color='orange', s=60)\n",
    "        ax4.set_xlabel('Sharpe Ratio', fontsize=10)\n",
    "        ax4.set_ylabel('Return (%)', fontsize=10)\n",
    "        ax4.set_title('Sharpe Ratio vs Return', fontsize=12, fontweight='bold')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add trend line\n",
    "        if len(sharpe_data) > 1:\n",
    "            z = np.polyfit(sharpe_data['Sharpe Ratio'], sharpe_data['Return [%]'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax4.plot(sharpe_data['Sharpe Ratio'].sort_values(), \n",
    "                    p(sharpe_data['Sharpe Ratio'].sort_values()), \n",
    "                    \"r--\", alpha=0.8, linewidth=1)\n",
    "    \n",
    "    # 5. Trade Count Analysis\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    trade_counts = results_df['# Trades'].dropna()\n",
    "    if len(trade_counts) > 0:\n",
    "        ax5.bar(range(len(trade_counts)), sorted(trade_counts, reverse=True), \n",
    "               color='lightcoral', alpha=0.7)\n",
    "        ax5.set_xlabel('Strategy Rank', fontsize=10)\n",
    "        ax5.set_ylabel('Number of Trades', fontsize=10)\n",
    "        ax5.set_title('Trade Count by Strategy', fontsize=12, fontweight='bold')\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Performance Metrics Heatmap\n",
    "    ax6 = fig.add_subplot(gs[2, 1:])\n",
    "    \n",
    "    # Select key metrics for heatmap\n",
    "    heatmap_metrics = ['Return [%]', 'Sharpe Ratio', 'Win Rate [%]', '# Trades']\n",
    "    heatmap_data = results_df[heatmap_metrics].head(10)\n",
    "    \n",
    "    if len(heatmap_data) > 0:\n",
    "        # Normalize data for better visualization\n",
    "        heatmap_normalized = heatmap_data.copy()\n",
    "        for col in heatmap_metrics:\n",
    "            if col in heatmap_normalized.columns:\n",
    "                col_data = heatmap_normalized[col].fillna(0)\n",
    "                if col_data.std() != 0:\n",
    "                    heatmap_normalized[col] = (col_data - col_data.min()) / (col_data.max() - col_data.min())\n",
    "        \n",
    "        im = ax6.imshow(heatmap_normalized.T, cmap='RdYlGn', aspect='auto')\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        ax6.set_xticks(range(len(heatmap_data)))\n",
    "        ax6.set_xticklabels([name.replace('VWAP_', '')[:10] + '...' if len(name) > 13 else name.replace('VWAP_', '') \n",
    "                           for name in heatmap_data.index], rotation=45, ha='right')\n",
    "        ax6.set_yticks(range(len(heatmap_metrics)))\n",
    "        ax6.set_yticklabels(heatmap_metrics)\n",
    "        ax6.set_title('Performance Metrics Heatmap (Normalized)', fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax6)\n",
    "        cbar.set_label('Normalized Value', fontsize=9)\n",
    "    \n",
    "    # 7. Price Chart with VWAP\n",
    "    ax7 = fig.add_subplot(gs[3, :])\n",
    "    \n",
    "    # Plot price and VWAP for context\n",
    "    recent_data = data.tail(500)  # Last 500 days\n",
    "    ax7.plot(recent_data.index, recent_data['close'], label=f'{ticker_name} Price', \n",
    "            color='blue', linewidth=1, alpha=0.8)\n",
    "    \n",
    "    if 'vwap' in recent_data.columns:\n",
    "        ax7.plot(recent_data.index, recent_data['vwap'], label='VWAP', \n",
    "                color='red', linewidth=1.5, alpha=0.8)\n",
    "    \n",
    "    ax7.set_title(f'{ticker_name} Price vs VWAP (Last 500 Days)', fontsize=12, fontweight='bold')\n",
    "    ax7.set_ylabel('Price ($)', fontsize=10)\n",
    "    ax7.set_xlabel('Date', fontsize=10)\n",
    "    ax7.legend()\n",
    "    ax7.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format x-axis dates\n",
    "    ax7.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    ax7.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.setp(ax7.xaxis.get_majorticklabels(), rotation=45)\n",
    "    \n",
    "    plt.suptitle(f'VWAP Strategy Analysis - {ticker_name}', fontsize=18, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… Comprehensive plots created successfully!\")\n",
    "\n",
    "# Create plots for training results\n",
    "if len(train_results) > 0:\n",
    "    print(\"ðŸ“Š Creating comprehensive performance plots...\")\n",
    "    create_comprehensive_plots(train_results, df_clean, ticker_name)\n",
    "else:\n",
    "    print(\"âš ï¸ No successful backtest results to plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c7d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_strategy_performance(strategy_result: Dict, data: pd.DataFrame, \n",
    "                                       ticker_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot detailed performance for a single strategy\n",
    "    \"\"\"\n",
    "    if not strategy_result.get('success', False):\n",
    "        print(\"âš ï¸ Cannot plot failed strategy\")\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Get the backtest object to access detailed results\n",
    "    bt = strategy_result.get('backtest_object')\n",
    "    strategy_name = strategy_result.get('strategy_name', 'Unknown')\n",
    "    \n",
    "    # 1. Price chart with entry/exit points (if backtest object available)\n",
    "    recent_data = data.tail(500)\n",
    "    ax1.plot(recent_data.index, recent_data['close'], label=f'{ticker_name} Price', \n",
    "            color='blue', linewidth=1)\n",
    "    \n",
    "    if 'vwap' in recent_data.columns:\n",
    "        ax1.plot(recent_data.index, recent_data['vwap'], label='VWAP', \n",
    "                color='red', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    ax1.set_title(f'{strategy_name} - Price & VWAP', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Price ($)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Performance metrics bar chart\n",
    "    metrics = {\n",
    "        'Return (%)': strategy_result.get('Return [%]', 0),\n",
    "        'Sharpe Ratio': strategy_result.get('Sharpe Ratio', 0),\n",
    "        'Win Rate (%)': strategy_result.get('Win Rate [%]', 0),\n",
    "        'Max DD (%)': -abs(strategy_result.get('Max Drawdown [%]', 0))\n",
    "    }\n",
    "    \n",
    "    colors = ['green' if v > 0 else 'red' for v in metrics.values()]\n",
    "    bars = ax2.bar(metrics.keys(), metrics.values(), color=colors, alpha=0.7)\n",
    "    ax2.set_title('Key Performance Metrics', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, value in zip(bars, metrics.values()):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + (0.5 if height > 0 else -0.5),\n",
    "                f'{value:.1f}', ha='center', va='bottom' if height > 0 else 'top')\n",
    "    \n",
    "    # 3. Trade statistics\n",
    "    trade_stats = {\n",
    "        'Total Trades': strategy_result.get('# Trades', 0),\n",
    "        'Winning Trades': int(strategy_result.get('# Trades', 0) * strategy_result.get('Win Rate [%]', 0) / 100),\n",
    "        'Avg Trade (%)': strategy_result.get('Avg Trade [%]', 0),\n",
    "        'Best Trade (%)': strategy_result.get('Best Trade [%]', 0),\n",
    "        'Worst Trade (%)': strategy_result.get('Worst Trade [%]', 0)\n",
    "    }\n",
    "    \n",
    "    ax3.barh(list(trade_stats.keys()), list(trade_stats.values()), color='skyblue', alpha=0.7)\n",
    "    ax3.set_title('Trade Statistics', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Value')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Risk metrics\n",
    "    risk_metrics = {\n",
    "        'Volatility (%)': strategy_result.get('Volatility (ann.) [%]', 0),\n",
    "        'Max Drawdown (%)': abs(strategy_result.get('Max Drawdown [%]', 0)),\n",
    "        'Calmar Ratio': strategy_result.get('Calmar Ratio', 0) if strategy_result.get('Calmar Ratio') not in ['N/A', None] else 0,\n",
    "        'Sortino Ratio': strategy_result.get('Sortino Ratio', 0) if strategy_result.get('Sortino Ratio') not in ['N/A', None] else 0\n",
    "    }\n",
    "    \n",
    "    ax4.pie([max(0.1, abs(v)) for v in risk_metrics.values()], \n",
    "           labels=risk_metrics.keys(), autopct='%1.1f%%', startangle=90)\n",
    "    ax4.set_title('Risk Profile', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle(f'Detailed Analysis: {strategy_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot detailed analysis for best strategy\n",
    "if len(train_results) > 0:\n",
    "    best_strategy = train_results.loc[train_results['Return [%]'].idxmax()].to_dict()\n",
    "    print(f\"ðŸ“Š Creating detailed analysis for best strategy: {best_strategy['strategy_name']}\")\n",
    "    plot_individual_strategy_performance(best_strategy, df_clean, ticker_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106e8616",
   "metadata": {},
   "source": [
    "## 11. Monte Carlo Simulation and Robustness Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468f571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_monte_carlo_simulation(strategy_config: Dict, original_data: pd.DataFrame, \n",
    "                              n_simulations: int = 100, random_seed: int = 42) -> Dict:\n",
    "    \"\"\"\n",
    "    Run Monte Carlo simulation for strategy robustness testing\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    \n",
    "    print(f\"ðŸŽ² Running Monte Carlo simulation for {strategy_config['name']} ({n_simulations} runs)...\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Generate random OHLC data based on original data statistics\n",
    "    ohlc_generator = random_ohlc_data(original_data[['open', 'high', 'low', 'close', 'volume']])\n",
    "    \n",
    "    for i in range(n_simulations):\n",
    "        try:\n",
    "            # Generate random data\n",
    "            random_data = next(ohlc_generator)\n",
    "            random_data.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "            \n",
    "            # Run backtest on random data\n",
    "            result = run_single_backtest(strategy_config, random_data)\n",
    "            \n",
    "            if result['success']:\n",
    "                results.append({\n",
    "                    'simulation': i + 1,\n",
    "                    'return': result.get('Return [%]', 0),\n",
    "                    'sharpe': result.get('Sharpe Ratio', 0),\n",
    "                    'max_dd': result.get('Max Drawdown [%]', 0),\n",
    "                    'trades': result.get('# Trades', 0),\n",
    "                    'win_rate': result.get('Win Rate [%]', 0)\n",
    "                })\n",
    "            \n",
    "            if (i + 1) % 20 == 0:\n",
    "                print(f\"  â³ Completed {i + 1}/{n_simulations} simulations...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        return {'success': False, 'error': 'No successful simulations'}\n",
    "    \n",
    "    # Calculate statistics\n",
    "    returns = [r['return'] for r in results]\n",
    "    sharpes = [r['sharpe'] for r in results if not pd.isna(r['sharpe'])]\n",
    "    \n",
    "    mc_stats = {\n",
    "        'success': True,\n",
    "        'n_successful_sims': len(results),\n",
    "        'return_stats': {\n",
    "            'mean': np.mean(returns),\n",
    "            'std': np.std(returns),\n",
    "            'min': np.min(returns),\n",
    "            'max': np.max(returns),\n",
    "            'percentile_5': np.percentile(returns, 5),\n",
    "            'percentile_95': np.percentile(returns, 95)\n",
    "        },\n",
    "        'sharpe_stats': {\n",
    "            'mean': np.mean(sharpes) if sharpes else 0,\n",
    "            'std': np.std(sharpes) if sharpes else 0,\n",
    "        },\n",
    "        'positive_return_probability': len([r for r in returns if r > 0]) / len(returns),\n",
    "        'raw_results': results\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… Monte Carlo completed: {len(results)} successful simulations\")\n",
    "    print(f\"ðŸ“Š Mean return: {mc_stats['return_stats']['mean']:.2f}% Â± {mc_stats['return_stats']['std']:.2f}%\")\n",
    "    print(f\"ðŸŽ¯ Positive return probability: {mc_stats['positive_return_probability']:.2%}\")\n",
    "    \n",
    "    return mc_stats\n",
    "\n",
    "def plot_monte_carlo_results(mc_results: Dict, strategy_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot Monte Carlo simulation results\n",
    "    \"\"\"\n",
    "    if not mc_results.get('success', False):\n",
    "        print(\"âš ï¸ No Monte Carlo results to plot\")\n",
    "        return\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    results = mc_results['raw_results']\n",
    "    returns = [r['return'] for r in results]\n",
    "    sharpes = [r['sharpe'] for r in results if not pd.isna(r['sharpe'])]\n",
    "    \n",
    "    # 1. Return distribution\n",
    "    ax1.hist(returns, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax1.axvline(np.mean(returns), color='red', linestyle='--', \n",
    "               label=f'Mean: {np.mean(returns):.2f}%')\n",
    "    ax1.axvline(0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax1.set_xlabel('Return (%)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Monte Carlo Return Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cumulative return probability\n",
    "    sorted_returns = np.sort(returns)\n",
    "    cumprob = np.arange(1, len(sorted_returns) + 1) / len(sorted_returns)\n",
    "    \n",
    "    ax2.plot(sorted_returns, cumprob, color='green', linewidth=2)\n",
    "    ax2.axvline(0, color='red', linestyle='--', alpha=0.7, label='Break-even')\n",
    "    ax2.set_xlabel('Return (%)')\n",
    "    ax2.set_ylabel('Cumulative Probability')\n",
    "    ax2.set_title('Cumulative Return Probability')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Sharpe ratio distribution (if available)\n",
    "    if sharpes:\n",
    "        ax3.hist(sharpes, bins=20, alpha=0.7, color='orange', edgecolor='black')\n",
    "        ax3.axvline(np.mean(sharpes), color='red', linestyle='--',\n",
    "                   label=f'Mean: {np.mean(sharpes):.2f}')\n",
    "        ax3.set_xlabel('Sharpe Ratio')\n",
    "        ax3.set_ylabel('Frequency')\n",
    "        ax3.set_title('Sharpe Ratio Distribution')\n",
    "        ax3.legend()\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        ax3.text(0.5, 0.5, 'No Sharpe Ratio Data', ha='center', va='center', \n",
    "                transform=ax3.transAxes, fontsize=14)\n",
    "        ax3.set_title('Sharpe Ratio Distribution')\n",
    "    \n",
    "    # 4. Risk-return scatter\n",
    "    max_dds = [abs(r['max_dd']) for r in results]\n",
    "    ax4.scatter(max_dds, returns, alpha=0.6, color='purple')\n",
    "    ax4.set_xlabel('Max Drawdown (%)')\n",
    "    ax4.set_ylabel('Return (%)')\n",
    "    ax4.set_title('Risk vs Return')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.suptitle(f'Monte Carlo Analysis: {strategy_name}', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run Monte Carlo simulation on best strategy\n",
    "if len(train_results) > 0:\n",
    "    best_strategy_name = train_results.loc[train_results['Return [%]'].idxmax(), 'strategy_name']\n",
    "    best_config = next(\n",
    "        (config for config in strategy_configs if config['name'] == best_strategy_name),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    if best_config:\n",
    "        # Prepare data in correct format for Monte Carlo\n",
    "        mc_data = df_clean[['open', 'high', 'low', 'close', 'volume']].copy()\n",
    "        mc_data.columns = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "        \n",
    "        print(f\"ðŸŽ² Starting Monte Carlo simulation for best strategy: {best_strategy_name}\")\n",
    "        mc_results = run_monte_carlo_simulation(best_config, mc_data, n_simulations=50)\n",
    "        \n",
    "        if mc_results.get('success', False):\n",
    "            plot_monte_carlo_results(mc_results, best_strategy_name)\n",
    "        else:\n",
    "            print(f\"âŒ Monte Carlo simulation failed: {mc_results.get('error', 'Unknown error')}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No strategies available for Monte Carlo simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ebfca",
   "metadata": {},
   "source": [
    "## 12. Multi-Timeframe Analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
