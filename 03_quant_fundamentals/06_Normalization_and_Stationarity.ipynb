{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc998c9",
   "metadata": {},
   "source": [
    "# Normalization and Stationarity Analysis of S&P 500 (SPY) Time Series\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates two key preprocessing steps for financial time series: normalization to a fixed scale and transformation toward stationarity. These steps make the data suitable for downstream statistical and machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "1. Scale SPY prices into a uniform range using `MinMaxScaler`.\n",
    "2. Apply differencing to remove trends and achieve stationarity.\n",
    "3. Confirm stationarity with the Augmented Dickey-Fuller test.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Details\n",
    "- Source: `spy_historical_data.csv` (S&P 500 ETF) from the data collection module.\n",
    "- Features: timestamp index and closing prices.\n",
    "- Purpose: illustrate preprocessing on an authentic market series.\n",
    "\n",
    "---\n",
    "\n",
    "## Techniques\n",
    "### Normalization\n",
    "- `MinMaxScaler` scales prices into the [0, 1] range to reduce the effect of large values.\n",
    "- Useful for neural nets or any gradient-based learners that assume similarly scaled inputs.\n",
    "\n",
    "### Differencing\n",
    "- First-order differencing (`df.diff()`) removes linear trends and focuses on daily returns.\n",
    "- Stationary series are better behaved for time series models such as ARIMA.\n",
    "\n",
    "### Statistical Testing\n",
    "- Augmented Dickey-Fuller (ADF) test checks for the presence of a unit root.\n",
    "- A p-value below 0.05 indicates rejection of non-stationarity.\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Results\n",
    "- Raw SPY data remains non-stationary with an upward drift.\n",
    "- Normalized values stay bounded between 0 and 1 while following the same pattern.\n",
    "- Differenced series centers around zero and exhibits constant variance.\n",
    "- ADF test should support stationarity after differencing.\n",
    "\n",
    "---\n",
    "\n",
    "## Applications\n",
    "- Preprocessed series ready for machine learning models.\n",
    "- Better volatility targets for risk analysis.\n",
    "- Normalized features for strategy development and statistical inference.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "1. Normalize to compare features on equal footing.\n",
    "2. Difference to satisfy stationarity assumptions.\n",
    "3. Always validate preprocessing choices with statistical tests.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a620cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bfe06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file located: c:\\Users\\calli\\OneDrive\\Programmazione\\github\\FromZeroToQuant\\FromZeroToQuant-\\01_get_the_data\\spy_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Construct the path to the CSV file\n",
    "path = os.path.abspath(os.path.join(\"..\", \"01_get_the_data\", \"spy_historical_data.csv\"))\n",
    "\n",
    "# Validate file exists\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "    \n",
    "print(f\"Data file located: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e0136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1000 rows of data\n",
      "Final dataset shape: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-31 16:30:00</td>\n",
       "      <td>451.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY\n",
       "0 2021-08-31 16:30:00  451.56\n",
       "1 2021-09-01 16:30:00  451.80\n",
       "2 2021-09-02 16:30:00  453.19\n",
       "3 2021-09-03 16:30:00  453.08\n",
       "4 2021-09-07 16:30:00  451.46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV with error handling\n",
    "try:\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Successfully loaded {len(df)} rows of data\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load CSV file: {e}\")\n",
    "\n",
    "# Drop any rows that are completely NaN (e.g. 'Date' row)\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# Validate required columns exist\n",
    "required_columns = ['datetime', 'SPY']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "# Convert datetime column to proper datetime format\n",
    "try:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "except Exception as e:\n",
    "    # Try alternative datetime parsing if specific format fails\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Show the result\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba712fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete. Range: [0.0000, 1.0000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY_close_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-31 16:30:00</td>\n",
       "      <td>451.56</td>\n",
       "      <td>0.329004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "      <td>0.329835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "      <td>0.334649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "      <td>0.334268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "      <td>0.328658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY  SPY_close_normalized\n",
       "0 2021-08-31 16:30:00  451.56              0.329004\n",
       "1 2021-09-01 16:30:00  451.80              0.329835\n",
       "2 2021-09-02 16:30:00  453.19              0.334649\n",
       "3 2021-09-03 16:30:00  453.08              0.334268\n",
       "4 2021-09-07 16:30:00  451.46              0.328658"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate SPY data before normalization\n",
    "if df['SPY'].isna().any():\n",
    "    print(f\"Warning: Found {df['SPY'].isna().sum()} NaN values in SPY column\")\n",
    "    df = df.dropna(subset=['SPY'])\n",
    "\n",
    "# Normalize the close prices column using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['SPY_close_normalized'] = scaler.fit_transform(df[['SPY']])\n",
    "\n",
    "print(f\"Normalization complete. Range: [{df['SPY_close_normalized'].min():.4f}, {df['SPY_close_normalized'].max():.4f}]\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differencing complete. 999 observations remaining after removing NaN values\n",
      "Mean of differenced series: 0.192167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY_close_normalized</th>\n",
       "      <th>SPY_close_differenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "      <td>0.329835</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "      <td>0.334649</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "      <td>0.334268</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "      <td>0.328658</td>\n",
       "      <td>-1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-08 16:30:00</td>\n",
       "      <td>450.91</td>\n",
       "      <td>0.326753</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY  SPY_close_normalized  SPY_close_differenced\n",
       "1 2021-09-01 16:30:00  451.80              0.329835                   0.24\n",
       "2 2021-09-02 16:30:00  453.19              0.334649                   1.39\n",
       "3 2021-09-03 16:30:00  453.08              0.334268                  -0.11\n",
       "4 2021-09-07 16:30:00  451.46              0.328658                  -1.62\n",
       "5 2021-09-08 16:30:00  450.91              0.326753                  -0.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate first difference to achieve stationarity\n",
    "df['SPY_close_differenced'] = df['SPY'].diff()\n",
    "\n",
    "# Remove the first row which will be NaN due to differencing\n",
    "df = df.dropna(subset=['SPY_close_differenced'])\n",
    "\n",
    "print(f\"Differencing complete. {len(df)} observations remaining after removing NaN values\")\n",
    "print(f\"Mean of differenced series: {df['SPY_close_differenced'].mean():.6f}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AUGMENTED DICKEY-FULLER STATIONARITY TEST ===\n",
      "Null Hypothesis: Series has unit root (non-stationary)\n",
      "Alternative Hypothesis: Series is stationary\n",
      "\n",
      "ADF Test Statistic: -17.412612\n",
      "P-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.436939\n",
      "\t5%: -2.864449\n",
      "\t10%: -2.568319\n",
      "\n",
      "=== INTERPRETATION ===\n",
      "✅ CONCLUSION: The differenced series IS STATIONARY\n",
      "   (p-value < 0.05: Reject null hypothesis)\n",
      "\n",
      "Confidence level: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Verify stationarity of the differenced series using Augmented Dickey-Fuller test\n",
    "print(\"=== AUGMENTED DICKEY-FULLER STATIONARITY TEST ===\")\n",
    "print(\"Null Hypothesis: Series has unit root (non-stationary)\")\n",
    "print(\"Alternative Hypothesis: Series is stationary\\n\")\n",
    "\n",
    "# Perform ADF test (no need for additional dropna as data is already cleaned)\n",
    "result = adfuller(df['SPY_close_differenced'])\n",
    "\n",
    "# Display detailed results\n",
    "print(f'ADF Test Statistic: {result[0]:.6f}')\n",
    "print(f'P-value: {result[1]:.6f}')\n",
    "print(f'Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'\\t{key}: {value:.6f}')\n",
    "\n",
    "# Interpret results\n",
    "print(\"\\n=== INTERPRETATION ===\")\n",
    "if result[1] < 0.05:\n",
    "    print(\"✅ CONCLUSION: The differenced series IS STATIONARY\")\n",
    "    print(\"   (p-value < 0.05: Reject null hypothesis)\")\n",
    "else:\n",
    "    print(\"❌ CONCLUSION: The differenced series is NOT STATIONARY\")\n",
    "    print(\"   (p-value >= 0.05: Fail to reject null hypothesis)\")\n",
    "    \n",
    "print(f\"\\nConfidence level: {(1-result[1])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
