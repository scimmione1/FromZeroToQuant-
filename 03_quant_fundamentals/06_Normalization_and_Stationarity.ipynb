{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dc998c9",
   "metadata": {},
   "source": [
    "# Normalization and Stationarity Analysis of S&P 500 (SPY) Time Series\n",
    "\n",
    "## üìä **Overview**\n",
    "This notebook demonstrates two fundamental preprocessing techniques for financial time series data: **normalization** and **stationarity transformation**. These techniques are essential for preparing financial data for machine learning models and statistical analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Objectives**\n",
    "1. **Data Normalization**: Scale S&P 500 price data to a standardized range (0-1) using MinMaxScaler\n",
    "2. **Stationarity Transformation**: Remove trends and make the series stationary using differencing\n",
    "3. **Statistical Validation**: Verify stationarity using the Augmented Dickey-Fuller (ADF) test\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **Dataset**\n",
    "- **Source**: S&P 500 ETF (SPY) historical data\n",
    "- **File**: `spy_historical_data.csv` from the data collection module\n",
    "- **Features**: Datetime index and SPY closing prices\n",
    "- **Purpose**: Demonstrate preprocessing techniques on real financial data\n",
    "\n",
    "---\n",
    "\n",
    "## üîß **Key Techniques Implemented**\n",
    "\n",
    "### 1Ô∏è‚É£ **Normalization with MinMaxScaler**\n",
    "- **Purpose**: Scale price data to range [0, 1] for improved model performance\n",
    "- **Method**: `sklearn.preprocessing.MinMaxScaler`\n",
    "- **Benefits**: \n",
    "  - Reduces impact of scale variations\n",
    "  - Prevents larger values from dominating model training\n",
    "  - Essential for neural networks and gradient-based algorithms\n",
    "\n",
    "### 2Ô∏è‚É£ **Stationarity via Differencing**\n",
    "- **Purpose**: Remove trends and achieve constant mean/variance over time\n",
    "- **Method**: First-order differencing (`df.diff()`)\n",
    "- **Benefits**:\n",
    "  - Eliminates non-stationary behavior\n",
    "  - Makes time series suitable for ARIMA modeling\n",
    "  - Focuses on price changes rather than absolute levels\n",
    "\n",
    "### 3Ô∏è‚É£ **Statistical Testing**\n",
    "- **Test**: Augmented Dickey-Fuller (ADF) Test\n",
    "- **Null Hypothesis**: Series has unit root (non-stationary)\n",
    "- **Interpretation**: p-value < 0.05 indicates stationarity\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Expected Results**\n",
    "- **Original SPY Data**: Non-stationary with upward trend over time\n",
    "- **Normalized Data**: Values scaled between 0 and 1, maintaining original trend pattern\n",
    "- **Differenced Data**: Stationary series representing daily price changes\n",
    "- **ADF Test**: Confirms statistical stationarity of differenced series\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Applications**\n",
    "- **Machine Learning**: Preprocessed data ready for ML models\n",
    "- **Risk Management**: Stationary returns for volatility modeling\n",
    "- **Algorithmic Trading**: Normalized features for strategy development\n",
    "- **Statistical Analysis**: Foundation for time series forecasting\n",
    "\n",
    "---\n",
    "\n",
    "## üìö **Key Learning Points**\n",
    "1. **Why Normalize**: Financial data often has different scales; normalization ensures equal treatment\n",
    "2. **Why Stationarity**: Most statistical models assume stationarity for valid inference\n",
    "3. **Practical Implementation**: Real-world application of preprocessing techniques\n",
    "4. **Statistical Validation**: Importance of testing assumptions before modeling\n",
    "\n",
    "Let's dive into the implementation! üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a620cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68bfe06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file located: c:\\Users\\calli\\OneDrive\\Programmazione\\github\\FromZeroToQuant\\FromZeroToQuant-\\01_get_the_data\\spy_historical_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Construct the path to the CSV file\n",
    "path = os.path.abspath(os.path.join(\"..\", \"01_get_the_data\", \"spy_historical_data.csv\"))\n",
    "\n",
    "# Validate file exists\n",
    "if not os.path.exists(path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {path}\")\n",
    "    \n",
    "print(f\"Data file located: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e0136f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 1000 rows of data\n",
      "Final dataset shape: (1000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-31 16:30:00</td>\n",
       "      <td>451.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY\n",
       "0 2021-08-31 16:30:00  451.56\n",
       "1 2021-09-01 16:30:00  451.80\n",
       "2 2021-09-02 16:30:00  453.19\n",
       "3 2021-09-03 16:30:00  453.08\n",
       "4 2021-09-07 16:30:00  451.46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV with error handling\n",
    "try:\n",
    "    df = pd.read_csv(path)\n",
    "    print(f\"Successfully loaded {len(df)} rows of data\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load CSV file: {e}\")\n",
    "\n",
    "# Drop any rows that are completely NaN (e.g. 'Date' row)\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "# Validate required columns exist\n",
    "required_columns = ['datetime', 'SPY']\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "if missing_columns:\n",
    "    raise ValueError(f\"Missing required columns: {missing_columns}\")\n",
    "\n",
    "# Convert datetime column to proper datetime format\n",
    "try:\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S')\n",
    "except Exception as e:\n",
    "    # Try alternative datetime parsing if specific format fails\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "\n",
    "# Show the result\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba712fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization complete. Range: [0.0000, 1.0000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY_close_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-08-31 16:30:00</td>\n",
       "      <td>451.56</td>\n",
       "      <td>0.329004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "      <td>0.329835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "      <td>0.334649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "      <td>0.334268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "      <td>0.328658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY  SPY_close_normalized\n",
       "0 2021-08-31 16:30:00  451.56              0.329004\n",
       "1 2021-09-01 16:30:00  451.80              0.329835\n",
       "2 2021-09-02 16:30:00  453.19              0.334649\n",
       "3 2021-09-03 16:30:00  453.08              0.334268\n",
       "4 2021-09-07 16:30:00  451.46              0.328658"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate SPY data before normalization\n",
    "if df['SPY'].isna().any():\n",
    "    print(f\"Warning: Found {df['SPY'].isna().sum()} NaN values in SPY column\")\n",
    "    df = df.dropna(subset=['SPY'])\n",
    "\n",
    "# Normalize the close prices column using MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['SPY_close_normalized'] = scaler.fit_transform(df[['SPY']])\n",
    "\n",
    "print(f\"Normalization complete. Range: [{df['SPY_close_normalized'].min():.4f}, {df['SPY_close_normalized'].max():.4f}]\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differencing complete. 999 observations remaining after removing NaN values\n",
      "Mean of differenced series: 0.192167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SPY</th>\n",
       "      <th>SPY_close_normalized</th>\n",
       "      <th>SPY_close_differenced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-01 16:30:00</td>\n",
       "      <td>451.80</td>\n",
       "      <td>0.329835</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-02 16:30:00</td>\n",
       "      <td>453.19</td>\n",
       "      <td>0.334649</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-03 16:30:00</td>\n",
       "      <td>453.08</td>\n",
       "      <td>0.334268</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-07 16:30:00</td>\n",
       "      <td>451.46</td>\n",
       "      <td>0.328658</td>\n",
       "      <td>-1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-09-08 16:30:00</td>\n",
       "      <td>450.91</td>\n",
       "      <td>0.326753</td>\n",
       "      <td>-0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     SPY  SPY_close_normalized  SPY_close_differenced\n",
       "1 2021-09-01 16:30:00  451.80              0.329835                   0.24\n",
       "2 2021-09-02 16:30:00  453.19              0.334649                   1.39\n",
       "3 2021-09-03 16:30:00  453.08              0.334268                  -0.11\n",
       "4 2021-09-07 16:30:00  451.46              0.328658                  -1.62\n",
       "5 2021-09-08 16:30:00  450.91              0.326753                  -0.55"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate first difference to achieve stationarity\n",
    "df['SPY_close_differenced'] = df['SPY'].diff()\n",
    "\n",
    "# Remove the first row which will be NaN due to differencing\n",
    "df = df.dropna(subset=['SPY_close_differenced'])\n",
    "\n",
    "print(f\"Differencing complete. {len(df)} observations remaining after removing NaN values\")\n",
    "print(f\"Mean of differenced series: {df['SPY_close_differenced'].mean():.6f}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AUGMENTED DICKEY-FULLER STATIONARITY TEST ===\n",
      "Null Hypothesis: Series has unit root (non-stationary)\n",
      "Alternative Hypothesis: Series is stationary\n",
      "\n",
      "ADF Test Statistic: -17.412612\n",
      "P-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.436939\n",
      "\t5%: -2.864449\n",
      "\t10%: -2.568319\n",
      "\n",
      "=== INTERPRETATION ===\n",
      "‚úÖ CONCLUSION: The differenced series IS STATIONARY\n",
      "   (p-value < 0.05: Reject null hypothesis)\n",
      "\n",
      "Confidence level: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Verify stationarity of the differenced series using Augmented Dickey-Fuller test\n",
    "print(\"=== AUGMENTED DICKEY-FULLER STATIONARITY TEST ===\")\n",
    "print(\"Null Hypothesis: Series has unit root (non-stationary)\")\n",
    "print(\"Alternative Hypothesis: Series is stationary\\n\")\n",
    "\n",
    "# Perform ADF test (no need for additional dropna as data is already cleaned)\n",
    "result = adfuller(df['SPY_close_differenced'])\n",
    "\n",
    "# Display detailed results\n",
    "print(f'ADF Test Statistic: {result[0]:.6f}')\n",
    "print(f'P-value: {result[1]:.6f}')\n",
    "print(f'Critical Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'\\t{key}: {value:.6f}')\n",
    "\n",
    "# Interpret results\n",
    "print(\"\\n=== INTERPRETATION ===\")\n",
    "if result[1] < 0.05:\n",
    "    print(\"‚úÖ CONCLUSION: The differenced series IS STATIONARY\")\n",
    "    print(\"   (p-value < 0.05: Reject null hypothesis)\")\n",
    "else:\n",
    "    print(\"‚ùå CONCLUSION: The differenced series is NOT STATIONARY\")\n",
    "    print(\"   (p-value >= 0.05: Fail to reject null hypothesis)\")\n",
    "    \n",
    "print(f\"\\nConfidence level: {(1-result[1])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
