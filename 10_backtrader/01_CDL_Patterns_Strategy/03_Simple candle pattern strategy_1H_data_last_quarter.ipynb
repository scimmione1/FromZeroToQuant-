{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3465ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import backtrader as bt\n",
    "import backtrader.feeds as btfeeds\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1345ce95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì TA-Lib is available\n"
     ]
    }
   ],
   "source": [
    "# Install TA-Lib if not available\n",
    "try:\n",
    "    import talib\n",
    "    print(\"‚úì TA-Lib is available\")\n",
    "except ImportError:\n",
    "    print(\"Installing TA-Lib...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # Try to install TA-Lib\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"TA-Lib\"])\n",
    "        import talib\n",
    "        print(\"‚úì TA-Lib installed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to install TA-Lib: {e}\")\n",
    "        print(\"üí° Please install TA-Lib manually:\")\n",
    "        print(\"   conda install -c conda-forge ta-lib\")\n",
    "        print(\"   or download from: https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "406d4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_conditions = {\n",
    "        'bullish_reversal_patterns': [\n",
    "            'CDLHAMMER',              # Hammer\n",
    "            'CDLINVERTEDHAMMER',      # Inverted Hammer\n",
    "            'CDLMORNINGSTAR',         # Morning Star\n",
    "            'CDLMORNINGDOJISTAR',     # Morning Doji Star\n",
    "            'CDLENGULFING',           # Bullish Engulfing\n",
    "            'CDLPIERCING',            # Piercing Pattern\n",
    "            'CDLHARAMI',              # Bullish Harami\n",
    "            'CDLHARAMICROSS',         # Bullish Harami Cross\n",
    "            'CDLTAKURI',              # Takuri (Dragonfly Doji)\n",
    "        ],\n",
    "        \n",
    "        'bullish_continuation_patterns': [\n",
    "            'CDL3WHITESOLDIERS',      # Three White Soldiers\n",
    "            'CDLRISEFALL3METHODS',    # Rising Three Methods\n",
    "            'CDLMATHOLD',             # Mat Hold\n",
    "            'CDLSEPARATINGLINES',     # Bullish Separating Lines\n",
    "            'CDLTASUKIGAP',           # Bullish Tasuki Gap uptrend\n",
    "        ],\n",
    "        \n",
    "        'bullish_bottom_patterns': [\n",
    "            'CDLABANDONEDBABY',       # Abandoned Baby\n",
    "            'CDLLADDERBOTTOM',        # Ladder Bottom\n",
    "            'CDLMATCHINGLOW',         # Matching Low\n",
    "            'CDLUNIQUE3RIVER',        # Unique Three River\n",
    "        ],\n",
    "        \n",
    "        'bullish_special_patterns': [\n",
    "            'CDL3INSIDE',             # Three Inside Up\n",
    "            'CDL3OUTSIDE',            # Three Outside Up\n",
    "            'CDLBELTHOLD',            # Belt Hold\n",
    "            'CDLBREAKAWAY',           # Breakaway\n",
    "            'CDLKICKING',             # Kicking\n",
    "            'CDLKICKINGBYLENGTH',     # Kicking By Length\n",
    "            'CDLSTICKSANDWICH',       # Stick Sandwich\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ebcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Long_Candlesticks Strategy created - using TA-Lib candlestick patterns!\n"
     ]
    }
   ],
   "source": [
    "# Strategy Candlestick Patterns - FIXED VERSION with Proper Risk Management\n",
    "\n",
    "class Long_Candlesticks(bt.Strategy):\n",
    "    \"\"\"\n",
    "    Strategy focusing on long candlestick patterns for trade entries\n",
    "    Entry signals based on bullish patterns using TA-Lib candlestick functions\n",
    "    \n",
    "    DESIGNED FOR HOURLY DATA (1H timeframe)\n",
    "    Stop-loss and take-profit based on ATR\n",
    "    \n",
    "    Expected data: S&P 500 hourly OHLCV bars\n",
    "    Timeframe: 1H (hourly candles)\n",
    "    \"\"\"\n",
    "    \n",
    "    params = (\n",
    "        ('printlog', True),  # Enable logging to debug issues\n",
    "        ('atr_period', 14),\n",
    "        ('atr_sl_multiplier', 2.0),\n",
    "        ('atr_tp_multiplier', 3.0),\n",
    "        ('position_pct', 0.05),  # Use only 5% of portfolio per trade for safety\n",
    "        ('max_trades', 10),  # Limit total number of trades\n",
    "        ('lookback_period', 50),  # Number of bars to look back for pattern detection\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # ATR for stop-loss and take-profit calculations\n",
    "        self.atr = bt.indicators.ATR(self.data, period=self.p.atr_period)\n",
    "\n",
    "        self.stop_loss = None\n",
    "        self.take_profit = None\n",
    "        \n",
    "        self.order = None\n",
    "        self.trade_count = 0\n",
    "        \n",
    "        # Store OHLC data for TA-Lib calculations\n",
    "        self.open_data = []\n",
    "        self.high_data = []\n",
    "        self.low_data = []\n",
    "        self.close_data = []\n",
    "\n",
    "    def log(self, txt, dt=None, doprint=False):\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print(f'{dt.isoformat()}, {txt}')\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(f'BUY EXECUTED, Price: {order.executed.price:.2f}')\n",
    "            else:\n",
    "                self.log(f'SELL EXECUTED, Price: {order.executed.price:.2f}')\n",
    "        self.order = None\n",
    "\n",
    "    def notify_trade(self, trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "        self.trade_count += 1\n",
    "        self.log(f'TRADE #{self.trade_count}: PROFIT {trade.pnl:.2f}', doprint=True)\n",
    "\n",
    "    def check_bullish_patterns(self, open_prices, high_prices, low_prices, close_prices):\n",
    "        \"\"\"Check for bullish candlestick patterns using TA-Lib\"\"\"\n",
    "        bullish_signals = []\n",
    "        \n",
    "        try:\n",
    "            # Convert to numpy arrays\n",
    "            open_arr = np.array(open_prices, dtype=np.float64)\n",
    "            high_arr = np.array(high_prices, dtype=np.float64)\n",
    "            low_arr = np.array(low_prices, dtype=np.float64)\n",
    "            close_arr = np.array(close_prices, dtype=np.float64)\n",
    "            \n",
    "            # Check bullish reversal patterns\n",
    "            hammer = talib.CDLHAMMER(open_arr, high_arr, low_arr, close_arr)\n",
    "            inverted_hammer = talib.CDLINVERTEDHAMMER(open_arr, high_arr, low_arr, close_arr)\n",
    "            morning_star = talib.CDLMORNINGSTAR(open_arr, high_arr, low_arr, close_arr)\n",
    "            morning_doji = talib.CDLMORNINGDOJISTAR(open_arr, high_arr, low_arr, close_arr)\n",
    "            engulfing = talib.CDLENGULFING(open_arr, high_arr, low_arr, close_arr)\n",
    "            piercing = talib.CDLPIERCING(open_arr, high_arr, low_arr, close_arr)\n",
    "            harami = talib.CDLHARAMI(open_arr, high_arr, low_arr, close_arr)\n",
    "\n",
    "            # added patterns\n",
    "            takuri = talib.CDLTAKURI(open_arr, high_arr, low_arr, close_arr)  # Takuri (Dragonfly Doji)\n",
    "            rise_fall = talib.CDLRISEFALL3METHODS(open_arr, high_arr, low_arr, close_arr)  # Rising Three Methods\n",
    "            mat_hold = talib.CDLMATHOLD(open_arr, high_arr, low_arr, close_arr)  # Mat Hold\n",
    "            separating_lines = talib.CDLSEPARATINGLINES(open_arr, high_arr, low_arr, close_arr)  # Bullish Separating Lines\n",
    "            tasuki_gap = talib.CDLTASUKIGAP(open_arr, high_arr, low_arr, close_arr)  # Bullish Tasuki Gap uptrend\n",
    "            abandoned_baby = talib.CDLABANDONEDBABY(open_arr, high_arr, low_arr, close_arr)  # Abandoned Baby\n",
    "            ladder_bottom = talib.CDLLADDERBOTTOM(open_arr, high_arr, low_arr, close_arr)  # Ladder Bottom\n",
    "            matching_low = talib.CDLMATCHINGLOW(open_arr, high_arr, low_arr, close_arr)  # Matching Low\n",
    "            unique_three_river = talib.CDLUNIQUE3RIVER(open_arr, high_arr, low_arr, close_arr)  # Unique Three River\n",
    "            three_inside = talib.CDL3INSIDE(open_arr, high_arr, low_arr, close_arr)  # Three Inside Up\n",
    "            three_outside = talib.CDL3OUTSIDE(open_arr, high_arr, low_arr, close_arr)  # Three Outside Up\n",
    "            belt_hold = talib.CDLBELTHOLD(open_arr, high_arr, low_arr, close_arr)  # Belt Hold\n",
    "            breakaway = talib.CDLBREAKAWAY(open_arr, high_arr, low_arr, close_arr)  # Breakaway\n",
    "            kicking = talib.CDLKICKING(open_arr, high_arr, low_arr, close_arr)  # Kicking\n",
    "            kicking_by_length = talib.CDLKICKINGBYLENGTH(open_arr, high_arr, low_arr, close_arr)  # Kicking By Length\n",
    "            sticks_sandwich = talib.CDLSTICKSANDWICH(open_arr, high_arr, low_arr, close_arr)  # Stick Sandwich\n",
    "\n",
    "            # Check bullish continuation patterns\n",
    "            three_white_soldiers = talib.CDL3WHITESOLDIERS(open_arr, high_arr, low_arr, close_arr)\n",
    "            \n",
    "            # Combine all bullish signals (positive values indicate bullish patterns)\n",
    "            patterns = [hammer, inverted_hammer, morning_star, morning_doji, \n",
    "                       engulfing, piercing, harami, three_white_soldiers, \n",
    "                       takuri, rise_fall, mat_hold, separating_lines, tasuki_gap, \n",
    "                       abandoned_baby, ladder_bottom, matching_low, unique_three_river, \n",
    "                       three_inside, three_outside, belt_hold, breakaway, kicking, \n",
    "                       kicking_by_length, sticks_sandwich]\n",
    "\n",
    "            # Check if any pattern shows a bullish signal (> 0) in the last bar\n",
    "            for pattern in patterns:\n",
    "                if len(pattern) > 0 and pattern[-1] > 0:\n",
    "                    bullish_signals.append(pattern[-1])\n",
    "            \n",
    "            return len(bullish_signals) > 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"Pattern detection error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def next(self):\n",
    "        # Store current OHLC data\n",
    "        self.open_data.append(float(self.data.open[0]))\n",
    "        self.high_data.append(float(self.data.high[0]))\n",
    "        self.low_data.append(float(self.data.low[0]))\n",
    "        self.close_data.append(float(self.data.close[0]))\n",
    "        \n",
    "        # Keep only the last lookback_period bars\n",
    "        if len(self.close_data) > self.p.lookback_period:\n",
    "            self.open_data = self.open_data[-self.p.lookback_period:]\n",
    "            self.high_data = self.high_data[-self.p.lookback_period:]\n",
    "            self.low_data = self.low_data[-self.p.lookback_period:]\n",
    "            self.close_data = self.close_data[-self.p.lookback_period:]\n",
    "        # Wait for enough data for pattern detection and ATR to stabilize\n",
    "        if len(self.close_data) < 30 or len(self.data) < 60:\n",
    "            return\n",
    "            \n",
    "        # Ensure ATR has valid values\n",
    "        if not self.atr or len(self.atr) == 0 or self.atr[0] is None or np.isnan(self.atr[0]):\n",
    "            return\n",
    "\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:\n",
    "            # Check for bullish candlestick patterns\n",
    "            if self.check_bullish_patterns(self.open_data, self.high_data, \n",
    "                                         self.low_data, self.close_data):\n",
    "                self.log('BUY SIGNAL: Bullish candlestick pattern detected')\n",
    "                \n",
    "                # SAFE position sizing calculation\n",
    "                if self.trade_count >= self.p.max_trades:\n",
    "                    self.log(f'Max trades ({self.p.max_trades}) reached, skipping entry')\n",
    "                    return\n",
    "                \n",
    "                cash = self.broker.getcash()\n",
    "                portfolio_value = self.broker.getvalue()\n",
    "                price = self.data.close[0]\n",
    "                \n",
    "                # Calculate position size with multiple safety checks\n",
    "                position_value = portfolio_value * self.p.position_pct\n",
    "                max_position_value = min(position_value, cash * 0.95)  # Never use more than 95% of cash\n",
    "                size = max(1, int(max_position_value / price))  # Ensure at least 1 share\n",
    "                cost = size * price\n",
    "                \n",
    "                self.log(f'POSITION CALC: Portfolio=${portfolio_value:.2f}, Cash=${cash:.2f}, Price=${price:.2f}')\n",
    "                self.log(f'Size={size}, Cost=${cost:.2f}, Position%={self.p.position_pct*100:.1f}%')\n",
    "                \n",
    "                # Safety check: ensure we can afford the position\n",
    "                if cost <= cash and size > 0 and cost < portfolio_value * 0.2:  # Never risk more than 20%\n",
    "                    self.order = self.buy(size=size)\n",
    "                    # Set stop-loss and take-profit based on ATR\n",
    "                    self.stop_loss = price - (self.atr[0] * self.p.atr_sl_multiplier)\n",
    "                    self.take_profit = price + (self.atr[0] * self.p.atr_tp_multiplier)\n",
    "                    self.log(f'BUY ORDER: Size={size}, Price=${price:.2f}, Cost=${cost:.2f}')\n",
    "                    self.log(f'SL=${self.stop_loss:.2f}, TP=${self.take_profit:.2f}, ATR=${self.atr[0]:.2f}')\n",
    "                else:\n",
    "                    self.log(f'POSITION REJECTED: Cost=${cost:.2f} > Available=${cash:.2f} or unsafe size')\n",
    "        else:\n",
    "            # Manage existing position with ATR-based stop-loss and take-profit\n",
    "            if self.stop_loss is not None and self.data.close[0] <= self.stop_loss:\n",
    "                self.log('STOP-LOSS HIT')\n",
    "                self.order = self.sell()\n",
    "            elif self.take_profit is not None and self.data.close[0] >= self.take_profit:\n",
    "                self.log('TAKE-PROFIT HIT')\n",
    "                self.order = self.sell()\n",
    "\n",
    "    def stop(self):\n",
    "        self.log(f'Long_Candlesticks Strategy: {self.trade_count} trades, Final Value: ${self.broker.getvalue():.2f}', doprint=True)\n",
    "\n",
    "print(\"‚úì Long_Candlesticks Strategy created - using TA-Lib candlestick patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d9ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV Files List for Multi-Year Quarterly Backtesting\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# List of quarterly CSV files for backtesting\n",
    "csv_files = [\n",
    "    'USA500IDXUSD_H1_returns_2019_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2020_q4.csv', \n",
    "    'USA500IDXUSD_H1_returns_2021_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2022_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2023_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2024_q4.csv'\n",
    "]\n",
    "\n",
    "# Automatically detect all Q4 CSV files in the data directory\n",
    "data_dir = '01_data'\n",
    "auto_detected_files = glob.glob(os.path.join(data_dir, '*_q4.csv'))\n",
    "\n",
    "print(f\"üìÇ Manual CSV list: {len(csv_files)} files\")\n",
    "print(f\"üîç Auto-detected files: {len(auto_detected_files)} files\")\n",
    "\n",
    "# Use auto-detected files if available, otherwise use manual list\n",
    "if auto_detected_files:\n",
    "    csv_files = [os.path.basename(f) for f in auto_detected_files]\n",
    "    csv_files.sort()  # Sort chronologically\n",
    "    print(\"‚úÖ Using auto-detected files:\")\n",
    "else:\n",
    "    print(\"‚úÖ Using manual file list:\")\n",
    "\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    full_path = os.path.join(data_dir, file)\n",
    "    exists = \"‚úì\" if os.path.exists(full_path) else \"‚ùå\"\n",
    "    print(f\"  {i}. {exists} {file}\")\n",
    "\n",
    "print(f\"\\nüéØ Ready to backtest {len(csv_files)} quarterly datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51e09937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Backtest function ready for Long_Candlesticks\n"
     ]
    }
   ],
   "source": [
    "# Backtest Function for Long_Candlesticks Strategy\n",
    "\n",
    "def test_long_candlesticks_strategy(csv_filename=None):\n",
    "    \"\"\"Test the Long_Candlesticks strategy with S&P 500 quarterly data\"\"\"\n",
    "    \n",
    "    # Use provided filename or default to 2023 Q4\n",
    "    if csv_filename is None:\n",
    "        csv_filename = 'USA500IDXUSD_H1_returns_2023_q4.csv'\n",
    "    \n",
    "    print(f\"=== TESTING Long_Candlesticks on {csv_filename} ===\\n\")\n",
    "    \n",
    "    cerebro = bt.Cerebro()\n",
    "    \n",
    "    # Load S&P 500 data\n",
    "    spy_file = os.path.join('01_data', csv_filename)\n",
    "    df = pd.read_csv(spy_file)\n",
    "    \n",
    "    # Combine date and timestamp columns\n",
    "    df['DateTime'] = pd.to_datetime(df['date'] + ' ' + df['timestamp'])\n",
    "    \n",
    "    # Rename columns to match expected format\n",
    "    df = df.rename(columns={\n",
    "        'open': 'Open',\n",
    "        'high': 'High', \n",
    "        'low': 'Low',\n",
    "        'close': 'Close',\n",
    "        'volume': 'Volume'\n",
    "    })\n",
    "    \n",
    "    # Select only needed columns and use DateTime\n",
    "    df = df[['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    df = df.rename(columns={'DateTime': 'Date'})\n",
    "    df = df.sort_values('Date').dropna()\n",
    "    \n",
    "    # Use full quarterly dataset (Q4 data)\n",
    "    start_date = df['Date'].min()\n",
    "    end_date = df['Date'].max()\n",
    "    df_recent = df.copy()\n",
    "    \n",
    "    print(f\"üìä Data: {len(df_recent)} hourly bars from {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"üìÖ Dataset: {csv_filename} (Full Q4 period)\")\n",
    "    \n",
    "    # Create temporary file for backtrader\n",
    "    temp_file = 'temp_simplified_test.csv'\n",
    "    df_recent.to_csv(temp_file, index=False)\n",
    "    \n",
    "    # Create data feed\n",
    "    data = btfeeds.GenericCSVData(\n",
    "        dataname=temp_file,\n",
    "        dtformat=('%Y-%m-%d %H:%M:%S'),\n",
    "        datetime=0, open=1, high=2, low=3, close=4, volume=5,\n",
    "        openinterest=-1, headers=True,\n",
    "    )\n",
    "\n",
    "    # Add data and strategy\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.addstrategy(Long_Candlesticks, printlog=False)\n",
    "    \n",
    "    # Set initial capital and commission\n",
    "    initial_capital = 50000.0\n",
    "    cerebro.broker.setcash(initial_capital)\n",
    "    cerebro.broker.setcommission(commission=0.001)  # 0.1% commission\n",
    "    cerebro.broker.set_slippage_perc(0.01)  # 1% slippage for realism\n",
    "    \n",
    "    # Add analyzers\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"trades\")\n",
    "    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name=\"sharpe\")\n",
    "    cerebro.addanalyzer(bt.analyzers.DrawDown, _name=\"drawdown\")\n",
    "\n",
    "    print(f\"üí∞ Starting Capital: ${initial_capital:,.2f}\")\n",
    "    print(\"üöÄ Running backtest...\\n\")\n",
    "    \n",
    "    # Run backtest\n",
    "    results = cerebro.run()\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "    \n",
    "    # Calculate results\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "    \n",
    "    print(f\"\\n=== BACKTEST RESULTS ===\")\n",
    "    print(f\"üí∞ Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    print(f\"üìà Total Return: {total_return:.2f}%\")\n",
    "    print(f\"üíµ Net Profit: ${final_value - initial_capital:,.2f}\")\n",
    "    \n",
    "    # Analyze trades\n",
    "    strat = results[0]\n",
    "    trade_analysis = strat.analyzers.trades.get_analysis()\n",
    "    \n",
    "    if trade_analysis and hasattr(trade_analysis, 'total'):\n",
    "        total_trades = getattr(trade_analysis.total, 'total', 0)\n",
    "        print(f\"\\n=== TRADE ANALYSIS ===\")\n",
    "        print(f\"üìä Total Trades: {total_trades}\")\n",
    "        \n",
    "        # Winning trades\n",
    "        if hasattr(trade_analysis, 'won'):\n",
    "            won_trades = getattr(trade_analysis.won, 'total', 0)\n",
    "            won_pnl = getattr(trade_analysis.won, 'pnl', {}).get('total', 0)\n",
    "            win_rate = (won_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "            print(f\"‚úÖ Winning Trades: {won_trades} ({win_rate:.1f}%)\")\n",
    "            if won_pnl:\n",
    "                print(f\"üí∞ Winning PnL: ${won_pnl:.2f}\")\n",
    "        \n",
    "        # Losing trades  \n",
    "        if hasattr(trade_analysis, 'lost'):\n",
    "            lost_trades = getattr(trade_analysis.lost, 'total', 0)\n",
    "            lost_pnl = getattr(trade_analysis.lost, 'pnl', {}).get('total', 0)\n",
    "            print(f\"‚ùå Losing Trades: {lost_trades}\")\n",
    "            if lost_pnl:\n",
    "                print(f\"üí∏ Losing PnL: ${lost_pnl:.2f}\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    print(f\"\\n=== PERFORMANCE METRICS ===\")\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_analysis = strat.analyzers.sharpe.get_analysis()\n",
    "    if sharpe_analysis and 'sharperatio' in sharpe_analysis:\n",
    "        sharpe_ratio = sharpe_analysis['sharperatio'] or 0\n",
    "        print(f\"üìä Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "\n",
    "    # Drawdown Analysis\n",
    "    drawdown_analysis = strat.analyzers.drawdown.get_analysis()\n",
    "    if drawdown_analysis:\n",
    "        max_dd = drawdown_analysis.get('max', {}).get('drawdown', 0)\n",
    "        print(f\"üìâ Max Drawdown: {max_dd:.2f}%\")\n",
    "    \n",
    "    return results, total_trades, final_value\n",
    "\n",
    "print(\"‚úì Backtest function ready for Long_Candlesticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cd38550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-file backtesting function ready!\n"
     ]
    }
   ],
   "source": [
    "# Multi-File Backtesting Function\n",
    "\n",
    "def run_multi_file_backtests(csv_files_list):\n",
    "    \"\"\"Run backtests on multiple CSV files and collect comprehensive results\"\"\"\n",
    "    \n",
    "    print(\"üöÄ STARTING MULTI-FILE BACKTESTING CAMPAIGN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_results = {}\n",
    "    summary_data = []\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files_list, 1):\n",
    "        print(f\"\\nüìä BACKTEST {i}/{len(csv_files_list)}: {csv_file}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Check if file exists\n",
    "            full_path = os.path.join('01_data', csv_file)\n",
    "            if not os.path.exists(full_path):\n",
    "                print(f\"‚ùå File not found: {csv_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Run individual backtest\n",
    "            results, trade_count, final_value = test_long_candlesticks_strategy(csv_file)\n",
    "            \n",
    "            # Extract detailed analytics\n",
    "            strat = results[0]\n",
    "            trade_analysis = strat.analyzers.trades.get_analysis()\n",
    "            sharpe_analysis = strat.analyzers.sharpe.get_analysis()\n",
    "            drawdown_analysis = strat.analyzers.drawdown.get_analysis()\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            initial_capital = 50000.0\n",
    "            total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "            net_profit = final_value - initial_capital\n",
    "            \n",
    "            # Extract trade statistics\n",
    "            total_trades = getattr(trade_analysis.total, 'total', 0) if hasattr(trade_analysis, 'total') else 0\n",
    "            won_trades = getattr(trade_analysis.won, 'total', 0) if hasattr(trade_analysis, 'won') else 0\n",
    "            lost_trades = getattr(trade_analysis.lost, 'total', 0) if hasattr(trade_analysis, 'lost') else 0\n",
    "            win_rate = (won_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "            \n",
    "            won_pnl = getattr(trade_analysis.won, 'pnl', {}).get('total', 0) if hasattr(trade_analysis, 'won') else 0\n",
    "            lost_pnl = getattr(trade_analysis.lost, 'pnl', {}).get('total', 0) if hasattr(trade_analysis, 'lost') else 0\n",
    "            \n",
    "            sharpe_ratio = sharpe_analysis.get('sharperatio', 0) if sharpe_analysis else 0\n",
    "            max_drawdown = drawdown_analysis.get('max', {}).get('drawdown', 0) if drawdown_analysis else 0\n",
    "            \n",
    "            # Store results\n",
    "            file_result = {\n",
    "                'csv_file': csv_file,\n",
    "                'final_value': final_value,\n",
    "                'total_return_pct': total_return,\n",
    "                'net_profit': net_profit,\n",
    "                'total_trades': total_trades,\n",
    "                'won_trades': won_trades,\n",
    "                'lost_trades': lost_trades,\n",
    "                'win_rate_pct': win_rate,\n",
    "                'won_pnl': won_pnl,\n",
    "                'lost_pnl': lost_pnl,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown_pct': max_drawdown\n",
    "            }\n",
    "            \n",
    "            all_results[csv_file] = file_result\n",
    "            summary_data.append(file_result)\n",
    "            \n",
    "            # Print results for this file\n",
    "            print(f\"\\nüìà DETAILED RESULTS FOR {csv_file}:\")\n",
    "            print(f\"üí∞ Final Value: ${final_value:,.2f}\")\n",
    "            print(f\"üìä Total Return: {total_return:.2f}%\")\n",
    "            print(f\"üíµ Net Profit: ${net_profit:,.2f}\")\n",
    "            print(f\"üìà Total Trades: {total_trades}\")\n",
    "            print(f\"‚úÖ Won: {won_trades} ({win_rate:.1f}%) | PnL: ${won_pnl:.2f}\")\n",
    "            print(f\"‚ùå Lost: {lost_trades} | PnL: ${lost_pnl:.2f}\")\n",
    "            print(f\"üìä Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "            print(f\"üìâ Max Drawdown: {max_drawdown:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ERROR in {csv_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(f\"\\n\\nüéØ COMPREHENSIVE BACKTESTING SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if summary_data:\n",
    "        total_files = len(summary_data)\n",
    "        avg_return = sum(d['total_return_pct'] for d in summary_data) / total_files\n",
    "        avg_trades = sum(d['total_trades'] for d in summary_data) / total_files\n",
    "        avg_win_rate = sum(d['win_rate_pct'] for d in summary_data) / total_files\n",
    "        avg_sharpe = sum(d['sharpe_ratio'] for d in summary_data) / total_files\n",
    "        avg_drawdown = sum(d['max_drawdown_pct'] for d in summary_data) / total_files\n",
    "        \n",
    "        best_performer = max(summary_data, key=lambda x: x['total_return_pct'])\n",
    "        worst_performer = min(summary_data, key=lambda x: x['total_return_pct'])\n",
    "        \n",
    "        print(f\"üìä Backtested Files: {total_files}\")\n",
    "        print(f\"üìà Average Return: {avg_return:.2f}%\")\n",
    "        print(f\"üî¢ Average Trades per Quarter: {avg_trades:.1f}\")\n",
    "        print(f\"üéØ Average Win Rate: {avg_win_rate:.1f}%\")\n",
    "        print(f\"üìä Average Sharpe Ratio: {avg_sharpe:.4f}\")\n",
    "        print(f\"üìâ Average Max Drawdown: {avg_drawdown:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nüèÜ BEST PERFORMER:\")\n",
    "        print(f\"   üìÅ {best_performer['csv_file']}\")\n",
    "        print(f\"   üìà Return: {best_performer['total_return_pct']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nüìâ WORST PERFORMER:\")\n",
    "        print(f\"   üìÅ {worst_performer['csv_file']}\")\n",
    "        print(f\"   üìà Return: {worst_performer['total_return_pct']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nüìã DETAILED PERFORMANCE TABLE:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'File':<35} {'Return %':<10} {'Trades':<8} {'Win %':<8} {'Sharpe':<10} {'DD %':<8}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for data in summary_data:\n",
    "            print(f\"{data['csv_file']:<35} {data['total_return_pct']:>8.2f}% {data['total_trades']:>6.0f}   {data['win_rate_pct']:>6.1f}%  {data['sharpe_ratio']:>8.4f}  {data['max_drawdown_pct']:>6.2f}%\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No successful backtests completed\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"‚úÖ Multi-file backtesting function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d30174e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2023_q4.csv ===\n",
      "\n",
      "üìä Data: 1463 hourly bars from 2023-10-02 to 2023-12-29\n",
      "üìÖ Dataset: USA500IDXUSD_H1_returns_2023_q4.csv (Full Q4 period)\n",
      "üí∞ Starting Capital: $50,000.00\n",
      "üöÄ Running backtest...\n",
      "\n",
      "2023-10-09, TRADE #1: PROFIT 38.23\n",
      "2023-12-29, Long_Candlesticks Strategy: 1 trades, Final Value: $-289181.38\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "üí∞ Final Portfolio Value: $-289,181.38\n",
      "üìà Total Return: -678.36%\n",
      "üíµ Net Profit: $-339,181.38\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "üìä Total Trades: 2\n",
      "‚úÖ Winning Trades: 1 (50.0%)\n",
      "üí∞ Winning PnL: $12.65\n",
      "‚ùå Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "üìä Sharpe Ratio: 0.0000\n",
      "üìâ Max Drawdown: 430.42%\n",
      "\n",
      "üéâ BACKTEST COMPLETED SUCCESSFULLY!\n",
      "üìä Summary: 2 trades, Final Value: $-289,181.38\n",
      "üìà Strategy executed multiple trades\n",
      "2023-12-29, Long_Candlesticks Strategy: 1 trades, Final Value: $-289181.38\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "üí∞ Final Portfolio Value: $-289,181.38\n",
      "üìà Total Return: -678.36%\n",
      "üíµ Net Profit: $-339,181.38\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "üìä Total Trades: 2\n",
      "‚úÖ Winning Trades: 1 (50.0%)\n",
      "üí∞ Winning PnL: $12.65\n",
      "‚ùå Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "üìä Sharpe Ratio: 0.0000\n",
      "üìâ Max Drawdown: 430.42%\n",
      "\n",
      "üéâ BACKTEST COMPLETED SUCCESSFULLY!\n",
      "üìä Summary: 2 trades, Final Value: $-289,181.38\n",
      "üìà Strategy executed multiple trades\n"
     ]
    }
   ],
   "source": [
    "# Execute Long_Candlesticks Backtest\n",
    "try:\n",
    "    results, trade_count, final_value = test_long_candlesticks_strategy()\n",
    "    \n",
    "    print(f\"\\nüéâ BACKTEST COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"üìä Summary: {trade_count} trades, Final Value: ${final_value:,.2f}\")\n",
    "    \n",
    "    if trade_count > 10:\n",
    "        print(\"‚úÖ Strategy shows active trading with multiple trades\")\n",
    "    elif trade_count > 1:\n",
    "        print(\"üìà Strategy executed multiple trades\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Strategy was very selective with few trades\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running backtest: {str(e)}\")\n",
    "    print(\"üí° Make sure the S&P 500 data file exists at the specified path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ LAUNCHING COMPREHENSIVE QUARTERLY BACKTESTING\n",
      "üîÑ This will run the Long_Candlesticks strategy on each Q4 dataset\n",
      "‚è∞ Please wait while processing multiple datasets...\n",
      "\n",
      "üöÄ STARTING MULTI-FILE BACKTESTING CAMPAIGN\n",
      "============================================================\n",
      "\n",
      "üìä BACKTEST 1/6: USA500IDXUSD_H1_returns_2019_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2019_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "üìä BACKTEST 2/6: USA500IDXUSD_H1_returns_2020_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2020_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "üìä BACKTEST 3/6: USA500IDXUSD_H1_returns_2021_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2021_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "üìä BACKTEST 4/6: USA500IDXUSD_H1_returns_2022_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2022_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "üìä BACKTEST 5/6: USA500IDXUSD_H1_returns_2023_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2023_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "üìä BACKTEST 6/6: USA500IDXUSD_H1_returns_2024_q4.csv\n",
      "--------------------------------------------------\n",
      "‚ùå ERROR in USA500IDXUSD_H1_returns_2024_q4.csv: name 'test_long_candlesticks_strategy' is not defined\n",
      "\n",
      "\n",
      "üéØ COMPREHENSIVE BACKTESTING SUMMARY\n",
      "======================================================================\n",
      "‚ùå No successful backtests completed\n",
      "\n",
      "üéâ MULTI-FILE BACKTESTING COMPLETED!\n",
      "üìä Successfully processed 0 datasets\n"
     ]
    }
   ],
   "source": [
    "# # Execute Multi-File Backtesting Campaign\n",
    "\n",
    "# # Run backtests on all quarterly CSV files\n",
    "# print(\"üéØ LAUNCHING COMPREHENSIVE QUARTERLY BACKTESTING\")\n",
    "# print(\"üîÑ This will run the Long_Candlesticks strategy on each Q4 dataset\")\n",
    "# print(\"‚è∞ Please wait while processing multiple datasets...\\n\")\n",
    "\n",
    "# try:\n",
    "#     # Execute the multi-file backtesting\n",
    "#     all_backtest_results = run_multi_file_backtests(csv_files)\n",
    "    \n",
    "#     print(f\"\\nüéâ MULTI-FILE BACKTESTING COMPLETED!\")\n",
    "#     print(f\"üìä Successfully processed {len(all_backtest_results)} datasets\")\n",
    "    \n",
    "#     # Additional insights\n",
    "#     if all_backtest_results:\n",
    "#         profitable_quarters = sum(1 for result in all_backtest_results.values() \n",
    "#                                  if result['total_return_pct'] > 0)\n",
    "#         total_quarters = len(all_backtest_results)\n",
    "#         profitability_rate = (profitable_quarters / total_quarters * 100) if total_quarters > 0 else 0\n",
    "        \n",
    "#         print(f\"üí∞ Profitable Quarters: {profitable_quarters}/{total_quarters} ({profitability_rate:.1f}%)\")\n",
    "        \n",
    "#         # Strategy consistency analysis\n",
    "#         returns = [result['total_return_pct'] for result in all_backtest_results.values()]\n",
    "#         avg_return = sum(returns) / len(returns) if returns else 0\n",
    "#         return_std = np.std(returns) if returns else 0\n",
    "        \n",
    "#         print(f\"üìà Return Statistics:\")\n",
    "#         print(f\"   ‚Ä¢ Average: {avg_return:.2f}%\")\n",
    "#         print(f\"   ‚Ä¢ Std Dev: {return_std:.2f}%\")\n",
    "#         print(f\"   ‚Ä¢ Range: {min(returns):.2f}% to {max(returns):.2f}%\")\n",
    "        \n",
    "#         # Trading activity analysis\n",
    "#         trade_counts = [result['total_trades'] for result in all_backtest_results.values()]\n",
    "#         avg_trades = sum(trade_counts) / len(trade_counts) if trade_counts else 0\n",
    "        \n",
    "#         print(f\"üî¢ Trading Activity:\")\n",
    "#         print(f\"   ‚Ä¢ Average trades per quarter: {avg_trades:.1f}\")\n",
    "#         print(f\"   ‚Ä¢ Total trades across all quarters: {sum(trade_counts)}\")\n",
    "        \n",
    "#         print(f\"\\n‚úÖ Long_Candlesticks strategy analysis complete across {len(csv_files)} quarterly periods\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"‚ùå Error in multi-file backtesting: {str(e)}\")\n",
    "#     print(\"üí° Check that all CSV files exist in the 01_data directory\")\n",
    "#     print(\"üîç You can also run individual backtests by calling:\")\n",
    "#     print(\"   test_long_candlesticks_strategy('specific_file.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d69075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOURLY DATA VALIDATION ===\n",
      "üìä Total records: 8,869\n",
      "üìÖ Date range: 2019-10-01 to 2024-12-31\n",
      "üïê Most common time interval: 0 days 01:00:00\n",
      "üìà Price range: $2876.97 - $6099.28\n",
      "\\nüîç Sample hourly data progression:\n",
      "  2019-10-01 00:00:00 - Close: $2981.57\n",
      "  2019-10-01 01:00:00 - Close: $2981.57\n",
      "  2019-10-01 02:00:00 - Close: $2986.07\n",
      "  2019-10-01 03:00:00 - Close: $2988.07\n",
      "  2019-10-01 04:00:00 - Close: $2987.57\n",
      "  2019-10-01 05:00:00 - Close: $2989.07\n",
      "  2019-10-01 06:00:00 - Close: $2988.07\n",
      "  2019-10-01 07:00:00 - Close: $2987.87\n",
      "  2019-10-01 08:00:00 - Close: $2990.57\n",
      "  2019-10-01 09:00:00 - Close: $2986.57\n",
      "\\n‚úÖ Hourly intervals: 8,480 / 8,868 (95.6%)\n",
      "‚úÖ Data confirmed as hourly timeframe\n"
     ]
    }
   ],
   "source": [
    "# # Validate Hourly Data Structure\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Quick data validation\n",
    "# spy_file = os.path.join('01_data', 'USA500IDXUSD_H1_returns_2019-2024_q4.csv')\n",
    "# df = pd.read_csv(spy_file)\n",
    "\n",
    "# print(\"=== HOURLY DATA VALIDATION ===\")\n",
    "# print(f\"üìä Total records: {len(df):,}\")\n",
    "# print(f\"üìÖ Date range: {df.date.min()} to {df.date.max()}\")\n",
    "\n",
    "# # Check time intervals\n",
    "# df['DateTime'] = pd.to_datetime(df['date'] + ' ' + df['timestamp'])\n",
    "# df_sorted = df.sort_values('DateTime')\n",
    "\n",
    "# # Calculate time differences between consecutive bars\n",
    "# time_diffs = df_sorted['DateTime'].diff().dropna()\n",
    "# most_common_diff = time_diffs.mode().iloc[0] if len(time_diffs) > 0 else None\n",
    "\n",
    "# print(f\"üïê Most common time interval: {most_common_diff}\")\n",
    "# print(f\"üìà Price range: ${df.close.min():.2f} - ${df.close.max():.2f}\")\n",
    "\n",
    "# # Show sample of hourly progression\n",
    "# print(f\"\\\\nüîç Sample hourly data progression:\")\n",
    "# sample = df_sorted[['date', 'timestamp', 'close']].head(10)\n",
    "# for idx, row in sample.iterrows():\n",
    "#     print(f\"  {row['date']} {row['timestamp']} - Close: ${row['close']:.2f}\")\n",
    "\n",
    "# # Verify we have proper hourly intervals\n",
    "# hourly_count = (time_diffs == pd.Timedelta(hours=1)).sum()\n",
    "# total_intervals = len(time_diffs)\n",
    "# hourly_percentage = (hourly_count / total_intervals * 100) if total_intervals > 0 else 0\n",
    "\n",
    "# print(f\"\\\\n‚úÖ Hourly intervals: {hourly_count:,} / {total_intervals:,} ({hourly_percentage:.1f}%)\")\n",
    "\n",
    "# if hourly_percentage > 90:\n",
    "#     print(\"‚úÖ Data confirmed as hourly timeframe\")\n",
    "# elif hourly_percentage > 50:\n",
    "#     print(\"‚ö†Ô∏è Mixed timeframe data detected\") \n",
    "# else:\n",
    "#     print(\"‚ùå Data does not appear to be hourly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
