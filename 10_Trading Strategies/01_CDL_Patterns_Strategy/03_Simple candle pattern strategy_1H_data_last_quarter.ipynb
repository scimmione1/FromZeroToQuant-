{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3465ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import backtrader as bt\n",
    "import backtrader.feeds as btfeeds\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1345ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install TA-Lib if not available\n",
    "# try:\n",
    "#     import talib\n",
    "#     print(\"âœ“ TA-Lib is available\")\n",
    "# except ImportError:\n",
    "#     print(\"Installing TA-Lib...\")\n",
    "#     import subprocess\n",
    "#     import sys\n",
    "    \n",
    "#     # Try to install TA-Lib\n",
    "#     try:\n",
    "#         subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"TA-Lib\"])\n",
    "#         import talib\n",
    "#         print(\"âœ“ TA-Lib installed successfully\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"âŒ Failed to install TA-Lib: {e}\")\n",
    "#         print(\"ğŸ’¡ Please install TA-Lib manually:\")\n",
    "#         print(\"   conda install -c conda-forge ta-lib\")\n",
    "#         print(\"   or download from: https://www.lfd.uci.edu/~gohlke/pythonlibs/#ta-lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "406d4cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_conditions = {\n",
    "        'bullish_reversal_patterns': [\n",
    "            'CDLHAMMER',              # Hammer\n",
    "            'CDLINVERTEDHAMMER',      # Inverted Hammer\n",
    "            'CDLMORNINGSTAR',         # Morning Star\n",
    "            'CDLMORNINGDOJISTAR',     # Morning Doji Star\n",
    "            'CDLENGULFING',           # Bullish Engulfing\n",
    "            'CDLPIERCING',            # Piercing Pattern\n",
    "            'CDLHARAMI',              # Bullish Harami\n",
    "            'CDLHARAMICROSS',         # Bullish Harami Cross\n",
    "            'CDLTAKURI',              # Takuri (Dragonfly Doji)\n",
    "        ],\n",
    "        \n",
    "        'bullish_continuation_patterns': [\n",
    "            'CDL3WHITESOLDIERS',      # Three White Soldiers\n",
    "            'CDLRISEFALL3METHODS',    # Rising Three Methods\n",
    "            'CDLMATHOLD',             # Mat Hold\n",
    "            'CDLSEPARATINGLINES',     # Bullish Separating Lines\n",
    "            'CDLTASUKIGAP',           # Bullish Tasuki Gap uptrend\n",
    "        ],\n",
    "        \n",
    "        'bullish_bottom_patterns': [\n",
    "            'CDLABANDONEDBABY',       # Abandoned Baby\n",
    "            'CDLLADDERBOTTOM',        # Ladder Bottom\n",
    "            'CDLMATCHINGLOW',         # Matching Low\n",
    "            'CDLUNIQUE3RIVER',        # Unique Three River\n",
    "        ],\n",
    "        \n",
    "        'bullish_special_patterns': [\n",
    "            'CDL3INSIDE',             # Three Inside Up\n",
    "            'CDL3OUTSIDE',            # Three Outside Up\n",
    "            'CDLBELTHOLD',            # Belt Hold\n",
    "            'CDLBREAKAWAY',           # Breakaway\n",
    "            'CDLKICKING',             # Kicking\n",
    "            'CDLKICKINGBYLENGTH',     # Kicking By Length\n",
    "            'CDLSTICKSANDWICH',       # Stick Sandwich\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ebcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Long_Candlesticks Strategy created - using TA-Lib candlestick patterns!\n"
     ]
    }
   ],
   "source": [
    "# Strategy Candlestick Patterns - FIXED VERSION with Proper Risk Management\n",
    "\n",
    "class Long_Candlesticks(bt.Strategy):\n",
    "    \"\"\"\n",
    "    Strategy focusing on long candlestick patterns for trade entries\n",
    "    Entry signals based on bullish patterns using TA-Lib candlestick functions\n",
    "    \n",
    "    DESIGNED FOR HOURLY DATA (1H timeframe)\n",
    "    Stop-loss and take-profit based on ATR\n",
    "    \n",
    "    Expected data: S&P 500 hourly OHLCV bars\n",
    "    Timeframe: 1H (hourly candles)\n",
    "    \"\"\"\n",
    "    \n",
    "    params = (\n",
    "        ('printlog', True),  # Enable logging to debug issues\n",
    "        ('atr_period', 14),\n",
    "        ('atr_sl_multiplier', 2.0),\n",
    "        ('atr_tp_multiplier', 3.0),\n",
    "        ('position_pct', 0.05),  # Use only 5% of portfolio per trade for safety\n",
    "        ('max_trades', 10),  # Limit total number of trades\n",
    "        ('lookback_period', 50),  # Number of bars to look back for pattern detection\n",
    "    )\n",
    "\n",
    "    def __init__(self):\n",
    "        # ATR for stop-loss and take-profit calculations\n",
    "        self.atr = bt.indicators.ATR(self.data, period=self.p.atr_period)\n",
    "\n",
    "        self.stop_loss = None\n",
    "        self.take_profit = None\n",
    "        \n",
    "        self.order = None\n",
    "        self.trade_count = 0\n",
    "        \n",
    "        # Store OHLC data for TA-Lib calculations\n",
    "        self.open_data = []\n",
    "        self.high_data = []\n",
    "        self.low_data = []\n",
    "        self.close_data = []\n",
    "\n",
    "    def log(self, txt, dt=None, doprint=False):\n",
    "        if self.params.printlog or doprint:\n",
    "            dt = dt or self.datas[0].datetime.date(0)\n",
    "            print(f'{dt.isoformat()}, {txt}')\n",
    "\n",
    "    def notify_order(self, order):\n",
    "        if order.status in [order.Completed]:\n",
    "            if order.isbuy():\n",
    "                self.log(f'BUY EXECUTED, Price: {order.executed.price:.2f}')\n",
    "            else:\n",
    "                self.log(f'SELL EXECUTED, Price: {order.executed.price:.2f}')\n",
    "        self.order = None\n",
    "\n",
    "    def notify_trade(self, trade):\n",
    "        if not trade.isclosed:\n",
    "            return\n",
    "        self.trade_count += 1\n",
    "        self.log(f'TRADE #{self.trade_count}: PROFIT {trade.pnl:.2f}', doprint=True)\n",
    "\n",
    "    def check_bullish_patterns(self, open_prices, high_prices, low_prices, close_prices):\n",
    "        \"\"\"Check for bullish candlestick patterns using TA-Lib\"\"\"\n",
    "        bullish_signals = []\n",
    "        \n",
    "        try:\n",
    "            # Convert to numpy arrays\n",
    "            open_arr = np.array(open_prices, dtype=np.float64)\n",
    "            high_arr = np.array(high_prices, dtype=np.float64)\n",
    "            low_arr = np.array(low_prices, dtype=np.float64)\n",
    "            close_arr = np.array(close_prices, dtype=np.float64)\n",
    "            \n",
    "            # Check bullish reversal patterns\n",
    "            hammer = talib.CDLHAMMER(open_arr, high_arr, low_arr, close_arr)\n",
    "            inverted_hammer = talib.CDLINVERTEDHAMMER(open_arr, high_arr, low_arr, close_arr)\n",
    "            morning_star = talib.CDLMORNINGSTAR(open_arr, high_arr, low_arr, close_arr)\n",
    "            morning_doji = talib.CDLMORNINGDOJISTAR(open_arr, high_arr, low_arr, close_arr)\n",
    "            engulfing = talib.CDLENGULFING(open_arr, high_arr, low_arr, close_arr)\n",
    "            piercing = talib.CDLPIERCING(open_arr, high_arr, low_arr, close_arr)\n",
    "            harami = talib.CDLHARAMI(open_arr, high_arr, low_arr, close_arr)\n",
    "\n",
    "            # added patterns\n",
    "            takuri = talib.CDLTAKURI(open_arr, high_arr, low_arr, close_arr)  # Takuri (Dragonfly Doji)\n",
    "            rise_fall = talib.CDLRISEFALL3METHODS(open_arr, high_arr, low_arr, close_arr)  # Rising Three Methods\n",
    "            mat_hold = talib.CDLMATHOLD(open_arr, high_arr, low_arr, close_arr)  # Mat Hold\n",
    "            separating_lines = talib.CDLSEPARATINGLINES(open_arr, high_arr, low_arr, close_arr)  # Bullish Separating Lines\n",
    "            tasuki_gap = talib.CDLTASUKIGAP(open_arr, high_arr, low_arr, close_arr)  # Bullish Tasuki Gap uptrend\n",
    "            abandoned_baby = talib.CDLABANDONEDBABY(open_arr, high_arr, low_arr, close_arr)  # Abandoned Baby\n",
    "            ladder_bottom = talib.CDLLADDERBOTTOM(open_arr, high_arr, low_arr, close_arr)  # Ladder Bottom\n",
    "            matching_low = talib.CDLMATCHINGLOW(open_arr, high_arr, low_arr, close_arr)  # Matching Low\n",
    "            unique_three_river = talib.CDLUNIQUE3RIVER(open_arr, high_arr, low_arr, close_arr)  # Unique Three River\n",
    "            three_inside = talib.CDL3INSIDE(open_arr, high_arr, low_arr, close_arr)  # Three Inside Up\n",
    "            three_outside = talib.CDL3OUTSIDE(open_arr, high_arr, low_arr, close_arr)  # Three Outside Up\n",
    "            belt_hold = talib.CDLBELTHOLD(open_arr, high_arr, low_arr, close_arr)  # Belt Hold\n",
    "            breakaway = talib.CDLBREAKAWAY(open_arr, high_arr, low_arr, close_arr)  # Breakaway\n",
    "            kicking = talib.CDLKICKING(open_arr, high_arr, low_arr, close_arr)  # Kicking\n",
    "            kicking_by_length = talib.CDLKICKINGBYLENGTH(open_arr, high_arr, low_arr, close_arr)  # Kicking By Length\n",
    "            sticks_sandwich = talib.CDLSTICKSANDWICH(open_arr, high_arr, low_arr, close_arr)  # Stick Sandwich\n",
    "\n",
    "            # Check bullish continuation patterns\n",
    "            three_white_soldiers = talib.CDL3WHITESOLDIERS(open_arr, high_arr, low_arr, close_arr)\n",
    "            \n",
    "            # Combine all bullish signals (positive values indicate bullish patterns)\n",
    "            patterns = [hammer, inverted_hammer, morning_star, morning_doji, \n",
    "                       engulfing, piercing, harami, three_white_soldiers, \n",
    "                       takuri, rise_fall, mat_hold, separating_lines, tasuki_gap, \n",
    "                       abandoned_baby, ladder_bottom, matching_low, unique_three_river, \n",
    "                       three_inside, three_outside, belt_hold, breakaway, kicking, \n",
    "                       kicking_by_length, sticks_sandwich]\n",
    "\n",
    "            # Check if any pattern shows a bullish signal (> 0) in the last bar\n",
    "            for pattern in patterns:\n",
    "                if len(pattern) > 0 and pattern[-1] > 0:\n",
    "                    bullish_signals.append(pattern[-1])\n",
    "            \n",
    "            return len(bullish_signals) > 0\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.log(f\"Pattern detection error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def next(self):\n",
    "        # Store current OHLC data\n",
    "        self.open_data.append(float(self.data.open[0]))\n",
    "        self.high_data.append(float(self.data.high[0]))\n",
    "        self.low_data.append(float(self.data.low[0]))\n",
    "        self.close_data.append(float(self.data.close[0]))\n",
    "        \n",
    "        # Keep only the last lookback_period bars\n",
    "        if len(self.close_data) > self.p.lookback_period:\n",
    "            self.open_data = self.open_data[-self.p.lookback_period:]\n",
    "            self.high_data = self.high_data[-self.p.lookback_period:]\n",
    "            self.low_data = self.low_data[-self.p.lookback_period:]\n",
    "            self.close_data = self.close_data[-self.p.lookback_period:]\n",
    "        # Wait for enough data for pattern detection and ATR to stabilize\n",
    "        if len(self.close_data) < 30 or len(self.data) < 60:\n",
    "            return\n",
    "            \n",
    "        # Ensure ATR has valid values\n",
    "        if not self.atr or len(self.atr) == 0 or self.atr[0] is None or np.isnan(self.atr[0]):\n",
    "            return\n",
    "\n",
    "        if self.order:\n",
    "            return\n",
    "\n",
    "        if not self.position:\n",
    "            # Check for bullish candlestick patterns\n",
    "            if self.check_bullish_patterns(self.open_data, self.high_data, \n",
    "                                         self.low_data, self.close_data):\n",
    "                self.log('BUY SIGNAL: Bullish candlestick pattern detected')\n",
    "                \n",
    "                # SAFE position sizing calculation\n",
    "                if self.trade_count >= self.p.max_trades:\n",
    "                    self.log(f'Max trades ({self.p.max_trades}) reached, skipping entry')\n",
    "                    return\n",
    "                \n",
    "                cash = self.broker.getcash()\n",
    "                portfolio_value = self.broker.getvalue()\n",
    "                price = self.data.close[0]\n",
    "                \n",
    "                # Calculate position size with multiple safety checks\n",
    "                position_value = portfolio_value * self.p.position_pct\n",
    "                max_position_value = min(position_value, cash * 0.95)  # Never use more than 95% of cash\n",
    "                size = max(1, int(max_position_value / price))  # Ensure at least 1 share\n",
    "                cost = size * price\n",
    "                \n",
    "                self.log(f'POSITION CALC: Portfolio=${portfolio_value:.2f}, Cash=${cash:.2f}, Price=${price:.2f}')\n",
    "                self.log(f'Size={size}, Cost=${cost:.2f}, Position%={self.p.position_pct*100:.1f}%')\n",
    "                \n",
    "                # Safety check: ensure we can afford the position\n",
    "                if cost <= cash and size > 0 and cost < portfolio_value * 0.2:  # Never risk more than 20%\n",
    "                    self.order = self.buy(size=size)\n",
    "                    # Set stop-loss and take-profit based on ATR\n",
    "                    self.stop_loss = price - (self.atr[0] * self.p.atr_sl_multiplier)\n",
    "                    self.take_profit = price + (self.atr[0] * self.p.atr_tp_multiplier)\n",
    "                    self.log(f'BUY ORDER: Size={size}, Price=${price:.2f}, Cost=${cost:.2f}')\n",
    "                    self.log(f'SL=${self.stop_loss:.2f}, TP=${self.take_profit:.2f}, ATR=${self.atr[0]:.2f}')\n",
    "                else:\n",
    "                    self.log(f'POSITION REJECTED: Cost=${cost:.2f} > Available=${cash:.2f} or unsafe size')\n",
    "        else:\n",
    "            # Manage existing position with ATR-based stop-loss and take-profit\n",
    "            if self.stop_loss is not None and self.data.close[0] <= self.stop_loss:\n",
    "                self.log('STOP-LOSS HIT')\n",
    "                self.order = self.sell()\n",
    "            elif self.take_profit is not None and self.data.close[0] >= self.take_profit:\n",
    "                self.log('TAKE-PROFIT HIT')\n",
    "                self.order = self.sell()\n",
    "\n",
    "    def stop(self):\n",
    "        self.log(f'Long_Candlesticks Strategy: {self.trade_count} trades, Final Value: ${self.broker.getvalue():.2f}', doprint=True)\n",
    "\n",
    "print(\"âœ“ Long_Candlesticks Strategy created - using TA-Lib candlestick patterns!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "440d9ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Manual CSV list: 6 files\n",
      "ğŸ” Auto-detected files: 6 files\n",
      "âœ… Using auto-detected files:\n",
      "  1. âœ“ USA500IDXUSD_H1_returns_2019_q4.csv\n",
      "  2. âœ“ USA500IDXUSD_H1_returns_2020_q4.csv\n",
      "  3. âœ“ USA500IDXUSD_H1_returns_2021_q4.csv\n",
      "  4. âœ“ USA500IDXUSD_H1_returns_2022_q4.csv\n",
      "  5. âœ“ USA500IDXUSD_H1_returns_2023_q4.csv\n",
      "  6. âœ“ USA500IDXUSD_H1_returns_2024_q4.csv\n",
      "\n",
      "ğŸ¯ Ready to backtest 6 quarterly datasets\n"
     ]
    }
   ],
   "source": [
    "# CSV Files List for Multi-Year Quarterly Backtesting\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# List of quarterly CSV files for backtesting\n",
    "csv_files = [\n",
    "    'USA500IDXUSD_H1_returns_2019_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2020_q4.csv', \n",
    "    'USA500IDXUSD_H1_returns_2021_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2022_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2023_q4.csv',\n",
    "    'USA500IDXUSD_H1_returns_2024_q4.csv'\n",
    "]\n",
    "\n",
    "# Automatically detect all Q4 CSV files in the data directory\n",
    "data_dir = '01_data'\n",
    "auto_detected_files = glob.glob(os.path.join(data_dir, '*_q4.csv'))\n",
    "\n",
    "print(f\"ğŸ“‚ Manual CSV list: {len(csv_files)} files\")\n",
    "print(f\"ğŸ” Auto-detected files: {len(auto_detected_files)} files\")\n",
    "\n",
    "# Use auto-detected files if available, otherwise use manual list\n",
    "if auto_detected_files:\n",
    "    csv_files = [os.path.basename(f) for f in auto_detected_files]\n",
    "    csv_files.sort()  # Sort chronologically\n",
    "    print(\"âœ… Using auto-detected files:\")\n",
    "else:\n",
    "    print(\"âœ… Using manual file list:\")\n",
    "\n",
    "for i, file in enumerate(csv_files, 1):\n",
    "    full_path = os.path.join(data_dir, file)\n",
    "    exists = \"âœ“\" if os.path.exists(full_path) else \"âŒ\"\n",
    "    print(f\"  {i}. {exists} {file}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Ready to backtest {len(csv_files)} quarterly datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51e09937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Backtest function ready for Long_Candlesticks\n"
     ]
    }
   ],
   "source": [
    "# Backtest Function for Long_Candlesticks Strategy\n",
    "\n",
    "def test_long_candlesticks_strategy(csv_filename=None):\n",
    "    \"\"\"Test the Long_Candlesticks strategy with S&P 500 quarterly data\"\"\"\n",
    "    \n",
    "    # Use provided filename or default to 2023 Q4\n",
    "    if csv_filename is None:\n",
    "        csv_filename = 'USA500IDXUSD_H1_returns_2023_q4.csv'\n",
    "    \n",
    "    print(f\"=== TESTING Long_Candlesticks on {csv_filename} ===\\n\")\n",
    "    \n",
    "    cerebro = bt.Cerebro()\n",
    "    \n",
    "    # Load S&P 500 data\n",
    "    spy_file = os.path.join('01_data', csv_filename)\n",
    "    df = pd.read_csv(spy_file)\n",
    "    \n",
    "    # Combine date and timestamp columns\n",
    "    df['DateTime'] = pd.to_datetime(df['date'] + ' ' + df['timestamp'])\n",
    "    \n",
    "    # Rename columns to match expected format\n",
    "    df = df.rename(columns={\n",
    "        'open': 'Open',\n",
    "        'high': 'High', \n",
    "        'low': 'Low',\n",
    "        'close': 'Close',\n",
    "        'volume': 'Volume'\n",
    "    })\n",
    "    \n",
    "    # Select only needed columns and use DateTime\n",
    "    df = df[['DateTime', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "    df = df.rename(columns={'DateTime': 'Date'})\n",
    "    df = df.sort_values('Date').dropna()\n",
    "    \n",
    "    # Use full quarterly dataset (Q4 data)\n",
    "    start_date = df['Date'].min()\n",
    "    end_date = df['Date'].max()\n",
    "    df_recent = df.copy()\n",
    "    \n",
    "    print(f\"ğŸ“Š Data: {len(df_recent)} hourly bars from {start_date.date()} to {end_date.date()}\")\n",
    "    print(f\"ğŸ“… Dataset: {csv_filename} (Full Q4 period)\")\n",
    "    \n",
    "    # Create temporary file for backtrader\n",
    "    temp_file = 'temp_simplified_test.csv'\n",
    "    df_recent.to_csv(temp_file, index=False)\n",
    "    \n",
    "    # Create data feed\n",
    "    data = btfeeds.GenericCSVData(\n",
    "        dataname=temp_file,\n",
    "        dtformat=('%Y-%m-%d %H:%M:%S'),\n",
    "        datetime=0, open=1, high=2, low=3, close=4, volume=5,\n",
    "        openinterest=-1, headers=True,\n",
    "    )\n",
    "\n",
    "    # Add data and strategy\n",
    "    cerebro.adddata(data)\n",
    "    cerebro.addstrategy(Long_Candlesticks, printlog=False)\n",
    "    \n",
    "    # Set initial capital and commission\n",
    "    initial_capital = 50000.0\n",
    "    cerebro.broker.setcash(initial_capital)\n",
    "    cerebro.broker.setcommission(commission=0.001)  # 0.1% commission\n",
    "    cerebro.broker.set_slippage_perc(0.01)  # 1% slippage for realism\n",
    "    \n",
    "    # Add analyzers\n",
    "    cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"trades\")\n",
    "    cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name=\"sharpe\")\n",
    "    cerebro.addanalyzer(bt.analyzers.DrawDown, _name=\"drawdown\")\n",
    "\n",
    "    print(f\"ğŸ’° Starting Capital: ${initial_capital:,.2f}\")\n",
    "    print(\"ğŸš€ Running backtest...\\n\")\n",
    "    \n",
    "    # Run backtest\n",
    "    results = cerebro.run()\n",
    "    \n",
    "    # Clean up temporary file\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)\n",
    "    \n",
    "    # Calculate results\n",
    "    final_value = cerebro.broker.getvalue()\n",
    "    total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "    \n",
    "    print(f\"\\n=== BACKTEST RESULTS ===\")\n",
    "    print(f\"ğŸ’° Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    print(f\"ğŸ“ˆ Total Return: {total_return:.2f}%\")\n",
    "    print(f\"ğŸ’µ Net Profit: ${final_value - initial_capital:,.2f}\")\n",
    "    \n",
    "    # Analyze trades\n",
    "    strat = results[0]\n",
    "    trade_analysis = strat.analyzers.trades.get_analysis()\n",
    "    \n",
    "    if trade_analysis and hasattr(trade_analysis, 'total'):\n",
    "        total_trades = getattr(trade_analysis.total, 'total', 0)\n",
    "        print(f\"\\n=== TRADE ANALYSIS ===\")\n",
    "        print(f\"ğŸ“Š Total Trades: {total_trades}\")\n",
    "        \n",
    "        # Winning trades\n",
    "        if hasattr(trade_analysis, 'won'):\n",
    "            won_trades = getattr(trade_analysis.won, 'total', 0)\n",
    "            won_pnl = getattr(trade_analysis.won, 'pnl', {}).get('total', 0)\n",
    "            win_rate = (won_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "            print(f\"âœ… Winning Trades: {won_trades} ({win_rate:.1f}%)\")\n",
    "            if won_pnl:\n",
    "                print(f\"ğŸ’° Winning PnL: ${won_pnl:.2f}\")\n",
    "        \n",
    "        # Losing trades  \n",
    "        if hasattr(trade_analysis, 'lost'):\n",
    "            lost_trades = getattr(trade_analysis.lost, 'total', 0)\n",
    "            lost_pnl = getattr(trade_analysis.lost, 'pnl', {}).get('total', 0)\n",
    "            print(f\"âŒ Losing Trades: {lost_trades}\")\n",
    "            if lost_pnl:\n",
    "                print(f\"ğŸ’¸ Losing PnL: ${lost_pnl:.2f}\")\n",
    "    \n",
    "    # Performance metrics\n",
    "    print(f\"\\n=== PERFORMANCE METRICS ===\")\n",
    "    \n",
    "    # Sharpe Ratio\n",
    "    sharpe_analysis = strat.analyzers.sharpe.get_analysis()\n",
    "    if sharpe_analysis and 'sharperatio' in sharpe_analysis:\n",
    "        sharpe_ratio = sharpe_analysis['sharperatio'] or 0\n",
    "        print(f\"ğŸ“Š Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "\n",
    "    # Drawdown Analysis\n",
    "    drawdown_analysis = strat.analyzers.drawdown.get_analysis()\n",
    "    if drawdown_analysis:\n",
    "        max_dd = drawdown_analysis.get('max', {}).get('drawdown', 0)\n",
    "        print(f\"ğŸ“‰ Max Drawdown: {max_dd:.2f}%\")\n",
    "    \n",
    "    return results, total_trades, final_value\n",
    "\n",
    "print(\"âœ“ Backtest function ready for Long_Candlesticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cd38550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Multi-file backtesting function ready!\n"
     ]
    }
   ],
   "source": [
    "# Multi-File Backtesting Function\n",
    "\n",
    "def run_multi_file_backtests(csv_files_list):\n",
    "    \"\"\"Run backtests on multiple CSV files and collect comprehensive results\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ STARTING MULTI-FILE BACKTESTING CAMPAIGN\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    all_results = {}\n",
    "    summary_data = []\n",
    "    \n",
    "    for i, csv_file in enumerate(csv_files_list, 1):\n",
    "        print(f\"\\nğŸ“Š BACKTEST {i}/{len(csv_files_list)}: {csv_file}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        try:\n",
    "            # Check if file exists\n",
    "            full_path = os.path.join('01_data', csv_file)\n",
    "            if not os.path.exists(full_path):\n",
    "                print(f\"âŒ File not found: {csv_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Run individual backtest\n",
    "            results, trade_count, final_value = test_long_candlesticks_strategy(csv_file)\n",
    "            \n",
    "            # Extract detailed analytics\n",
    "            strat = results[0]\n",
    "            trade_analysis = strat.analyzers.trades.get_analysis()\n",
    "            sharpe_analysis = strat.analyzers.sharpe.get_analysis()\n",
    "            drawdown_analysis = strat.analyzers.drawdown.get_analysis()\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            initial_capital = 50000.0\n",
    "            total_return = ((final_value - initial_capital) / initial_capital) * 100\n",
    "            net_profit = final_value - initial_capital\n",
    "            \n",
    "            # Extract trade statistics\n",
    "            total_trades = getattr(trade_analysis.total, 'total', 0) if hasattr(trade_analysis, 'total') else 0\n",
    "            won_trades = getattr(trade_analysis.won, 'total', 0) if hasattr(trade_analysis, 'won') else 0\n",
    "            lost_trades = getattr(trade_analysis.lost, 'total', 0) if hasattr(trade_analysis, 'lost') else 0\n",
    "            win_rate = (won_trades / total_trades * 100) if total_trades > 0 else 0\n",
    "            \n",
    "            won_pnl = getattr(trade_analysis.won, 'pnl', {}).get('total', 0) if hasattr(trade_analysis, 'won') else 0\n",
    "            lost_pnl = getattr(trade_analysis.lost, 'pnl', {}).get('total', 0) if hasattr(trade_analysis, 'lost') else 0\n",
    "            \n",
    "            sharpe_ratio = sharpe_analysis.get('sharperatio', 0) if sharpe_analysis else 0\n",
    "            max_drawdown = drawdown_analysis.get('max', {}).get('drawdown', 0) if drawdown_analysis else 0\n",
    "            \n",
    "            # Store results\n",
    "            file_result = {\n",
    "                'csv_file': csv_file,\n",
    "                'final_value': final_value,\n",
    "                'total_return_pct': total_return,\n",
    "                'net_profit': net_profit,\n",
    "                'total_trades': total_trades,\n",
    "                'won_trades': won_trades,\n",
    "                'lost_trades': lost_trades,\n",
    "                'win_rate_pct': win_rate,\n",
    "                'won_pnl': won_pnl,\n",
    "                'lost_pnl': lost_pnl,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'max_drawdown_pct': max_drawdown\n",
    "            }\n",
    "            \n",
    "            all_results[csv_file] = file_result\n",
    "            summary_data.append(file_result)\n",
    "            \n",
    "            # Print results for this file\n",
    "            print(f\"\\nğŸ“ˆ DETAILED RESULTS FOR {csv_file}:\")\n",
    "            print(f\"ğŸ’° Final Value: ${final_value:,.2f}\")\n",
    "            print(f\"ğŸ“Š Total Return: {total_return:.2f}%\")\n",
    "            print(f\"ğŸ’µ Net Profit: ${net_profit:,.2f}\")\n",
    "            print(f\"ğŸ“ˆ Total Trades: {total_trades}\")\n",
    "            print(f\"âœ… Won: {won_trades} ({win_rate:.1f}%) | PnL: ${won_pnl:.2f}\")\n",
    "            print(f\"âŒ Lost: {lost_trades} | PnL: ${lost_pnl:.2f}\")\n",
    "            print(f\"ğŸ“Š Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "            print(f\"ğŸ“‰ Max Drawdown: {max_drawdown:.2f}%\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ERROR in {csv_file}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print(f\"\\n\\nğŸ¯ COMPREHENSIVE BACKTESTING SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    if summary_data:\n",
    "        total_files = len(summary_data)\n",
    "        avg_return = sum(d['total_return_pct'] for d in summary_data) / total_files\n",
    "        avg_trades = sum(d['total_trades'] for d in summary_data) / total_files\n",
    "        avg_win_rate = sum(d['win_rate_pct'] for d in summary_data) / total_files\n",
    "        avg_sharpe = sum(d['sharpe_ratio'] for d in summary_data) / total_files\n",
    "        avg_drawdown = sum(d['max_drawdown_pct'] for d in summary_data) / total_files\n",
    "        \n",
    "        best_performer = max(summary_data, key=lambda x: x['total_return_pct'])\n",
    "        worst_performer = min(summary_data, key=lambda x: x['total_return_pct'])\n",
    "        \n",
    "        print(f\"ğŸ“Š Backtested Files: {total_files}\")\n",
    "        print(f\"ğŸ“ˆ Average Return: {avg_return:.2f}%\")\n",
    "        print(f\"ğŸ”¢ Average Trades per Quarter: {avg_trades:.1f}\")\n",
    "        print(f\"ğŸ¯ Average Win Rate: {avg_win_rate:.1f}%\")\n",
    "        print(f\"ğŸ“Š Average Sharpe Ratio: {avg_sharpe:.4f}\")\n",
    "        print(f\"ğŸ“‰ Average Max Drawdown: {avg_drawdown:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nğŸ† BEST PERFORMER:\")\n",
    "        print(f\"   ğŸ“ {best_performer['csv_file']}\")\n",
    "        print(f\"   ğŸ“ˆ Return: {best_performer['total_return_pct']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‰ WORST PERFORMER:\")\n",
    "        print(f\"   ğŸ“ {worst_performer['csv_file']}\")\n",
    "        print(f\"   ğŸ“ˆ Return: {worst_performer['total_return_pct']:.2f}%\")\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ DETAILED PERFORMANCE TABLE:\")\n",
    "        print(\"-\" * 100)\n",
    "        print(f\"{'File':<35} {'Return %':<10} {'Trades':<8} {'Win %':<8} {'Sharpe':<10} {'DD %':<8}\")\n",
    "        print(\"-\" * 100)\n",
    "        \n",
    "        for data in summary_data:\n",
    "            print(f\"{data['csv_file']:<35} {data['total_return_pct']:>8.2f}% {data['total_trades']:>6.0f}   {data['win_rate_pct']:>6.1f}%  {data['sharpe_ratio']:>8.4f}  {data['max_drawdown_pct']:>6.2f}%\")\n",
    "    \n",
    "    else:\n",
    "        print(\"âŒ No successful backtests completed\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "print(\"âœ… Multi-file backtesting function ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d30174e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2023_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1463 hourly bars from 2023-10-02 to 2023-12-29\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2023_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2023-10-09, TRADE #1: PROFIT 38.23\n",
      "2023-12-29, Long_Candlesticks Strategy: 1 trades, Final Value: $-289181.38\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $-289,181.38\n",
      "ğŸ“ˆ Total Return: -678.36%\n",
      "ğŸ’µ Net Profit: $-339,181.38\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 1 (50.0%)\n",
      "ğŸ’° Winning PnL: $12.65\n",
      "âŒ Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 430.42%\n",
      "\n",
      "ğŸ‰ BACKTEST COMPLETED SUCCESSFULLY!\n",
      "ğŸ“Š Summary: 2 trades, Final Value: $-289,181.38\n",
      "ğŸ“ˆ Strategy executed multiple trades\n"
     ]
    }
   ],
   "source": [
    "# Execute Long_Candlesticks Backtest\n",
    "try:\n",
    "    results, trade_count, final_value = test_long_candlesticks_strategy()\n",
    "    \n",
    "    print(f\"\\nğŸ‰ BACKTEST COMPLETED SUCCESSFULLY!\")\n",
    "    print(f\"ğŸ“Š Summary: {trade_count} trades, Final Value: ${final_value:,.2f}\")\n",
    "    \n",
    "    if trade_count > 10:\n",
    "        print(\"âœ… Strategy shows active trading with multiple trades\")\n",
    "    elif trade_count > 1:\n",
    "        print(\"ğŸ“ˆ Strategy executed multiple trades\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Strategy was very selective with few trades\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error running backtest: {str(e)}\")\n",
    "    print(\"ğŸ’¡ Make sure the S&P 500 data file exists at the specified path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481bdfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ LAUNCHING COMPREHENSIVE QUARTERLY BACKTESTING\n",
      "ğŸ”„ This will run the Long_Candlesticks strategy on each Q4 dataset\n",
      "â° Please wait while processing multiple datasets...\n",
      "\n",
      "ğŸš€ STARTING MULTI-FILE BACKTESTING CAMPAIGN\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š BACKTEST 1/6: USA500IDXUSD_H1_returns_2019_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2019_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1485 hourly bars from 2019-10-01 to 2019-12-31\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2019_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2019-10-07, TRADE #1: PROFIT 36.80\n",
      "2019-12-31, Long_Candlesticks Strategy: 1 trades, Final Value: $-134462.92\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $-134,462.92\n",
      "ğŸ“ˆ Total Return: -368.93%\n",
      "ğŸ’µ Net Profit: $-184,462.92\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 1 (50.0%)\n",
      "ğŸ’° Winning PnL: $25.11\n",
      "âŒ Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 403.76%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2019_q4.csv:\n",
      "ğŸ’° Final Value: $-134,462.92\n",
      "ğŸ“Š Total Return: -368.93%\n",
      "ğŸ’µ Net Profit: $-184,462.92\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 1 (50.0%) | PnL: $25.11\n",
      "âŒ Lost: 0 | PnL: $0.00\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2019_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "ğŸ“Š BACKTEST 2/6: USA500IDXUSD_H1_returns_2020_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2020_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1485 hourly bars from 2020-10-01 to 2020-12-31\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2020_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2020-10-08, TRADE #1: PROFIT -183.32\n",
      "2020-12-31, Long_Candlesticks Strategy: 1 trades, Final Value: $-181728.03\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $-181,728.03\n",
      "ğŸ“ˆ Total Return: -463.46%\n",
      "ğŸ’µ Net Profit: $-231,728.03\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 0 (0.0%)\n",
      "âŒ Losing Trades: 1\n",
      "ğŸ’¸ Losing PnL: $-210.38\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 273.07%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2020_q4.csv:\n",
      "ğŸ’° Final Value: $-181,728.03\n",
      "ğŸ“Š Total Return: -463.46%\n",
      "ğŸ’µ Net Profit: $-231,728.03\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 0 (0.0%) | PnL: $0.00\n",
      "âŒ Lost: 1 | PnL: $-210.38\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2020_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "ğŸ“Š BACKTEST 3/6: USA500IDXUSD_H1_returns_2021_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2021_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1488 hourly bars from 2021-10-01 to 2021-12-31\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2021_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2021-10-07, TRADE #1: PROFIT 16.33\n",
      "2021-12-31, Long_Candlesticks Strategy: 1 trades, Final Value: $-132248.24\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $-132,248.24\n",
      "ğŸ“ˆ Total Return: -364.50%\n",
      "ğŸ’µ Net Profit: $-182,248.24\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 1 (50.0%)\n",
      "ğŸ’° Winning PnL: $7.62\n",
      "âŒ Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 223.94%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2021_q4.csv:\n",
      "ğŸ’° Final Value: $-132,248.24\n",
      "ğŸ“Š Total Return: -364.50%\n",
      "ğŸ’µ Net Profit: $-182,248.24\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 1 (50.0%) | PnL: $7.62\n",
      "âŒ Lost: 0 | PnL: $0.00\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2021_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "ğŸ“Š BACKTEST 4/6: USA500IDXUSD_H1_returns_2022_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2022_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1463 hourly bars from 2022-10-03 to 2022-12-30\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2022_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2022-10-07, TRADE #1: PROFIT -115.88\n",
      "2022-12-30, Long_Candlesticks Strategy: 1 trades, Final Value: $70630.49\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $70,630.49\n",
      "ğŸ“ˆ Total Return: 41.26%\n",
      "ğŸ’µ Net Profit: $20,630.49\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 0 (0.0%)\n",
      "âŒ Losing Trades: 1\n",
      "ğŸ’¸ Losing PnL: $-130.92\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 392.52%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2022_q4.csv:\n",
      "ğŸ’° Final Value: $70,630.49\n",
      "ğŸ“Š Total Return: 41.26%\n",
      "ğŸ’µ Net Profit: $20,630.49\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 0 (0.0%) | PnL: $0.00\n",
      "âŒ Lost: 1 | PnL: $-130.92\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2022_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "ğŸ“Š BACKTEST 5/6: USA500IDXUSD_H1_returns_2023_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2023_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1463 hourly bars from 2023-10-02 to 2023-12-29\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2023_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2023-10-09, TRADE #1: PROFIT 38.23\n",
      "2023-12-29, Long_Candlesticks Strategy: 1 trades, Final Value: $-289181.38\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $-289,181.38\n",
      "ğŸ“ˆ Total Return: -678.36%\n",
      "ğŸ’µ Net Profit: $-339,181.38\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 1 (50.0%)\n",
      "ğŸ’° Winning PnL: $12.65\n",
      "âŒ Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 430.42%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2023_q4.csv:\n",
      "ğŸ’° Final Value: $-289,181.38\n",
      "ğŸ“Š Total Return: -678.36%\n",
      "ğŸ’µ Net Profit: $-339,181.38\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 1 (50.0%) | PnL: $12.65\n",
      "âŒ Lost: 0 | PnL: $0.00\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2023_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "ğŸ“Š BACKTEST 6/6: USA500IDXUSD_H1_returns_2024_q4.csv\n",
      "--------------------------------------------------\n",
      "=== TESTING Long_Candlesticks on USA500IDXUSD_H1_returns_2024_q4.csv ===\n",
      "\n",
      "ğŸ“Š Data: 1485 hourly bars from 2024-10-01 to 2024-12-31\n",
      "ğŸ“… Dataset: USA500IDXUSD_H1_returns_2024_q4.csv (Full Q4 period)\n",
      "ğŸ’° Starting Capital: $50,000.00\n",
      "ğŸš€ Running backtest...\n",
      "\n",
      "2024-10-08, TRADE #1: PROFIT 93.95\n",
      "2024-12-31, Long_Candlesticks Strategy: 1 trades, Final Value: $102225.39\n",
      "\n",
      "=== BACKTEST RESULTS ===\n",
      "ğŸ’° Final Portfolio Value: $102,225.39\n",
      "ğŸ“ˆ Total Return: 104.45%\n",
      "ğŸ’µ Net Profit: $52,225.39\n",
      "\n",
      "=== TRADE ANALYSIS ===\n",
      "ğŸ“Š Total Trades: 2\n",
      "âœ… Winning Trades: 1 (50.0%)\n",
      "ğŸ’° Winning PnL: $36.83\n",
      "âŒ Losing Trades: 0\n",
      "\n",
      "=== PERFORMANCE METRICS ===\n",
      "ğŸ“Š Sharpe Ratio: 0.0000\n",
      "ğŸ“‰ Max Drawdown: 236.53%\n",
      "\n",
      "ğŸ“ˆ DETAILED RESULTS FOR USA500IDXUSD_H1_returns_2024_q4.csv:\n",
      "ğŸ’° Final Value: $102,225.39\n",
      "ğŸ“Š Total Return: 104.45%\n",
      "ğŸ’µ Net Profit: $52,225.39\n",
      "ğŸ“ˆ Total Trades: 2\n",
      "âœ… Won: 1 (50.0%) | PnL: $36.83\n",
      "âŒ Lost: 0 | PnL: $0.00\n",
      "âŒ ERROR in USA500IDXUSD_H1_returns_2024_q4.csv: unsupported format string passed to NoneType.__format__\n",
      "\n",
      "\n",
      "ğŸ¯ COMPREHENSIVE BACKTESTING SUMMARY\n",
      "======================================================================\n",
      "âŒ Error in multi-file backtesting: unsupported operand type(s) for +: 'int' and 'NoneType'\n",
      "ğŸ’¡ Check that all CSV files exist in the 01_data directory\n",
      "ğŸ” You can also run individual backtests by calling:\n",
      "   test_long_candlesticks_strategy('specific_file.csv')\n"
     ]
    }
   ],
   "source": [
    "# # Execute Multi-File Backtesting Campaign\n",
    "\n",
    "# # Run backtests on all quarterly CSV files\n",
    "# print(\"ğŸ¯ LAUNCHING COMPREHENSIVE QUARTERLY BACKTESTING\")\n",
    "# print(\"ğŸ”„ This will run the Long_Candlesticks strategy on each Q4 dataset\")\n",
    "# print(\"â° Please wait while processing multiple datasets...\\n\")\n",
    "\n",
    "# try:\n",
    "#     # Execute the multi-file backtesting\n",
    "#     all_backtest_results = run_multi_file_backtests(csv_files)\n",
    "    \n",
    "#     print(f\"\\nğŸ‰ MULTI-FILE BACKTESTING COMPLETED!\")\n",
    "#     print(f\"ğŸ“Š Successfully processed {len(all_backtest_results)} datasets\")\n",
    "    \n",
    "#     # Additional insights\n",
    "#     if all_backtest_results:\n",
    "#         profitable_quarters = sum(1 for result in all_backtest_results.values() \n",
    "#                                  if result['total_return_pct'] > 0)\n",
    "#         total_quarters = len(all_backtest_results)\n",
    "#         profitability_rate = (profitable_quarters / total_quarters * 100) if total_quarters > 0 else 0\n",
    "        \n",
    "#         print(f\"ğŸ’° Profitable Quarters: {profitable_quarters}/{total_quarters} ({profitability_rate:.1f}%)\")\n",
    "        \n",
    "#         # Strategy consistency analysis\n",
    "#         returns = [result['total_return_pct'] for result in all_backtest_results.values()]\n",
    "#         avg_return = sum(returns) / len(returns) if returns else 0\n",
    "#         return_std = np.std(returns) if returns else 0\n",
    "        \n",
    "#         print(f\"ğŸ“ˆ Return Statistics:\")\n",
    "#         print(f\"   â€¢ Average: {avg_return:.2f}%\")\n",
    "#         print(f\"   â€¢ Std Dev: {return_std:.2f}%\")\n",
    "#         print(f\"   â€¢ Range: {min(returns):.2f}% to {max(returns):.2f}%\")\n",
    "        \n",
    "#         # Trading activity analysis\n",
    "#         trade_counts = [result['total_trades'] for result in all_backtest_results.values()]\n",
    "#         avg_trades = sum(trade_counts) / len(trade_counts) if trade_counts else 0\n",
    "        \n",
    "#         print(f\"ğŸ”¢ Trading Activity:\")\n",
    "#         print(f\"   â€¢ Average trades per quarter: {avg_trades:.1f}\")\n",
    "#         print(f\"   â€¢ Total trades across all quarters: {sum(trade_counts)}\")\n",
    "        \n",
    "#         print(f\"\\nâœ… Long_Candlesticks strategy analysis complete across {len(csv_files)} quarterly periods\")\n",
    "    \n",
    "# except Exception as e:\n",
    "#     print(f\"âŒ Error in multi-file backtesting: {str(e)}\")\n",
    "#     print(\"ğŸ’¡ Check that all CSV files exist in the 01_data directory\")\n",
    "#     print(\"ğŸ” You can also run individual backtests by calling:\")\n",
    "#     print(\"   test_long_candlesticks_strategy('specific_file.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d69075",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '01_data\\\\USA500IDXUSD_H1_returns_2019-2024_q4.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Quick data validation\u001b[39;00m\n\u001b[32m      6\u001b[39m spy_file = os.path.join(\u001b[33m'\u001b[39m\u001b[33m01_data\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUSA500IDXUSD_H1_returns_2019-2024_q4.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspy_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== HOURLY DATA VALIDATION ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š Total records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\bt\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m    876\u001b[39m             encoding=ioargs.encoding,\n\u001b[32m    877\u001b[39m             errors=errors,\n\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '01_data\\\\USA500IDXUSD_H1_returns_2019-2024_q4.csv'"
     ]
    }
   ],
   "source": [
    "# # Validate Hourly Data Structure\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Quick data validation\n",
    "# spy_file = os.path.join('01_data', 'USA500IDXUSD_H1_returns_2019-2024_q4.csv')\n",
    "# df = pd.read_csv(spy_file)\n",
    "\n",
    "# print(\"=== HOURLY DATA VALIDATION ===\")\n",
    "# print(f\"ğŸ“Š Total records: {len(df):,}\")\n",
    "# print(f\"ğŸ“… Date range: {df.date.min()} to {df.date.max()}\")\n",
    "\n",
    "# # Check time intervals\n",
    "# df['DateTime'] = pd.to_datetime(df['date'] + ' ' + df['timestamp'])\n",
    "# df_sorted = df.sort_values('DateTime')\n",
    "\n",
    "# # Calculate time differences between consecutive bars\n",
    "# time_diffs = df_sorted['DateTime'].diff().dropna()\n",
    "# most_common_diff = time_diffs.mode().iloc[0] if len(time_diffs) > 0 else None\n",
    "\n",
    "# print(f\"ğŸ• Most common time interval: {most_common_diff}\")\n",
    "# print(f\"ğŸ“ˆ Price range: ${df.close.min():.2f} - ${df.close.max():.2f}\")\n",
    "\n",
    "# # Show sample of hourly progression\n",
    "# print(f\"\\\\nğŸ” Sample hourly data progression:\")\n",
    "# sample = df_sorted[['date', 'timestamp', 'close']].head(10)\n",
    "# for idx, row in sample.iterrows():\n",
    "#     print(f\"  {row['date']} {row['timestamp']} - Close: ${row['close']:.2f}\")\n",
    "\n",
    "# # Verify we have proper hourly intervals\n",
    "# hourly_count = (time_diffs == pd.Timedelta(hours=1)).sum()\n",
    "# total_intervals = len(time_diffs)\n",
    "# hourly_percentage = (hourly_count / total_intervals * 100) if total_intervals > 0 else 0\n",
    "\n",
    "# print(f\"\\\\nâœ… Hourly intervals: {hourly_count:,} / {total_intervals:,} ({hourly_percentage:.1f}%)\")\n",
    "\n",
    "# if hourly_percentage > 90:\n",
    "#     print(\"âœ… Data confirmed as hourly timeframe\")\n",
    "# elif hourly_percentage > 50:\n",
    "#     print(\"âš ï¸ Mixed timeframe data detected\") \n",
    "# else:\n",
    "#     print(\"âŒ Data does not appear to be hourly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
