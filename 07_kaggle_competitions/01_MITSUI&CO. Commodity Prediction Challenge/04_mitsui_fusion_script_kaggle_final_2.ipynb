{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ULTRA-FAST KAGGLE SUBMISSION VERSION ==== #\n",
    "# Optimized for <480 minute time limit\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pickle\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle evaluation - ENABLED FOR SUBMISSION\n",
    "import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "# ==== ULTRA-FAST Configuration for Kaggle ==== #\n",
    "class FastConfig:\n",
    "    \"\"\"Ultra-fast configuration optimized for speed\"\"\"\n",
    "    NUM_TARGET_COLUMNS = 424\n",
    "    RANDOM_STATE = 42\n",
    "    CV_FOLDS = 1  # Minimal cross-validation for speed\n",
    "    \n",
    "    # Ultra-fast model parameters\n",
    "    LGBM_PARAMS_FAST = {\n",
    "        'n_estimators': 15,         # Drastically reduced\n",
    "        'learning_rate': 0.3,       # Higher for faster convergence\n",
    "        'num_leaves': 10,           # Minimal complexity\n",
    "        'max_depth': 3,             # Shallow trees\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': 1,                # Single thread to avoid overhead\n",
    "        'force_row_wise': True,\n",
    "        'min_child_samples': 100,   # Faster training\n",
    "        'subsample': 0.7,           # Speed up training\n",
    "        'feature_fraction': 0.7,\n",
    "    }\n",
    "    \n",
    "    # Minimal feature engineering\n",
    "    ROLLING_WINDOWS = [5]  # Single window only\n",
    "    LAG_PERIODS = [1]      # Single lag only\n",
    "    \n",
    "    # Ultra-fast training configuration\n",
    "    MAX_COMPLEX_MODELS = 0       # No stacking - too slow\n",
    "    MAX_SIMPLE_MODELS = 8        # Minimal LightGBM models\n",
    "    MIN_SAMPLES_REQUIRED = 200   # Higher threshold\n",
    "    \n",
    "    # Minimal validation\n",
    "    EARLY_STOPPING_ROUNDS = 5\n",
    "    VALIDATION_SPLIT = 0.1       # Smaller validation\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_data_path():\n",
    "        kaggle_path = Path('/kaggle/input/mitsui-commodity-prediction-challenge')\n",
    "        local_path = Path(\"dataset\")\n",
    "        \n",
    "        if kaggle_path.exists():\n",
    "            print(\"ðŸš€ Kaggle environment detected - SPEED MODE\")\n",
    "            return kaggle_path\n",
    "        else:\n",
    "            print(\"ðŸš€ Local development - SPEED MODE\")\n",
    "            return local_path\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_lgbm_params():\n",
    "        return FastConfig.LGBM_PARAMS_FAST.copy()\n",
    "\n",
    "CFG = FastConfig()\n",
    "data_path = CFG.get_data_path()\n",
    "\n",
    "# ==== MINIMAL Feature Engineering Pipeline ==== #\n",
    "class FastFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Ultra-fast feature engineering - minimal features only\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_names_ = []\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = [c for c in X.columns if c != 'date_id']\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return self._create_minimal_features(X.copy())\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X, y).transform(X)\n",
    "    \n",
    "    def _create_minimal_features(self, df):\n",
    "        \"\"\"Create only essential features for speed\"\"\"\n",
    "        feature_cols = [c for c in df.columns if c != 'date_id']\n",
    "        \n",
    "        # Only create 3 features per column for speed\n",
    "        for col in feature_cols:\n",
    "            try:\n",
    "                # Most essential features only\n",
    "                df[f'{col}_ma5'] = df[col].rolling(5).mean()\n",
    "                df[f'{col}_pct'] = df[col].pct_change()\n",
    "                df[f'{col}_lag1'] = df[col].shift(1)\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        df = df.fillna(0)\n",
    "        print(f\"âš¡ Fast features: {len(df.columns) - len(feature_cols)} added\")\n",
    "        return df\n",
    "\n",
    "# ==== ULTRA-FAST Model Management ==== #\n",
    "class FastModelManager:\n",
    "    \"\"\"Ultra-fast model management\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_columns = {}\n",
    "        \n",
    "    def calculate_target_importance_fast(self, train_labels_df):\n",
    "        \"\"\"Vectorized importance calculation\"\"\"\n",
    "        target_columns = [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "        \n",
    "        # Vectorized - much faster than loops\n",
    "        variances = train_labels_df[target_columns].var()\n",
    "        non_null_ratios = train_labels_df[target_columns].notna().mean()\n",
    "        importance_scores = (variances * non_null_ratios).fillna(0).tolist()\n",
    "        \n",
    "        return importance_scores\n",
    "    \n",
    "    def select_fast_strategies(self, target_columns, importance_scores):\n",
    "        \"\"\"Fast strategy selection\"\"\"\n",
    "        target_scores = list(zip(target_columns, importance_scores))\n",
    "        target_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        strategies = {}\n",
    "        for i, (target, score) in enumerate(target_scores):\n",
    "            if i < CFG.MAX_SIMPLE_MODELS:\n",
    "                strategies[target] = 'lightgbm'\n",
    "            else:\n",
    "                strategies[target] = 'linear'  # Most targets use linear\n",
    "                \n",
    "        return strategies\n",
    "    \n",
    "    def train_fast_lightgbm(self, X, y, target_name):\n",
    "        \"\"\"Minimal LightGBM training\"\"\"\n",
    "        try:\n",
    "            lgbm_params = CFG.get_lgbm_params()\n",
    "            model = lgb.LGBMRegressor(**lgbm_params)\n",
    "            \n",
    "            # No validation split - train on all data for speed\n",
    "            model.fit(X, y, eval_set=[(X.sample(min(100, len(X))), \n",
    "                                     y.iloc[:min(100, len(y))])],\n",
    "                     callbacks=[lgb.early_stopping(CFG.EARLY_STOPPING_ROUNDS),\n",
    "                               lgb.log_evaluation(0)])\n",
    "            \n",
    "            self.models[target_name] = model\n",
    "            self.feature_columns[target_name] = X.columns.tolist()\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            return self.train_linear_model(X, y, target_name)\n",
    "    \n",
    "    def train_linear_model(self, X, y, target_name):\n",
    "        \"\"\"Ultra-fast linear model\"\"\"\n",
    "        model = Ridge(alpha=0.1, random_state=CFG.RANDOM_STATE)\n",
    "        model.fit(X, y)\n",
    "        \n",
    "        self.models[target_name] = model\n",
    "        self.feature_columns[target_name] = X.columns.tolist()\n",
    "        return model\n",
    "\n",
    "# ==== Minimal Stabilization ==== #\n",
    "def fast_stabilize_predictions(out_df, date_ids=None):\n",
    "    \"\"\"Fast prediction stabilization\"\"\"\n",
    "    out_df = out_df.astype(np.float32)\n",
    "    out_df[:] = np.nan_to_num(out_df.values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Quick flat row detection\n",
    "    row_stds = np.std(out_df.values, axis=1)\n",
    "    flat_mask = row_stds < 1e-10\n",
    "    \n",
    "    if np.any(flat_mask):\n",
    "        # Add minimal noise to flat rows\n",
    "        noise = np.random.normal(0, 1e-6, out_df.shape)\n",
    "        out_df.iloc[flat_mask] += noise[flat_mask]\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "# ==== ULTRA-FAST Pipeline Predictor ==== #\n",
    "class UltraFastPredictor:\n",
    "    \"\"\"Ultra-fast prediction pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feature_pipeline = None\n",
    "        self.model_manager = FastModelManager()\n",
    "        self.is_fitted = False\n",
    "        self.global_mean = 0.0\n",
    "    \n",
    "    def fit(self, train_df, train_labels_df):\n",
    "        \"\"\"Ultra-fast fitting\"\"\"\n",
    "        print(\"ðŸš€ Ultra-fast pipeline fitting...\")\n",
    "        \n",
    "        # Minimal feature engineering\n",
    "        self.feature_pipeline = FastFeatureEngineer()\n",
    "        X_train = self.feature_pipeline.fit_transform(train_df)\n",
    "        X_train = X_train.drop(columns=['date_id'])\n",
    "        \n",
    "        # Calculate global fallback\n",
    "        target_columns = [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "        self.global_mean = train_labels_df[target_columns].mean().mean()\n",
    "        \n",
    "        # Fast target selection\n",
    "        importance_scores = self.model_manager.calculate_target_importance_fast(train_labels_df)\n",
    "        strategies = self.model_manager.select_fast_strategies(target_columns, importance_scores)\n",
    "        \n",
    "        print(f\"ðŸ“Š Training {len(target_columns)} targets:\")\n",
    "        print(f\"   - LightGBM: {sum(1 for s in strategies.values() if s == 'lightgbm')}\")\n",
    "        print(f\"   - Linear: {sum(1 for s in strategies.values() if s == 'linear')}\")\n",
    "        \n",
    "        # Fast training with minimal validation\n",
    "        trained = 0\n",
    "        for target in target_columns:\n",
    "            strategy = strategies.get(target, 'linear')\n",
    "            \n",
    "            y = train_labels_df[target].dropna()\n",
    "            if len(y) < CFG.MIN_SAMPLES_REQUIRED:\n",
    "                continue\n",
    "                \n",
    "            common_idx = X_train.index.intersection(y.index)\n",
    "            X_aligned = X_train.loc[common_idx].fillna(0)\n",
    "            y_aligned = y.loc[common_idx]\n",
    "            \n",
    "            try:\n",
    "                if strategy == 'lightgbm':\n",
    "                    self.model_manager.train_fast_lightgbm(X_aligned, y_aligned, target)\n",
    "                else:\n",
    "                    self.model_manager.train_linear_model(X_aligned, y_aligned, target)\n",
    "                trained += 1\n",
    "            except Exception:\n",
    "                continue\n",
    "        \n",
    "        print(f\"âœ… Trained {trained} models in minimal time\")\n",
    "        self.is_fitted = True\n",
    "    \n",
    "    def predict(self, test: pl.DataFrame, *label_lags) -> pl.DataFrame:\n",
    "        \"\"\"Ultra-fast prediction\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Must fit before predict\")\n",
    "            \n",
    "        test_df = test.to_pandas()\n",
    "        X_test = self.feature_pipeline.transform(test_df)\n",
    "        X_test = X_test.drop(columns=['date_id'])\n",
    "        \n",
    "        # Fast prediction matrix\n",
    "        predictions = np.full((len(test_df), CFG.NUM_TARGET_COLUMNS), self.global_mean)\n",
    "        \n",
    "        for i in range(CFG.NUM_TARGET_COLUMNS):\n",
    "            target_name = f\"target_{i}\"\n",
    "            \n",
    "            if target_name in self.model_manager.models:\n",
    "                try:\n",
    "                    model = self.model_manager.models[target_name]\n",
    "                    feature_cols = self.model_manager.feature_columns[target_name]\n",
    "                    X_aligned = X_test[feature_cols].fillna(0)\n",
    "                    predictions[:, i] = model.predict(X_aligned)\n",
    "                except Exception:\n",
    "                    # Keep global mean fallback\n",
    "                    pass\n",
    "        \n",
    "        # Fast output creation\n",
    "        column_names = [f\"target_{i}\" for i in range(CFG.NUM_TARGET_COLUMNS)]\n",
    "        out_df = pd.DataFrame(predictions, columns=column_names)\n",
    "        out_df = fast_stabilize_predictions(out_df)\n",
    "        \n",
    "        # Verification\n",
    "        assert out_df.shape[1] == CFG.NUM_TARGET_COLUMNS\n",
    "        assert out_df.shape[0] == len(test_df)\n",
    "        \n",
    "        return pl.DataFrame(out_df)\n",
    "\n",
    "# ==== ULTRA-FAST Submission Manager ==== #\n",
    "class UltraFastSubmissionManager:\n",
    "    \"\"\"Speed-optimized submission manager\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.predictor = None\n",
    "        self.initialization_attempted = False\n",
    "        \n",
    "    def initialize_for_submission(self):\n",
    "        \"\"\"Minimal initialization\"\"\"\n",
    "        if self.initialization_attempted:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            print(\"ðŸš€ Ultra-fast initialization starting...\")\n",
    "            self.predictor = UltraFastPredictor()\n",
    "            \n",
    "            # Load data with minimal processing\n",
    "            train_df = pd.read_csv(data_path / 'train.csv')\n",
    "            train_labels_df = pd.read_csv(data_path / 'train_labels.csv')\n",
    "            \n",
    "            # Sample data for speed if too large\n",
    "            if len(train_df) > 5000:\n",
    "                sample_idx = np.random.choice(len(train_df), 5000, replace=False)\n",
    "                train_df = train_df.iloc[sample_idx]\n",
    "                train_labels_df = train_labels_df.iloc[sample_idx]\n",
    "                print(f\"ðŸ“Š Sampled to {len(train_df)} rows for speed\")\n",
    "            \n",
    "            self.predictor.fit(train_df, train_labels_df)\n",
    "            print(\"âœ… Ultra-fast initialization completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Init failed: {e}\")\n",
    "            self.predictor = self._create_minimal_fallback()\n",
    "            \n",
    "        finally:\n",
    "            self.initialization_attempted = True\n",
    "    \n",
    "    def _create_minimal_fallback(self):\n",
    "        \"\"\"Minimal fallback predictor\"\"\"\n",
    "        class MinimalFallback:\n",
    "            def predict(self, test, *args):\n",
    "                n_samples = len(test)\n",
    "                # Simple random predictions\n",
    "                preds = np.random.normal(0, 0.01, (n_samples, CFG.NUM_TARGET_COLUMNS))\n",
    "                columns = [f\"target_{i}\" for i in range(CFG.NUM_TARGET_COLUMNS)]\n",
    "                return pl.DataFrame(pd.DataFrame(preds, columns=columns))\n",
    "        \n",
    "        return MinimalFallback()\n",
    "    \n",
    "    def predict(self, test, *label_lags):\n",
    "        \"\"\"Main prediction with verification\"\"\"\n",
    "        if not self.initialization_attempted:\n",
    "            self.initialize_for_submission()\n",
    "            \n",
    "        result = self.predictor.predict(test, *label_lags)\n",
    "        \n",
    "        # Final verification\n",
    "        assert result.shape[1] == CFG.NUM_TARGET_COLUMNS\n",
    "        assert result.shape[0] == len(test)\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Global ultra-fast manager\n",
    "submission_manager = UltraFastSubmissionManager()\n",
    "\n",
    "def predict(test: pl.DataFrame,\n",
    "           label_lags_1_batch: pl.DataFrame,\n",
    "           label_lags_2_batch: pl.DataFrame,\n",
    "           label_lags_3_batch: pl.DataFrame,\n",
    "           label_lags_4_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Ultra-fast predict function\"\"\"\n",
    "    result = submission_manager.predict(test, label_lags_1_batch, \n",
    "                                      label_lags_2_batch, label_lags_3_batch, \n",
    "                                      label_lags_4_batch)\n",
    "    \n",
    "    # Safety check for exact column count\n",
    "    if result.shape[1] != CFG.NUM_TARGET_COLUMNS:\n",
    "        if result.shape[1] < CFG.NUM_TARGET_COLUMNS:\n",
    "            missing = CFG.NUM_TARGET_COLUMNS - result.shape[1]\n",
    "            zeros = pl.DataFrame({f\"target_{result.shape[1] + i}\": [0.0] * len(result) \n",
    "                                for i in range(missing)})\n",
    "            result = pl.concat([result, zeros], how=\"horizontal\")\n",
    "        else:\n",
    "            result = result.select([f\"target_{i}\" for i in range(CFG.NUM_TARGET_COLUMNS)])\n",
    "    \n",
    "    print(f\"âš¡ Ultra-fast prediction: {result.shape[0]} Ã— {result.shape[1]}\")\n",
    "    return result\n",
    "\n",
    "# Kaggle Inference Server - ENABLED\n",
    "inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway((str(data_path),))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
