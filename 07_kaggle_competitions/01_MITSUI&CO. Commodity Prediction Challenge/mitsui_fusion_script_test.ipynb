{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948b7572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Local development environment detected\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 1: Imports & Configuration ==== #\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import json\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Kaggle evaluation (COMMENTED OUT FOR LOCAL TESTING)\n",
    "# import kaggle_evaluation.mitsui_inference_server\n",
    "\n",
    "# ==== Global Configuration ==== #\n",
    "class Config:\n",
    "    \"\"\"Centralized configuration for Mitsui Commodity Prediction Challenge\"\"\"\n",
    "    NUM_TARGET_COLUMNS = 424\n",
    "    RANDOM_STATE = 42\n",
    "    CV_FOLDS = 3\n",
    "    \n",
    "    # Model parameters from best performing ensemble\n",
    "    LGBM_PARAMS = {\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 64,\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': 1,\n",
    "        'force_row_wise': True\n",
    "    }\n",
    "    \n",
    "    # Feature engineering parameters\n",
    "    ROLLING_WINDOWS = [3, 5, 10, 20]\n",
    "    LAG_PERIODS = [1, 2, 3]\n",
    "    \n",
    "    # Training configuration - make flexible for any competition setup\n",
    "    MAX_TARGETS_TRAINING = 10      # Limit for development/testing (None for all)\n",
    "    MAX_MODELS_KAGGLE = 5          # Limit for Kaggle submission constraints\n",
    "    MIN_SAMPLES_REQUIRED = 100     # Minimum samples needed to train a model\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_data_path():\n",
    "        \"\"\"Auto-detect environment and return appropriate data path\"\"\"\n",
    "        kaggle_path = Path('/kaggle/input/mitsui-commodity-prediction-challenge')\n",
    "        local_path = Path(\"dataset\")\n",
    "        \n",
    "        if kaggle_path.exists():\n",
    "            print(\"üîß Kaggle environment detected\")\n",
    "            return kaggle_path\n",
    "        else:\n",
    "            print(\"üîß Local development environment detected\")\n",
    "            return local_path\n",
    "\n",
    "CFG = Config()\n",
    "data_path = CFG.get_data_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c671c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Cell 2: Advanced Feature Engineering Pipeline ==== #\n",
    "class FeatureEngineer:\n",
    "    \"\"\"Advanced feature engineering pipeline based on winning ensemble analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, rolling_windows=None, lag_periods=None, enable_heavy_features=True):\n",
    "        self.rolling_windows = rolling_windows or CFG.ROLLING_WINDOWS\n",
    "        self.lag_periods = lag_periods or CFG.LAG_PERIODS\n",
    "        self.enable_heavy_features = enable_heavy_features\n",
    "        \n",
    "    def create_advanced_features(self, df, feature_cols):\n",
    "        \"\"\"\n",
    "        Create comprehensive technical and statistical features based on winning approach.\n",
    "        Implements the feature engineering that achieved 0.9095 Kaggle metric.\n",
    "        \"\"\"\n",
    "        print(\"üîß Creating advanced features for ensemble training...\")\n",
    "        \n",
    "        feature_count_before = len(df.columns)\n",
    "        df = df.copy()\n",
    "        \n",
    "        for col in feature_cols:\n",
    "            if col == 'date_id':\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                # Rolling statistics - core momentum indicators\n",
    "                for window in self.rolling_windows:\n",
    "                    df[f'{col}_rolling_mean_{window}'] = df[col].rolling(window).mean()\n",
    "                    df[f'{col}_rolling_std_{window}'] = df[col].rolling(window).std()\n",
    "                    \n",
    "                # Volatility measures\n",
    "                df[f'{col}_annual_vol_20'] = df[col].rolling(20).std() * np.sqrt(252)\n",
    "                df[f'{col}_pct_change'] = df[col].pct_change()\n",
    "                \n",
    "                # Lag features for temporal dependencies\n",
    "                for lag in self.lag_periods:\n",
    "                    df[f'{col}_lag_{lag}'] = df[col].shift(lag)\n",
    "                \n",
    "                if self.enable_heavy_features:\n",
    "                    # Higher order statistics\n",
    "                    df[f'{col}_rolling_skew_10'] = df[col].rolling(10).skew()\n",
    "                    df[f'{col}_rolling_kurt_10'] = df[col].rolling(10).kurt()\n",
    "                    \n",
    "                    # Autocorrelation features\n",
    "                    df[f'{col}_autocorr_1'] = df[col].rolling(20).apply(\n",
    "                        lambda x: x.autocorr(lag=1) if len(x.dropna()) > 1 else 0, raw=False\n",
    "                    )\n",
    "                    df[f'{col}_autocorr_5'] = df[col].rolling(20).apply(\n",
    "                        lambda x: x.autocorr(lag=5) if len(x.dropna()) > 5 else 0, raw=False\n",
    "                    )\n",
    "                    \n",
    "                    # Market regime indicators\n",
    "                    roll_mean = df[col].rolling(10).mean()\n",
    "                    roll_vol = df[col].rolling(10).std()\n",
    "                    df[f'{col}_regime_trend_up'] = (roll_mean > roll_mean.shift(1)).astype(int)\n",
    "                    df[f'{col}_regime_high_vol'] = (roll_vol > roll_vol.quantile(0.75)).astype(int)\n",
    "                    \n",
    "                    # Vol-of-vol (volatility clustering)\n",
    "                    rolling_vol = df[col].rolling(10).std()\n",
    "                    df[f'{col}_vol_of_vol'] = rolling_vol.rolling(5).std()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Error creating features for {col}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Alternatively, apply ffill for NaNs\n",
    "        # df = df.fillna(method='ffill').fillna(method='bfill')\n",
    "        # Fill NaN values\n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        feature_count_after = len(df.columns)\n",
    "        features_added = feature_count_after - feature_count_before\n",
    "        print(f\"‚úÖ Feature engineering completed: {features_added} features added\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Global feature engineer instance\n",
    "feature_engineer = FeatureEngineer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a862a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Cell 3: Stabilization (from Code 1) ==== #\n",
    "def _stabilize_and_detie_rows(out_df, date_ids=None):\n",
    "    \"\"\"Ensure no flat rows in predictions, add small noise if needed.\"\"\"\n",
    "    out_df = out_df.astype(np.float32)\n",
    "    out_df[:] = np.nan_to_num(out_df.values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    n_rows, n_cols = out_df.shape\n",
    "    if date_ids is None:\n",
    "        date_ids = np.zeros(n_rows, dtype=int)\n",
    "    vals = out_df.to_numpy(np.float32)\n",
    "    row_stds = np.std(vals, axis=1)\n",
    "    flat_mask = row_stds < 1e-15\n",
    "    if np.any(flat_mask):\n",
    "        for r_idx in np.where(flat_mask)[0]:\n",
    "            rng = np.random.default_rng(int(date_ids[r_idx]) + 131071)\n",
    "            noise = rng.normal(loc=0.0, scale=1.0, size=n_cols).astype(np.float32)\n",
    "            scale = (1.0 + abs(float(np.mean(vals[r_idx])))) * 1e-6\n",
    "            vals[r_idx] = vals[r_idx] + noise * scale\n",
    "        out_df.iloc[:, :] = vals\n",
    "    return out_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b3aa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Cell 4: Ensemble Model Management ==== #\n",
    "class EnsembleModelManager:\n",
    "    \"\"\"Manages ensemble model training and evaluation based on winning approach\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.feature_columns = {}\n",
    "        \n",
    "    def create_lgb_regressor(self):\n",
    "        \"\"\"Create LightGBM with optimized parameters\"\"\"\n",
    "        return lgb.LGBMRegressor(**CFG.LGBM_PARAMS)\n",
    "    \n",
    "    def train_stacking_model(self, X, y, target_name=None):\n",
    "        \"\"\"\n",
    "        Train stacking ensemble - the best performing method (0.7364 avg Kaggle metric)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            estimators = [\n",
    "                ('lr', LinearRegression()),\n",
    "                ('lgb', self.create_lgb_regressor())\n",
    "            ]\n",
    "            \n",
    "            model = StackingRegressor(\n",
    "                estimators=estimators,\n",
    "                final_estimator=LinearRegression(),\n",
    "                cv=CFG.CV_FOLDS,\n",
    "                n_jobs=1\n",
    "            )\n",
    "            \n",
    "            model.fit(X, y)\n",
    "            \n",
    "            if target_name:\n",
    "                self.models[target_name] = model\n",
    "                self.feature_columns[target_name] = X.columns.tolist()\n",
    "            \n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Stacking failed for {target_name}: {e}\")\n",
    "            # Fallback to simple linear regression\n",
    "            fallback_model = LinearRegression()\n",
    "            fallback_model.fit(X, y)\n",
    "            return fallback_model\n",
    "    \n",
    "    def evaluate_model_comprehensive(self, model, X, y, target_name=None):\n",
    "        \"\"\"\n",
    "        Comprehensive evaluation including Kaggle competition metric (Spearman correlation)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            preds = model.predict(X)\n",
    "            \n",
    "            # Standard metrics\n",
    "            rmse = np.sqrt(mean_squared_error(y, preds))\n",
    "            mae = mean_absolute_error(y, preds)\n",
    "\n",
    "            # Additional metrics can be added here\n",
    "            # Check if Kaggle metric is correctly implemented\n",
    "            # Kaggle competition metric (Spearman correlation)\n",
    "            kaggle_metric, _ = spearmanr(y, preds)\n",
    "            kaggle_metric = abs(kaggle_metric) if not np.isnan(kaggle_metric) else 0.0\n",
    "            \n",
    "            # Cross-validation\n",
    "            cv = KFold(n_splits=CFG.CV_FOLDS, shuffle=False, random_state=CFG.RANDOM_STATE)\n",
    "            cv_scores = cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_absolute_error\")\n",
    "            \n",
    "            results = {\n",
    "                'rmse': rmse,\n",
    "                'mae': mae,\n",
    "                'kaggle_metric': kaggle_metric,\n",
    "                'cv_mae_mean': -np.mean(cv_scores),\n",
    "                'cv_mae_std': np.std(cv_scores)\n",
    "            }\n",
    "            \n",
    "            print(f\"üìä {target_name or 'Model'} Performance:\")\n",
    "            print(f\"   RMSE: {rmse:.5f}, MAE: {mae:.5f}\")\n",
    "            print(f\"   Kaggle Metric: {kaggle_metric:.5f}\")\n",
    "            print(f\"   CV MAE: {results['cv_mae_mean']:.5f} (¬±{results['cv_mae_std']:.5f})\")\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Evaluation failed: {e}\")\n",
    "            return {'rmse': float('inf'), 'mae': float('inf'), 'kaggle_metric': 0.0}\n",
    "\n",
    "# Global model manager\n",
    "model_manager = EnsembleModelManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb700846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Cell 5: Training Pipeline Implementation ==== #\n",
    "def run_training_pipeline():\n",
    "    \"\"\"\n",
    "    Execute complete training pipeline for model development and validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ Starting Mitsui Commodity Prediction Training Pipeline\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        print(\"üìä Loading training data...\")\n",
    "        train_df = pd.read_csv(data_path / 'train.csv')\n",
    "        train_labels_df = pd.read_csv(data_path / 'train_labels.csv')\n",
    "        \n",
    "        print(f\"   Training features: {train_df.shape}\")\n",
    "        print(f\"   Training labels: {train_labels_df.shape}\")\n",
    "        \n",
    "        # Feature engineering\n",
    "        print(\"üîß Applying advanced feature engineering...\")\n",
    "        feature_cols = [c for c in train_df.columns if c != \"date_id\"]\n",
    "        train_engineered = feature_engineer.create_advanced_features(train_df, feature_cols)\n",
    "\n",
    "        # Train models for all available targets in the dataset\n",
    "        results = {}\n",
    "        target_columns = [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "        \n",
    "        print(f\"üìã Found {len(target_columns)} targets available\")\n",
    "        \n",
    "        # Apply training limits from configuration\n",
    "        if CFG.MAX_TARGETS_TRAINING:\n",
    "            target_columns = target_columns[:CFG.MAX_TARGETS_TRAINING]\n",
    "            print(f\"üîß Training limited to first {len(target_columns)} targets (config: MAX_TARGETS_TRAINING={CFG.MAX_TARGETS_TRAINING})\")\n",
    "        else:\n",
    "            print(f\"üöÄ Training ALL {len(target_columns)} targets\")\n",
    "        \n",
    "        for target in target_columns:\n",
    "            print(f\"\\nüéØ Training {target}...\")\n",
    "            \n",
    "            # Prepare data\n",
    "            X = train_engineered.drop(columns=['date_id'])\n",
    "            y = train_labels_df[target].dropna()\n",
    "            \n",
    "            # Align data\n",
    "            common_idx = X.index.intersection(y.index)\n",
    "            X_aligned = X.loc[common_idx].fillna(0)\n",
    "            y_aligned = y.loc[common_idx]\n",
    "            \n",
    "            if len(X_aligned) >= CFG.MIN_SAMPLES_REQUIRED:\n",
    "                # Train model\n",
    "                model = model_manager.train_stacking_model(X_aligned, y_aligned, target)\n",
    "                \n",
    "                # Evaluate\n",
    "                eval_results = model_manager.evaluate_model_comprehensive(\n",
    "                    model, X_aligned, y_aligned, target\n",
    "                )\n",
    "                results[target] = eval_results\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Insufficient data for {target}: {len(X_aligned)} < {CFG.MIN_SAMPLES_REQUIRED} samples\")\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\nüèÜ Training Pipeline Completed!\")\n",
    "        print(f\"üìä Trained {len(results)} models\")\n",
    "        \n",
    "        if results:\n",
    "            avg_kaggle_metric = np.mean([r['kaggle_metric'] for r in results.values()])\n",
    "            print(f\"üìà Average Kaggle Metric: {avg_kaggle_metric:.4f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training pipeline failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# Training pipeline enabled for local testing\n",
    "# training_results = run_training_pipeline()  # Will be called at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd9349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==== Cell 5.5: Pipeline Configuration Utilities ==== #\n",
    "# def configure_pipeline_for_scenario(scenario: str = 'development'):\n",
    "#     \"\"\"\n",
    "#     Configure the pipeline for different scenarios\n",
    "    \n",
    "#     Scenarios:\n",
    "#     - 'development': Fast training with limited targets for testing\n",
    "#     - 'full_training': Train on all targets for comprehensive analysis  \n",
    "#     - 'kaggle_submission': Optimized for Kaggle submission constraints\n",
    "#     \"\"\"\n",
    "#     if scenario == 'development':\n",
    "#         CFG.MAX_TARGETS_TRAINING = 5\n",
    "#         CFG.MAX_MODELS_KAGGLE = 3\n",
    "#         print(\"üîß Configured for DEVELOPMENT: Fast training with 5 targets max\")\n",
    "        \n",
    "#     elif scenario == 'full_training':\n",
    "#         CFG.MAX_TARGETS_TRAINING = None  # Train all targets\n",
    "#         CFG.MAX_MODELS_KAGGLE = 20\n",
    "#         print(\"üîß Configured for FULL TRAINING: All targets, comprehensive analysis\")\n",
    "        \n",
    "#     elif scenario == 'kaggle_submission':\n",
    "#         CFG.MAX_TARGETS_TRAINING = None  # Train all targets during development\n",
    "#         CFG.MAX_MODELS_KAGGLE = 5        # But only use 5 for Kaggle submission\n",
    "#         print(\"üîß Configured for KAGGLE SUBMISSION: Optimized for submission constraints\")\n",
    "        \n",
    "#     else:\n",
    "#         print(f\"‚ùå Unknown scenario '{scenario}'. Available: 'development', 'full_training', 'kaggle_submission'\")\n",
    "\n",
    "# def get_available_targets(train_labels_df: pd.DataFrame) -> List[str]:\n",
    "#     \"\"\"Get all available target columns from the training labels\"\"\"\n",
    "#     return [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "\n",
    "# def print_pipeline_status():\n",
    "#     \"\"\"Print current pipeline configuration status\"\"\"\n",
    "#     print(\"üìä Current Pipeline Configuration:\")\n",
    "#     print(f\"   MAX_TARGETS_TRAINING: {CFG.MAX_TARGETS_TRAINING}\")\n",
    "#     print(f\"   MAX_MODELS_KAGGLE: {CFG.MAX_MODELS_KAGGLE}\")\n",
    "#     print(f\"   MIN_SAMPLES_REQUIRED: {CFG.MIN_SAMPLES_REQUIRED}\")\n",
    "#     print(f\"   CV_FOLDS: {CFG.CV_FOLDS}\")\n",
    "\n",
    "# # Example usage:\n",
    "# configure_pipeline_for_scenario('development')  # For fast testing\n",
    "# # configure_pipeline_for_scenario('full_training')  # For complete analysis\n",
    "# # configure_pipeline_for_scenario('kaggle_submission')  # For competition submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903eda3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Cell 5: Training Pipeline Implementation ==== #\n",
    "def run_training_pipeline():\n",
    "    \"\"\"\n",
    "    Execute complete training pipeline for model development and validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üöÄ Starting Mitsui Commodity Prediction Training Pipeline\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load data\n",
    "        print(\"üìä Loading training data...\")\n",
    "        try:\n",
    "            train_df = pd.read_csv(data_path / 'train.csv')\n",
    "            train_labels_df = pd.read_csv(data_path / 'train_labels.csv')\n",
    "            print(f\"   Training features: {train_df.shape}\")\n",
    "            print(f\"   Training labels: {train_labels_df.shape}\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"‚ùå Dataset files not found: {e}\")\n",
    "            print(\"   Please ensure 'train.csv' and 'train_labels.csv' are in the 'dataset' folder\")\n",
    "            return {}\n",
    "        \n",
    "        # Feature engineering with optimized settings for faster local testing\n",
    "        print(\"üîß Applying feature engineering...\")\n",
    "        feature_cols = [c for c in train_df.columns if c != \"date_id\"]\n",
    "        \n",
    "        # Use lightweight feature engineering for faster local testing\n",
    "        feature_engineer_optimized = FeatureEngineer(\n",
    "            rolling_windows=[3, 5],  # Reduced from [3, 5, 10, 20]\n",
    "            lag_periods=[1],         # Reduced from [1, 2, 3]\n",
    "            enable_heavy_features=False  # Disable slow autocorr and regime features\n",
    "        )\n",
    "        \n",
    "        train_engineered = feature_engineer_optimized.create_advanced_features(train_df, feature_cols)\n",
    "\n",
    "        # Train models for available targets\n",
    "        results = {}\n",
    "        target_columns = [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "        \n",
    "        print(f\"üìã Found {len(target_columns)} targets available\")\n",
    "        \n",
    "        # Apply training limits from configuration\n",
    "        if CFG.MAX_TARGETS_TRAINING:\n",
    "            target_columns = target_columns[:CFG.MAX_TARGETS_TRAINING]\n",
    "            print(f\"üîß Training limited to first {len(target_columns)} targets (config: MAX_TARGETS_TRAINING={CFG.MAX_TARGETS_TRAINING})\")\n",
    "        else:\n",
    "            print(f\"üöÄ Training ALL {len(target_columns)} targets\")\n",
    "        \n",
    "        for i, target in enumerate(target_columns):\n",
    "            print(f\"\\nüéØ Training {target} ({i+1}/{len(target_columns)})...\")\n",
    "            \n",
    "            # Prepare data\n",
    "            X = train_engineered.drop(columns=['date_id'])\n",
    "            y = train_labels_df[target].dropna()\n",
    "            \n",
    "            # Align data\n",
    "            common_idx = X.index.intersection(y.index)\n",
    "            X_aligned = X.loc[common_idx].fillna(0)\n",
    "            y_aligned = y.loc[common_idx]\n",
    "            \n",
    "            print(f\"   Data shape: X={X_aligned.shape}, y={y_aligned.shape}\")\n",
    "            \n",
    "            if len(X_aligned) >= CFG.MIN_SAMPLES_REQUIRED:\n",
    "                # Use faster LinearRegression for local testing instead of slow StackingRegressor\n",
    "                try:\n",
    "                    print(f\"   üöÄ Training LinearRegression model for speed...\")\n",
    "                    model = LinearRegression()\n",
    "                    model.fit(X_aligned, y_aligned)\n",
    "                    \n",
    "                    # Store model\n",
    "                    model_manager.models[target] = model\n",
    "                    model_manager.feature_columns[target] = X_aligned.columns.tolist()\n",
    "                    \n",
    "                    # Quick evaluation\n",
    "                    preds = model.predict(X_aligned)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_aligned, preds))\n",
    "                    mae = mean_absolute_error(y_aligned, preds)\n",
    "                    \n",
    "                    # Spearman correlation (Kaggle metric)\n",
    "                    try:\n",
    "                        kaggle_metric, _ = spearmanr(y_aligned, preds)\n",
    "                        kaggle_metric = abs(kaggle_metric) if not np.isnan(kaggle_metric) else 0.0\n",
    "                    except:\n",
    "                        kaggle_metric = 0.0\n",
    "                    \n",
    "                    results[target] = {\n",
    "                        'rmse': rmse,\n",
    "                        'mae': mae,\n",
    "                        'kaggle_metric': kaggle_metric\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ Model trained! RMSE: {rmse:.4f}, MAE: {mae:.4f}, Kaggle: {kaggle_metric:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Model training failed: {e}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Insufficient data: {len(X_aligned)} < {CFG.MIN_SAMPLES_REQUIRED} samples\")\n",
    "        \n",
    "        # Summary\n",
    "        print(f\"\\nüèÜ Training Pipeline Completed!\")\n",
    "        print(f\"üìä Trained {len(results)} models\")\n",
    "        \n",
    "        if results:\n",
    "            avg_rmse = np.mean([r['rmse'] for r in results.values()])\n",
    "            avg_kaggle = np.mean([r['kaggle_metric'] for r in results.values()])\n",
    "            print(f\"üìà Average RMSE: {avg_rmse:.4f}\")\n",
    "            print(f\"üìà Average Kaggle Metric: {avg_kaggle:.4f}\")\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Training pipeline failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {}\n",
    "\n",
    "# Training pipeline enabled for local testing\n",
    "# training_results = run_training_pipeline()  # Will be called at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae565190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Mitsui Commodity Prediction Training Pipeline\n",
      "============================================================\n",
      "üìä Loading training data...\n",
      "   Training features: (1961, 558)\n",
      "   Training labels: (1961, 425)\n",
      "üîß Applying advanced feature engineering...\n",
      "üîß Creating advanced features for ensemble training...\n",
      "‚úÖ Feature engineering completed: 11140 features added\n",
      "üìã Found 424 targets available\n",
      "üîß Training limited to first 10 targets (config: MAX_TARGETS_TRAINING=10)\n",
      "\n",
      "üéØ Training target_0...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 148\u001b[39m\n\u001b[32m    137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m kaggle_predictor.predict(test, label_lags_1_batch, label_lags_2_batch, \n\u001b[32m    138\u001b[39m                                    label_lags_3_batch, label_lags_4_batch)\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Kaggle Inference Server (COMMENTED OUT FOR LOCAL TESTING)\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\u001b[39;00m\n\u001b[32m    142\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# else:\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m#     inference_server.run_local_gateway((str(data_path),))\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m training_results = \u001b[43mrun_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# LOCAL TESTING: Enable training pipeline for verificationprint(\"üß™ LOCAL TESTING MODE - Running training pipeline for verification...\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mrun_training_pipeline\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     46\u001b[39m y_aligned = y.loc[common_idx]\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X_aligned) >= CFG.MIN_SAMPLES_REQUIRED:\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     model = \u001b[43mmodel_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_stacking_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_aligned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_aligned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m     53\u001b[39m     eval_results = model_manager.evaluate_model_comprehensive(\n\u001b[32m     54\u001b[39m         model, X_aligned, y_aligned, target\n\u001b[32m     55\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mEnsembleModelManager.train_stacking_model\u001b[39m\u001b[34m(self, X, y, target_name)\u001b[39m\n\u001b[32m     18\u001b[39m estimators = [\n\u001b[32m     19\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m, LinearRegression()),\n\u001b[32m     20\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mlgb\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mself\u001b[39m.create_lgb_regressor())\n\u001b[32m     21\u001b[39m ]\n\u001b[32m     23\u001b[39m model = StackingRegressor(\n\u001b[32m     24\u001b[39m     estimators=estimators,\n\u001b[32m     25\u001b[39m     final_estimator=LinearRegression(),\n\u001b[32m     26\u001b[39m     cv=CFG.CV_FOLDS,\n\u001b[32m     27\u001b[39m     n_jobs=\u001b[32m1\u001b[39m\n\u001b[32m     28\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_name:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m.models[target_name] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:968\u001b[39m, in \u001b[36mStackingRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    966\u001b[39m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, sample_weight=sample_weight)\n\u001b[32m    967\u001b[39m y = column_or_1d(y, warn=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m968\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1467\u001b[39m     estimator._validate_params()\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1470\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1471\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1472\u001b[39m     )\n\u001b[32m   1473\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1474\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:259\u001b[39m, in \u001b[36m_BaseStacking.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    254\u001b[39m         cv.random_state = np.random.RandomState()\n\u001b[32m    256\u001b[39m     fit_params = (\n\u001b[32m    257\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33msample_weight\u001b[39m\u001b[33m\"\u001b[39m: sample_weight} \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     predictions = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcross_val_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_estimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstack_method_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mest\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdrop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# Only not None or not 'drop' estimators will be used in transform.\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m# Remove the None from the method as well.\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;28mself\u001b[39m.stack_method_ = [\n\u001b[32m    277\u001b[39m     meth\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m (meth, est) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m.stack_method_, all_estimators)\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m est != \u001b[33m\"\u001b[39m\u001b[33mdrop\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    280\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     62\u001b[39m config = get_config()\n\u001b[32m     63\u001b[39m iterable_with_config = (\n\u001b[32m     64\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1861\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1866\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1867\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1868\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1870\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1790\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1792\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m     config = {}\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    209\u001b[39m         skip_parameter_validation=(\n\u001b[32m    210\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    211\u001b[39m         )\n\u001b[32m    212\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    215\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    216\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    217\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    219\u001b[39m     msg = re.sub(\n\u001b[32m    220\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    222\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    223\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1293\u001b[39m, in \u001b[36mcross_val_predict\u001b[39m\u001b[34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, params, pre_dispatch, method)\u001b[39m\n\u001b[32m   1290\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m   1291\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m   1292\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m predictions = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1297\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1306\u001b[39m inv_test_indices = np.empty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype=\u001b[38;5;28mint\u001b[39m)\n\u001b[32m   1307\u001b[39m inv_test_indices[test_indices] = np.arange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     62\u001b[39m config = get_config()\n\u001b[32m     63\u001b[39m iterable_with_config = (\n\u001b[32m     64\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1861\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1863\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1865\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1866\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1867\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1868\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1870\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1790\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1791\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1792\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m     config = {}\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1378\u001b[39m, in \u001b[36m_fit_and_predict\u001b[39m\u001b[34m(estimator, X, y, train, test, fit_params, method)\u001b[39m\n\u001b[32m   1376\u001b[39m     estimator.fit(X_train, **fit_params)\n\u001b[32m   1377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1378\u001b[39m     \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m func = \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[32m   1380\u001b[39m predictions = func(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\calli\\miniconda3\\envs\\ml\\Lib\\site-packages\\lightgbm\\basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ==== Cell 6: Production Kaggle Integration ==== #\n",
    "class KagglePredictor:\n",
    "    \"\"\"Production-ready Kaggle prediction pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models_loaded = False\n",
    "        self.trained_models = {}\n",
    "        self.feature_columns = {}\n",
    "        self.is_initialized = False\n",
    "        \n",
    "    def initialize_models(self):\n",
    "        \"\"\"Initialize models from training data or load pre-trained models\"\"\"\n",
    "        try:\n",
    "            print(\"üöÄ Initializing prediction models...\")\n",
    "            \n",
    "            # Load training data\n",
    "            train_df = pd.read_csv(data_path / 'train.csv')\n",
    "            train_labels_df = pd.read_csv(data_path / 'train_labels.csv')\n",
    "            \n",
    "            print(f\"üìä Training data: {train_df.shape}, Labels: {train_labels_df.shape}\")\n",
    "            \n",
    "            # Feature engineering on training data\n",
    "            feature_cols = [c for c in train_df.columns if c != \"date_id\"]\n",
    "            train_engineered = feature_engineer.create_advanced_features(train_df, feature_cols)\n",
    "\n",
    "            # Train models for available targets (optimized for Kaggle submission constraints)\n",
    "            target_columns = [col for col in train_labels_df.columns if col.startswith('target_')]\n",
    "            \n",
    "            # For Kaggle submission, limit models to prevent memory/time constraints\n",
    "            selected_targets = target_columns[:CFG.MAX_MODELS_KAGGLE]\n",
    "            \n",
    "            print(f\"üîß Training {len(selected_targets)} models for Kaggle submission (config: MAX_MODELS_KAGGLE={CFG.MAX_MODELS_KAGGLE})\")\n",
    "            \n",
    "            for target in selected_targets:\n",
    "                print(f\"üîß Training model for {target}...\")\n",
    "                \n",
    "                # Prepare data\n",
    "                X = train_engineered.drop(columns=['date_id'])\n",
    "                y = train_labels_df[target].dropna()\n",
    "                \n",
    "                # Align X and y\n",
    "                common_idx = X.index.intersection(y.index)\n",
    "                X_aligned = X.loc[common_idx]\n",
    "                y_aligned = y.loc[common_idx]\n",
    "                \n",
    "                if len(X_aligned) >= CFG.MIN_SAMPLES_REQUIRED:\n",
    "                    model = model_manager.train_stacking_model(X_aligned, y_aligned, target)\n",
    "                    self.trained_models[target] = model\n",
    "                    self.feature_columns[target] = X_aligned.columns.tolist()\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Insufficient data for {target}: {len(X_aligned)} < {CFG.MIN_SAMPLES_REQUIRED} samples\")\n",
    "                        \n",
    "            print(f\"‚úÖ Initialized {len(self.trained_models)} specialized models\")\n",
    "            self.is_initialized = True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Model initialization failed: {e}\")\n",
    "            # Create fallback model\n",
    "            self.trained_models['fallback'] = LinearRegression()\n",
    "            self.is_initialized = True\n",
    "    \n",
    "    def predict(self, \n",
    "               test: pl.DataFrame,\n",
    "               label_lags_1_batch: pl.DataFrame,\n",
    "               label_lags_2_batch: pl.DataFrame, \n",
    "               label_lags_3_batch: pl.DataFrame,\n",
    "               label_lags_4_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "        \"\"\"\n",
    "        Kaggle predict hook with proper model integration and label lag utilization\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not self.is_initialized:\n",
    "                self.initialize_models()\n",
    "            \n",
    "            # Convert to pandas\n",
    "            test_df = test.to_pandas()\n",
    "            \n",
    "            # Feature engineering\n",
    "            feature_cols = [c for c in test_df.columns if c != \"date_id\"]\n",
    "            test_engineered = feature_engineer.create_advanced_features(test_df, feature_cols)\n",
    "            \n",
    "            # Prepare features for prediction\n",
    "            X_test = test_engineered.drop(columns=[\"date_id\"])\n",
    "            \n",
    "            # Initialize predictions array\n",
    "            predictions = np.zeros((len(test_df), CFG.NUM_TARGET_COLUMNS))\n",
    "            \n",
    "            # Generate predictions for each target\n",
    "            for i in range(CFG.NUM_TARGET_COLUMNS):\n",
    "                target_name = f\"target_{i}\"\n",
    "                \n",
    "                try:\n",
    "                    if target_name in self.trained_models:\n",
    "                        # Use specialized model\n",
    "                        model = self.trained_models[target_name]\n",
    "                        feature_cols_model = self.feature_columns[target_name]\n",
    "                        X_aligned = X_test[feature_cols_model]\n",
    "                        pred = model.predict(X_aligned)\n",
    "                    else:\n",
    "                        # Use fallback or simple heuristic\n",
    "                        if 'fallback' in self.trained_models:\n",
    "                            pred = self.trained_models['fallback'].predict(X_test.iloc[:, :min(10, X_test.shape[1])])\n",
    "                        else:\n",
    "                            # Last resort: use simple mean of features\n",
    "                            pred = np.mean(X_test.values, axis=1) * 0.01\n",
    "                    \n",
    "                    predictions[:, i] = pred\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # Generate small random noise as fallback\n",
    "                    predictions[:, i] = np.random.normal(0, 0.001, len(test_df))\n",
    "            \n",
    "            # Create output DataFrame\n",
    "            out_df = pd.DataFrame(predictions, columns=[f\"target_{i}\" for i in range(CFG.NUM_TARGET_COLUMNS)])\n",
    "            \n",
    "            # Apply stabilization to prevent flat predictions\n",
    "            out_df = _stabilize_and_detie_rows(out_df, test_df.get('date_id', None))\n",
    "            \n",
    "            return pl.DataFrame(out_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Prediction failed: {e}\")\n",
    "            # Emergency fallback\n",
    "            fallback_preds = np.random.normal(0, 0.001, (len(test), CFG.NUM_TARGET_COLUMNS))\n",
    "            out_df = pd.DataFrame(fallback_preds, columns=[f\"target_{i}\" for i in range(CFG.NUM_TARGET_COLUMNS)])\n",
    "            return pl.DataFrame(out_df)\n",
    "\n",
    "# Global predictor instance\n",
    "kaggle_predictor = KagglePredictor()\n",
    "\n",
    "def predict(test: pl.DataFrame,\n",
    "           label_lags_1_batch: pl.DataFrame,\n",
    "           label_lags_2_batch: pl.DataFrame,\n",
    "           label_lags_3_batch: pl.DataFrame,\n",
    "           label_lags_4_batch: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"Kaggle submission predict function\"\"\"\n",
    "    return kaggle_predictor.predict(test, label_lags_1_batch, label_lags_2_batch, \n",
    "                                   label_lags_3_batch, label_lags_4_batch)\n",
    "\n",
    "# Kaggle Inference Server (COMMENTED OUT FOR LOCAL TESTING)\n",
    "# inference_server = kaggle_evaluation.mitsui_inference_server.MitsuiInferenceServer(predict)\n",
    "\n",
    "# if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "#     inference_server.serve()\n",
    "# else:\n",
    "#     inference_server.run_local_gateway((str(data_path),))\n",
    "\n",
    "training_results = run_training_pipeline()\n",
    "\n",
    "# LOCAL TESTING: Enable training pipeline for verificationprint(\"üß™ LOCAL TESTING MODE - Running training pipeline for verification...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cada00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Cell 7: Local Testing & Verification ==== #\n",
    "def test_pipeline_locally():\n",
    "    \"\"\"\n",
    "    Test the complete pipeline locally without Kaggle dependencies\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üß™ Starting LOCAL TESTING of Mitsui Pipeline\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Configure for development testing\n",
    "        configure_pipeline_for_scenario('development')\n",
    "        print_pipeline_status()\n",
    "        \n",
    "        print(\"\\nüìä Testing prediction functionality...\")\n",
    "        \n",
    "        # Create dummy test data to verify prediction pipeline\n",
    "        np.random.seed(42)\n",
    "        dummy_test_data = {\n",
    "            'date_id': [1, 2, 3],\n",
    "            'feature_1': [1.2, 2.3, 3.4],\n",
    "            'feature_2': [0.5, 0.7, 0.9],\n",
    "            'feature_3': [-0.1, 0.2, 0.4]\n",
    "        }\n",
    "        \n",
    "        # Convert to polars DataFrame (as expected by Kaggle predict function)\n",
    "        test_df_polars = pl.DataFrame(dummy_test_data)\n",
    "        \n",
    "        # Create dummy label lag data\n",
    "        dummy_lags = pl.DataFrame({'dummy': [0, 0, 0]})\n",
    "        \n",
    "        print(\"üîß Testing predict function with dummy data...\")\n",
    "        \n",
    "        # Test the prediction function\n",
    "        predictions = kaggle_predictor.predict(\n",
    "            test=test_df_polars,\n",
    "            label_lags_1_batch=dummy_lags,\n",
    "            label_lags_2_batch=dummy_lags,\n",
    "            label_lags_3_batch=dummy_lags,\n",
    "            label_lags_4_batch=dummy_lags\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Predictions generated successfully!\")\n",
    "        print(f\"   Shape: {predictions.shape}\")\n",
    "        print(f\"   Columns: {len(predictions.columns)} targets\")\n",
    "        \n",
    "        # Verify prediction shape\n",
    "        expected_shape = (len(dummy_test_data['date_id']), CFG.NUM_TARGET_COLUMNS)\n",
    "        if predictions.shape == expected_shape:\n",
    "            print(f\"‚úÖ Prediction shape correct: {predictions.shape}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Prediction shape mismatch. Expected: {expected_shape}, Got: {predictions.shape}\")\n",
    "            \n",
    "        print(\"\\nüéØ LOCAL TESTING COMPLETED SUCCESSFULLY! üéâ\")\n",
    "        \n",
    "        return predictions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Local testing failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# Run local testing if this notebook is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    test_predictions = test_pipeline_locally()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
