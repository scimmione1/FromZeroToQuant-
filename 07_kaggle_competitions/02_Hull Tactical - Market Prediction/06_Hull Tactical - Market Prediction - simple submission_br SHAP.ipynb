{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "39d70b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "18d795b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8990, 98), (10, 99))"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Configuration and Data Loading (kaggle_evaluation only)\n",
    "# import kaggle_evaluation.default_inference_server as kdeval\n",
    "# DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "\n",
    "## Configuration and Data Loading (local version only)\n",
    "DATA_DIR = Path(\"01_data\")\n",
    "\n",
    "# Read CSV files from data_path\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH  = DATA_DIR / 'test.csv'\n",
    "\n",
    "VALIDATION_SIZE = 2700          # days, approx. 30% of data\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "import random\n",
    "RANDOM_SEED = random.randint(1, 10000)\n",
    "\n",
    "VOL_MULTIPLIER_LIMIT = 1.2\n",
    "VOL_WINDOW = 20\n",
    "\n",
    "def time_split_train_val(df: pd.DataFrame, val_size: int = 2700):\n",
    "    df = df.sort_values('date_id').reset_index(drop=True)\n",
    "    train_df = df.iloc[:-val_size].copy()\n",
    "    val_df   = df.iloc[-val_size:].copy()\n",
    "    return train_df, val_df\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# lower column names\n",
    "train_raw.columns = [c.lower() for c in train_raw.columns]\n",
    "test_raw.columns  = [c.lower() for c in test_raw.columns]\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "c51e9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_features = ['m4', 'm11', 'v13', 's2', 'p6', 'm12', 's1', 'v9', 'e17', 'p7'] # from EDA\n",
    "\n",
    "# # keep only main features in train_raw\n",
    "# train_p = train_raw[['date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'] + main_features].copy()\n",
    "# test_p  = test_raw[['date_id'] + main_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "2e5c69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "bd7d0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "64580af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check for nan in train_p\n",
    "# train_p.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "941f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Preparation\n",
    "excluded = {'date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'}\n",
    "feature_cols = [c for c in train_raw.columns if c not in excluded]\n",
    "feature_cols = [c for c in feature_cols if c in test_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "a4c1191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d1',\n",
       " 'd2',\n",
       " 'd3',\n",
       " 'd4',\n",
       " 'd5',\n",
       " 'd6',\n",
       " 'd7',\n",
       " 'd8',\n",
       " 'd9',\n",
       " 'e1',\n",
       " 'e10',\n",
       " 'e11',\n",
       " 'e12',\n",
       " 'e13',\n",
       " 'e14',\n",
       " 'e15',\n",
       " 'e16',\n",
       " 'e17',\n",
       " 'e18',\n",
       " 'e19',\n",
       " 'e2',\n",
       " 'e20',\n",
       " 'e3',\n",
       " 'e4',\n",
       " 'e5',\n",
       " 'e6',\n",
       " 'e7',\n",
       " 'e8',\n",
       " 'e9',\n",
       " 'i1',\n",
       " 'i2',\n",
       " 'i3',\n",
       " 'i4',\n",
       " 'i5',\n",
       " 'i6',\n",
       " 'i7',\n",
       " 'i8',\n",
       " 'i9',\n",
       " 'm1',\n",
       " 'm10',\n",
       " 'm11',\n",
       " 'm12',\n",
       " 'm13',\n",
       " 'm14',\n",
       " 'm15',\n",
       " 'm16',\n",
       " 'm17',\n",
       " 'm18',\n",
       " 'm2',\n",
       " 'm3',\n",
       " 'm4',\n",
       " 'm5',\n",
       " 'm6',\n",
       " 'm7',\n",
       " 'm8',\n",
       " 'm9',\n",
       " 'p1',\n",
       " 'p10',\n",
       " 'p11',\n",
       " 'p12',\n",
       " 'p13',\n",
       " 'p2',\n",
       " 'p3',\n",
       " 'p4',\n",
       " 'p5',\n",
       " 'p6',\n",
       " 'p7',\n",
       " 'p8',\n",
       " 'p9',\n",
       " 's1',\n",
       " 's10',\n",
       " 's11',\n",
       " 's12',\n",
       " 's2',\n",
       " 's3',\n",
       " 's4',\n",
       " 's5',\n",
       " 's6',\n",
       " 's7',\n",
       " 's8',\n",
       " 's9',\n",
       " 'v1',\n",
       " 'v10',\n",
       " 'v11',\n",
       " 'v12',\n",
       " 'v13',\n",
       " 'v2',\n",
       " 'v3',\n",
       " 'v4',\n",
       " 'v5',\n",
       " 'v6',\n",
       " 'v7',\n",
       " 'v8',\n",
       " 'v9']"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "a9fc3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame, median_map: Dict[str, float], feature_cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in feature_cols:\n",
    "        # if c not in df.columns:\n",
    "        #     df[c] = 0.0\n",
    "        #     df[f'{c}_was_na'] = 1\n",
    "        #     continue\n",
    "        if df[c].dtype.kind in 'fiu':\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "        else:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "4cf47989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 188\n"
     ]
    }
   ],
   "source": [
    "## Train / Validation Split and Median Imputation\n",
    "train_df, val_df = time_split_train_val(train_raw, val_size=VALIDATION_SIZE)\n",
    "\n",
    "median_map = {c: float(train_df[c].median(skipna=True)) if train_df[c].dtype.kind in 'fiu' else 0.0 \n",
    "              for c in feature_cols}\n",
    "\n",
    "train_p = prepare_df(train_df, median_map, feature_cols)\n",
    "val_p   = prepare_df(val_df, median_map, feature_cols)\n",
    "test_p  = prepare_df(test_raw, median_map, feature_cols)\n",
    "\n",
    "final_features = [f for c in feature_cols for f in (c, f\"{c}_was_na\")]\n",
    "print(\"Number of features:\", len(final_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b58e62ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "54eb7391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_id', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9',\n",
      "       ...\n",
      "       'v12_was_na', 'v13_was_na', 'v2_was_na', 'v3_was_na', 'v4_was_na',\n",
      "       'v5_was_na', 'v6_was_na', 'v7_was_na', 'v8_was_na', 'v9_was_na'],\n",
      "      dtype='object', length=192)\n"
     ]
    }
   ],
   "source": [
    "print(train_p.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "cc84dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d1',\n",
       " 'd1_was_na',\n",
       " 'd2',\n",
       " 'd2_was_na',\n",
       " 'd3',\n",
       " 'd3_was_na',\n",
       " 'd4',\n",
       " 'd4_was_na',\n",
       " 'd5',\n",
       " 'd5_was_na',\n",
       " 'd6',\n",
       " 'd6_was_na',\n",
       " 'd7',\n",
       " 'd7_was_na',\n",
       " 'd8',\n",
       " 'd8_was_na',\n",
       " 'd9',\n",
       " 'd9_was_na',\n",
       " 'e1',\n",
       " 'e1_was_na',\n",
       " 'e10',\n",
       " 'e10_was_na',\n",
       " 'e11',\n",
       " 'e11_was_na',\n",
       " 'e12',\n",
       " 'e12_was_na',\n",
       " 'e13',\n",
       " 'e13_was_na',\n",
       " 'e14',\n",
       " 'e14_was_na',\n",
       " 'e15',\n",
       " 'e15_was_na',\n",
       " 'e16',\n",
       " 'e16_was_na',\n",
       " 'e17',\n",
       " 'e17_was_na',\n",
       " 'e18',\n",
       " 'e18_was_na',\n",
       " 'e19',\n",
       " 'e19_was_na',\n",
       " 'e2',\n",
       " 'e2_was_na',\n",
       " 'e20',\n",
       " 'e20_was_na',\n",
       " 'e3',\n",
       " 'e3_was_na',\n",
       " 'e4',\n",
       " 'e4_was_na',\n",
       " 'e5',\n",
       " 'e5_was_na',\n",
       " 'e6',\n",
       " 'e6_was_na',\n",
       " 'e7',\n",
       " 'e7_was_na',\n",
       " 'e8',\n",
       " 'e8_was_na',\n",
       " 'e9',\n",
       " 'e9_was_na',\n",
       " 'i1',\n",
       " 'i1_was_na',\n",
       " 'i2',\n",
       " 'i2_was_na',\n",
       " 'i3',\n",
       " 'i3_was_na',\n",
       " 'i4',\n",
       " 'i4_was_na',\n",
       " 'i5',\n",
       " 'i5_was_na',\n",
       " 'i6',\n",
       " 'i6_was_na',\n",
       " 'i7',\n",
       " 'i7_was_na',\n",
       " 'i8',\n",
       " 'i8_was_na',\n",
       " 'i9',\n",
       " 'i9_was_na',\n",
       " 'm1',\n",
       " 'm1_was_na',\n",
       " 'm10',\n",
       " 'm10_was_na',\n",
       " 'm11',\n",
       " 'm11_was_na',\n",
       " 'm12',\n",
       " 'm12_was_na',\n",
       " 'm13',\n",
       " 'm13_was_na',\n",
       " 'm14',\n",
       " 'm14_was_na',\n",
       " 'm15',\n",
       " 'm15_was_na',\n",
       " 'm16',\n",
       " 'm16_was_na',\n",
       " 'm17',\n",
       " 'm17_was_na',\n",
       " 'm18',\n",
       " 'm18_was_na',\n",
       " 'm2',\n",
       " 'm2_was_na',\n",
       " 'm3',\n",
       " 'm3_was_na',\n",
       " 'm4',\n",
       " 'm4_was_na',\n",
       " 'm5',\n",
       " 'm5_was_na',\n",
       " 'm6',\n",
       " 'm6_was_na',\n",
       " 'm7',\n",
       " 'm7_was_na',\n",
       " 'm8',\n",
       " 'm8_was_na',\n",
       " 'm9',\n",
       " 'm9_was_na',\n",
       " 'p1',\n",
       " 'p1_was_na',\n",
       " 'p10',\n",
       " 'p10_was_na',\n",
       " 'p11',\n",
       " 'p11_was_na',\n",
       " 'p12',\n",
       " 'p12_was_na',\n",
       " 'p13',\n",
       " 'p13_was_na',\n",
       " 'p2',\n",
       " 'p2_was_na',\n",
       " 'p3',\n",
       " 'p3_was_na',\n",
       " 'p4',\n",
       " 'p4_was_na',\n",
       " 'p5',\n",
       " 'p5_was_na',\n",
       " 'p6',\n",
       " 'p6_was_na',\n",
       " 'p7',\n",
       " 'p7_was_na',\n",
       " 'p8',\n",
       " 'p8_was_na',\n",
       " 'p9',\n",
       " 'p9_was_na',\n",
       " 's1',\n",
       " 's1_was_na',\n",
       " 's10',\n",
       " 's10_was_na',\n",
       " 's11',\n",
       " 's11_was_na',\n",
       " 's12',\n",
       " 's12_was_na',\n",
       " 's2',\n",
       " 's2_was_na',\n",
       " 's3',\n",
       " 's3_was_na',\n",
       " 's4',\n",
       " 's4_was_na',\n",
       " 's5',\n",
       " 's5_was_na',\n",
       " 's6',\n",
       " 's6_was_na',\n",
       " 's7',\n",
       " 's7_was_na',\n",
       " 's8',\n",
       " 's8_was_na',\n",
       " 's9',\n",
       " 's9_was_na',\n",
       " 'v1',\n",
       " 'v1_was_na',\n",
       " 'v10',\n",
       " 'v10_was_na',\n",
       " 'v11',\n",
       " 'v11_was_na',\n",
       " 'v12',\n",
       " 'v12_was_na',\n",
       " 'v13',\n",
       " 'v13_was_na',\n",
       " 'v2',\n",
       " 'v2_was_na',\n",
       " 'v3',\n",
       " 'v3_was_na',\n",
       " 'v4',\n",
       " 'v4_was_na',\n",
       " 'v5',\n",
       " 'v5_was_na',\n",
       " 'v6',\n",
       " 'v6_was_na',\n",
       " 'v7',\n",
       " 'v7_was_na',\n",
       " 'v8',\n",
       " 'v8_was_na',\n",
       " 'v9',\n",
       " 'v9_was_na']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "2c9d2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 6290\n",
      "NaN values in y_train: 0\n",
      "After filling NaN values:\n",
      "NaN values in X_train: 0\n",
      "NaN values in y_train: 0\n",
      "NaN values in X_val: 0\n",
      "NaN values in y_val: 0\n"
     ]
    }
   ],
   "source": [
    "# === Bayesian Ridge Training ===\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepara i dati (usando gli stessi DataFrame)\n",
    "X_train = train_p[final_features]\n",
    "y_train = train_p['forward_returns']\n",
    "X_val   = val_p[final_features]\n",
    "y_val   = val_p['forward_returns']\n",
    "\n",
    "# Check for NaN values and handle them\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "X_train = X_train.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "y_val = y_val.fillna(0)\n",
    "\n",
    "# count nan in X_train, y_train, X_val, y_val\n",
    "print(f\"After filling NaN values:\")\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "print(f\"NaN values in X_val: {X_val.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_val: {y_val.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "0c814528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.010272\n"
     ]
    }
   ],
   "source": [
    "# Crea e allena il modello\n",
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione sul validation set\n",
    "val_pred = model.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"Validation RMSE: {rmse_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "5e627045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market annualized volatility: 0.1698\n",
      "Chosen scaling factor k=5.000 | Validation Sharpe=0.69\n"
     ]
    }
   ],
   "source": [
    "# === Volatility Scaling Calibration (BayesianRidge version) ===\n",
    "def strategy_stats(returns, exposures):\n",
    "    \"\"\"Compute Sharpe and volatility for a given exposure series.\"\"\"\n",
    "    strat = exposures * returns\n",
    "    mean = np.nanmean(strat)\n",
    "    std  = np.nanstd(strat)\n",
    "    sharpe = (mean / (std + 1e-9)) * np.sqrt(252)\n",
    "    vol = std * np.sqrt(252)\n",
    "    return {'sharpe': sharpe, 'vol': vol}\n",
    "\n",
    "# Ensure validation data has no NaN values\n",
    "val_features_clean = val_p[final_features].fillna(0)\n",
    "\n",
    "# Predict mean and std (Bayesian posterior uncertainty)\n",
    "val_pred_mean, val_pred_std = model.predict(val_features_clean, return_std=True)\n",
    "\n",
    "# Define market volatility for scaling reference\n",
    "market_vol = np.nanstd(train_p['forward_returns']) * np.sqrt(252)\n",
    "print(f\"Market annualized volatility: {market_vol:.4f}\")\n",
    "\n",
    "# We'll use a dynamic confidence weight: confidence = 1 / (1 + std)\n",
    "confidence = 1 / (1 + val_pred_std)\n",
    "val_conf_adj = val_pred_mean * confidence  # lower exposure when uncertainty is high\n",
    "\n",
    "# Grid search for best scaling factor k (Sharpe ratio under vol constraint)\n",
    "best_k, best_sharpe = 0.1, -1e9\n",
    "for k in np.linspace(0.01, 5.0, 100):\n",
    "    exposures = np.clip((k * val_conf_adj), 0, 2)\n",
    "    stats = strategy_stats(val_p['forward_returns'], exposures)\n",
    "    if stats['vol'] <= VOL_MULTIPLIER_LIMIT * market_vol and stats['sharpe'] > best_sharpe:\n",
    "        best_k = k\n",
    "        best_sharpe = stats['sharpe']\n",
    "\n",
    "print(f\"Chosen scaling factor k={best_k:.3f} | Validation Sharpe={best_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "65262718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_br.csv\n"
     ]
    }
   ],
   "source": [
    "## Test Predictions + Smoothing\n",
    "test_features_clean = test_p[final_features].fillna(0)\n",
    "test_pred = model.predict(test_features_clean)\n",
    "\n",
    "alpha = 0.8\n",
    "smoothed_allocation = []\n",
    "prev = 0.0\n",
    "for x in np.clip(best_k * test_pred, 0, 2):\n",
    "    s = alpha * x + (1 - alpha) * prev\n",
    "    smoothed_allocation.append(s)\n",
    "    prev = s\n",
    "smoothed_allocation = np.array(smoothed_allocation)\n",
    "\n",
    "# replace in final submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'date_id': test_p['date_id'],\n",
    "    'prediction': smoothed_allocation  \n",
    "})\n",
    "# submission_df.to_csv(\"submission_br.csv\", index=False)\n",
    "print(\"Saved submission_br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "40188a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SHAP explainer for Bayesian Ridge model...\n",
      "\n",
      "Top 20 Most Important Features (SHAP values):\n",
      "    feature  importance\n",
      "100      m4    0.000545\n",
      "170     v13    0.000512\n",
      "80      m11    0.000471\n",
      "146      s2    0.000410\n",
      "54       e8    0.000371\n",
      "110      m9    0.000344\n",
      "44       e3    0.000243\n",
      "132      p7    0.000242\n",
      "6        d4    0.000233\n",
      "82      m12    0.000209\n",
      "40       e2    0.000209\n",
      "138      s1    0.000203\n",
      "116     p11    0.000197\n",
      "96       m2    0.000192\n",
      "130      p6    0.000189\n",
      "134      p8    0.000161\n",
      "60       i2    0.000149\n",
      "118     p12    0.000139\n",
      "98       m3    0.000126\n",
      "144     s12    0.000121\n"
     ]
    }
   ],
   "source": [
    "# Install shap if not already installed: pip install shap\n",
    "import shap\n",
    "\n",
    "print(\"Creating SHAP explainer for Bayesian Ridge model...\")\n",
    "\n",
    "# For linear models like BayesianRidge, we can use the Linear explainer\n",
    "explainer = shap.LinearExplainer(model, X_train)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "# # Alternative: Use the general Explainer (slower but works for any model)\n",
    "# explainer = shap.Explainer(model, X_train)\n",
    "# shap_values = explainer(X_train)\n",
    "\n",
    "# Get feature importance as mean absolute SHAP values\n",
    "feature_importance_shap = pd.DataFrame({\n",
    "'feature': X_train.columns,\n",
    "'importance': np.abs(shap_values).mean(axis=0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features (SHAP values):\")\n",
    "print(feature_importance_shap.head(20))\n",
    "\n",
    "# Plot SHAP summary\n",
    "# shap.summary_plot(shap_values, X_train, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "cb838fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kaggle Evaluation Metric:\n",
    "\n",
    "strategy_returns = risk_free_rate * (1 - position) + position * forward_returns\n",
    "\n",
    "if position = 0 → invest in risk-free asset,\n",
    "\n",
    "if position = 1 → invest like the market,\n",
    "\n",
    "if position = 2 → you are leveraged ×2 on the market.\n",
    "\n",
    "\n",
    "def score():\n",
    "\n",
    "strategy_returns = rf * (1 - pos) + pos * fwd_returns\n",
    "\n",
    "In the code, the calibration seeks the best Sharpe of the portfolio exposed to pos by calculating:\n",
    "\n",
    "strat = exposures * returns\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "f6b6992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Kaggle Inference Server Wrapper (BayesianRidge version) ===\n",
    "\n",
    "# _model = model                     # BayesianRidge fitted model\n",
    "# _best_k = best_k                   # scaling factor from validation calibration\n",
    "# _history_returns = list(train_p['forward_returns'].iloc[-VOL_WINDOW:].tolist())\n",
    "\n",
    "# def predict(pl_df: pl.DataFrame) -> float:\n",
    "#     \"\"\"Predict allocation for one timestep (Kaggle competition API).\"\"\"\n",
    "#     global _history_returns\n",
    "#     # Convert Polars → Pandas\n",
    "#     pdf = pl_df.to_pandas()\n",
    "    \n",
    "#     # Apply same preprocessing\n",
    "#     pdf_p = prepare_df(pdf, median_map, feature_cols)\n",
    "#     for f in final_features:\n",
    "#         if f not in pdf_p.columns:\n",
    "#             pdf_p[f] = 0.0\n",
    "    \n",
    "#     # Convert to NumPy and predict\n",
    "#     x = pdf_p[final_features].to_numpy()\n",
    "\n",
    "#     \"\"\"\n",
    "#     added standard deviation based confidence adjustment\n",
    "#     to reduce allocation when uncertainty is high\n",
    "#     \"\"\"\n",
    "\n",
    "#     pred, std = model.predict(x, return_std=True)\n",
    "    \n",
    "#     # Compute rolling volatility estimate\n",
    "#     vol_est = np.std(_history_returns) or 1e-3\n",
    "#     confidence = 1 / (1 + std)\n",
    "#     alloc = float(np.clip(_best_k * pred * confidence / (vol_est + 1e-9), 0, 2))\n",
    "    \n",
    "#     # Update history (for volatility tracking)\n",
    "#     if 'lagged_forward_returns' in pl_df.columns:\n",
    "#         try:\n",
    "#             _history_returns.append(float(pl_df['lagged_forward_returns'][0]))\n",
    "#         except:\n",
    "#             _history_returns.append(0.0)\n",
    "#     else:\n",
    "#         _history_returns.append(0.0)\n",
    "    \n",
    "#     # Keep only the last VOL_WINDOW entries\n",
    "#     _history_returns = _history_returns[-VOL_WINDOW:]\n",
    "#     return alloc\n",
    "\n",
    "# # Instantiate the Kaggle inference server\n",
    "# server = kdeval.DefaultInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     server.serve()\n",
    "# else:\n",
    "#     server.run_local_gateway((str(DATA_DIR),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d9153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcbe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115cdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58021807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
