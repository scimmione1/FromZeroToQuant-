{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "39d70b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "18d795b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8990, 98), (10, 99))"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Configuration and Data Loading (kaggle_evaluation only)\n",
    "# import kaggle_evaluation.default_inference_server as kdeval\n",
    "# DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "\n",
    "## Configuration and Data Loading (local version only)\n",
    "DATA_DIR = Path(\"01_data\")\n",
    "\n",
    "# Read CSV files from data_path\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH  = DATA_DIR / 'test.csv'\n",
    "\n",
    "VALIDATION_SIZE = 2700          # days, approx. 30% of data\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "import random\n",
    "RANDOM_SEED = random.randint(1, 10000)\n",
    "\n",
    "VOL_MULTIPLIER_LIMIT = 1.2\n",
    "VOL_WINDOW = 20\n",
    "\n",
    "def time_split_train_val(df: pd.DataFrame, val_size: int = 2700):\n",
    "    df = df.sort_values('date_id').reset_index(drop=True)\n",
    "    train_df = df.iloc[:-val_size].copy()\n",
    "    val_df   = df.iloc[-val_size:].copy()\n",
    "    return train_df, val_df\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# lower column names\n",
    "train_raw.columns = [c.lower() for c in train_raw.columns]\n",
    "test_raw.columns  = [c.lower() for c in test_raw.columns]\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "c51e9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_features = ['m4', 'm11', 'v13', 's2', 'p6', 'm12', 's1', 'v9', 'e17', 'p7'] # from EDA\n",
    "\n",
    "# keep only main features in train_raw\n",
    "train_p = train_raw[['date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'] + main_features].copy()\n",
    "test_p  = test_raw[['date_id'] + main_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2e5c69fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8990, 14)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bd7d0f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>forward_returns</th>\n",
       "      <th>risk_free_rate</th>\n",
       "      <th>market_forward_excess_returns</th>\n",
       "      <th>m4</th>\n",
       "      <th>m11</th>\n",
       "      <th>v13</th>\n",
       "      <th>s2</th>\n",
       "      <th>p6</th>\n",
       "      <th>m12</th>\n",
       "      <th>s1</th>\n",
       "      <th>v9</th>\n",
       "      <th>e17</th>\n",
       "      <th>p7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.002421</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.003038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.008495</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.009624</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.010243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.004662</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.004046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.011686</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>-0.012301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_id  forward_returns  risk_free_rate  market_forward_excess_returns  \\\n",
       "0        0        -0.002421        0.000301                      -0.003038   \n",
       "1        1        -0.008495        0.000303                      -0.009114   \n",
       "2        2        -0.009624        0.000301                      -0.010243   \n",
       "3        3         0.004662        0.000299                       0.004046   \n",
       "4        4        -0.011686        0.000299                      -0.012301   \n",
       "\n",
       "   m4  m11  v13  s2  p6  m12  s1  v9  e17  p7  \n",
       "0 NaN  NaN  NaN NaN NaN  NaN NaN NaN  NaN NaN  \n",
       "1 NaN  NaN  NaN NaN NaN  NaN NaN NaN  NaN NaN  \n",
       "2 NaN  NaN  NaN NaN NaN  NaN NaN NaN  NaN NaN  \n",
       "3 NaN  NaN  NaN NaN NaN  NaN NaN NaN  NaN NaN  \n",
       "4 NaN  NaN  NaN NaN NaN  NaN NaN NaN  NaN NaN  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "64580af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_id                             0\n",
       "forward_returns                     0\n",
       "risk_free_rate                      0\n",
       "market_forward_excess_returns       0\n",
       "m4                               1006\n",
       "m11                              1006\n",
       "v13                              1511\n",
       "s2                               1006\n",
       "p6                               1638\n",
       "m12                              1006\n",
       "s1                               1006\n",
       "v9                               4539\n",
       "e17                              1006\n",
       "p7                               1616\n",
       "dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nan in train_p\n",
    "train_p.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "941f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Preparation\n",
    "excluded = {'date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'}\n",
    "feature_cols = [c for c in train_p.columns if c not in excluded]\n",
    "feature_cols = [c for c in feature_cols if c in test_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a4c1191f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m4', 'm11', 'v13', 's2', 'p6', 'm12', 's1', 'v9', 'e17', 'p7']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a9fc3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame, median_map: Dict[str, float], feature_cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in feature_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "            df[f'{c}_was_na'] = 1\n",
    "            continue\n",
    "        if df[c].dtype.kind in 'fiu':\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "        else:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4cf47989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 20\n"
     ]
    }
   ],
   "source": [
    "## Train / Validation Split and Median Imputation\n",
    "train_df, val_df = time_split_train_val(train_raw, val_size=VALIDATION_SIZE)\n",
    "\n",
    "median_map = {c: float(train_df[c].median(skipna=True)) if train_df[c].dtype.kind in 'fiu' else 0.0 \n",
    "              for c in feature_cols}\n",
    "\n",
    "train_p = prepare_df(train_df, median_map, feature_cols)\n",
    "val_p   = prepare_df(val_df, median_map, feature_cols)\n",
    "test_p  = prepare_df(test_raw, median_map, feature_cols)\n",
    "\n",
    "final_features = [f for c in feature_cols for f in (c, f\"{c}_was_na\")]\n",
    "print(\"Number of features:\", len(final_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "b58e62ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_id</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>...</th>\n",
       "      <th>m4_was_na</th>\n",
       "      <th>m11_was_na</th>\n",
       "      <th>v13_was_na</th>\n",
       "      <th>s2_was_na</th>\n",
       "      <th>p6_was_na</th>\n",
       "      <th>m12_was_na</th>\n",
       "      <th>s1_was_na</th>\n",
       "      <th>v9_was_na</th>\n",
       "      <th>e17_was_na</th>\n",
       "      <th>p7_was_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   date_id  d1  d2  d3  d4  d5  d6  d7  d8  d9  ...  m4_was_na  m11_was_na  \\\n",
       "0        0   0   0   0   1   1   0   0   0   1  ...          1           1   \n",
       "1        1   0   0   0   1   1   0   0   0   1  ...          1           1   \n",
       "2        2   0   0   0   1   0   0   0   0   1  ...          1           1   \n",
       "3        3   0   0   0   1   0   0   0   0   0  ...          1           1   \n",
       "4        4   0   0   0   1   0   0   0   0   0  ...          1           1   \n",
       "\n",
       "   v13_was_na  s2_was_na  p6_was_na  m12_was_na  s1_was_na  v9_was_na  \\\n",
       "0           1          1          1           1          1          1   \n",
       "1           1          1          1           1          1          1   \n",
       "2           1          1          1           1          1          1   \n",
       "3           1          1          1           1          1          1   \n",
       "4           1          1          1           1          1          1   \n",
       "\n",
       "   e17_was_na  p7_was_na  \n",
       "0           1          1  \n",
       "1           1          1  \n",
       "2           1          1  \n",
       "3           1          1  \n",
       "4           1          1  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "54eb7391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['date_id', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9',\n",
      "       ...\n",
      "       'm4_was_na', 'm11_was_na', 'v13_was_na', 's2_was_na', 'p6_was_na',\n",
      "       'm12_was_na', 's1_was_na', 'v9_was_na', 'e17_was_na', 'p7_was_na'],\n",
      "      dtype='object', length=108)\n"
     ]
    }
   ],
   "source": [
    "print(train_p.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cc84dbbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m4',\n",
       " 'm4_was_na',\n",
       " 'm11',\n",
       " 'm11_was_na',\n",
       " 'v13',\n",
       " 'v13_was_na',\n",
       " 's2',\n",
       " 's2_was_na',\n",
       " 'p6',\n",
       " 'p6_was_na',\n",
       " 'm12',\n",
       " 'm12_was_na',\n",
       " 's1',\n",
       " 's1_was_na',\n",
       " 'v9',\n",
       " 'v9_was_na',\n",
       " 'e17',\n",
       " 'e17_was_na',\n",
       " 'p7',\n",
       " 'p7_was_na']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2c9d2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 0\n",
      "NaN values in y_train: 0\n",
      "After filling NaN values:\n",
      "NaN values in X_train: 0\n",
      "NaN values in y_train: 0\n",
      "NaN values in X_val: 0\n",
      "NaN values in y_val: 0\n"
     ]
    }
   ],
   "source": [
    "# === Bayesian Ridge Training ===\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepara i dati (usando gli stessi DataFrame)\n",
    "X_train = train_p[final_features]\n",
    "y_train = train_p['forward_returns']\n",
    "X_val   = val_p[final_features]\n",
    "y_val   = val_p['forward_returns']\n",
    "\n",
    "# Check for NaN values and handle them\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "X_train = X_train.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "y_val = y_val.fillna(0)\n",
    "\n",
    "# count nan in X_train, y_train, X_val, y_val\n",
    "print(f\"After filling NaN values:\")\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "print(f\"NaN values in X_val: {X_val.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_val: {y_val.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0c814528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE: 0.010211\n"
     ]
    }
   ],
   "source": [
    "# Crea e allena il modello\n",
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione sul validation set\n",
    "val_pred = model.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"Validation RMSE: {rmse_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5e627045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market annualized volatility: 0.1698\n",
      "Chosen scaling factor k=5.000 | Validation Sharpe=0.88\n"
     ]
    }
   ],
   "source": [
    "# === Volatility Scaling Calibration (BayesianRidge version) ===\n",
    "def strategy_stats(returns, exposures):\n",
    "    \"\"\"Compute Sharpe and volatility for a given exposure series.\"\"\"\n",
    "    strat = exposures * returns\n",
    "    mean = np.nanmean(strat)\n",
    "    std  = np.nanstd(strat)\n",
    "    sharpe = (mean / (std + 1e-9)) * np.sqrt(252)\n",
    "    vol = std * np.sqrt(252)\n",
    "    return {'sharpe': sharpe, 'vol': vol}\n",
    "\n",
    "# Ensure validation data has no NaN values\n",
    "val_features_clean = val_p[final_features].fillna(0)\n",
    "\n",
    "# Predict mean and std (Bayesian posterior uncertainty)\n",
    "val_pred_mean, val_pred_std = model.predict(val_features_clean, return_std=True)\n",
    "\n",
    "# Define market volatility for scaling reference\n",
    "market_vol = np.nanstd(train_p['forward_returns']) * np.sqrt(252)\n",
    "print(f\"Market annualized volatility: {market_vol:.4f}\")\n",
    "\n",
    "# We'll use a dynamic confidence weight: confidence = 1 / (1 + std)\n",
    "confidence = 1 / (1 + val_pred_std)\n",
    "val_conf_adj = val_pred_mean * confidence  # lower exposure when uncertainty is high\n",
    "\n",
    "# Grid search for best scaling factor k (Sharpe ratio under vol constraint)\n",
    "best_k, best_sharpe = 0.1, -1e9\n",
    "for k in np.linspace(0.01, 5.0, 100):\n",
    "    exposures = np.clip((k * val_conf_adj), 0, 2)\n",
    "    stats = strategy_stats(val_p['forward_returns'], exposures)\n",
    "    if stats['vol'] <= VOL_MULTIPLIER_LIMIT * market_vol and stats['sharpe'] > best_sharpe:\n",
    "        best_k = k\n",
    "        best_sharpe = stats['sharpe']\n",
    "\n",
    "print(f\"Chosen scaling factor k={best_k:.3f} | Validation Sharpe={best_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "65262718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_br.csv\n"
     ]
    }
   ],
   "source": [
    "## Test Predictions + Smoothing\n",
    "test_features_clean = test_p[final_features].fillna(0)\n",
    "test_pred = model.predict(test_features_clean)\n",
    "\n",
    "alpha = 0.8\n",
    "smoothed_allocation = []\n",
    "prev = 0.0\n",
    "for x in np.clip(best_k * test_pred, 0, 2):\n",
    "    s = alpha * x + (1 - alpha) * prev\n",
    "    smoothed_allocation.append(s)\n",
    "    prev = s\n",
    "smoothed_allocation = np.array(smoothed_allocation)\n",
    "\n",
    "# replace in final submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'date_id': test_p['date_id'],\n",
    "    'prediction': smoothed_allocation  \n",
    "})\n",
    "# submission_df.to_csv(\"submission_br.csv\", index=False)\n",
    "print(\"Saved submission_br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "cb838fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kaggle Evaluation Metric:\n",
    "\n",
    "strategy_returns = risk_free_rate * (1 - position) + position * forward_returns\n",
    "\n",
    "if position = 0 → invest in risk-free asset,\n",
    "\n",
    "if position = 1 → invest like the market,\n",
    "\n",
    "if position = 2 → you are leveraged ×2 on the market.\n",
    "\n",
    "\n",
    "def score():\n",
    "\n",
    "strategy_returns = rf * (1 - pos) + pos * fwd_returns\n",
    "\n",
    "In the code, the calibration seeks the best Sharpe of the portfolio exposed to pos by calculating:\n",
    "\n",
    "strat = exposures * returns\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f6b6992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Kaggle Inference Server Wrapper (BayesianRidge version) ===\n",
    "\n",
    "# _model = model                     # BayesianRidge fitted model\n",
    "# _best_k = best_k                   # scaling factor from validation calibration\n",
    "# _history_returns = list(train_p['forward_returns'].iloc[-VOL_WINDOW:].tolist())\n",
    "\n",
    "# def predict(pl_df: pl.DataFrame) -> float:\n",
    "#     \"\"\"Predict allocation for one timestep (Kaggle competition API).\"\"\"\n",
    "#     global _history_returns\n",
    "#     # Convert Polars → Pandas\n",
    "#     pdf = pl_df.to_pandas()\n",
    "    \n",
    "#     # Apply same preprocessing\n",
    "#     pdf_p = prepare_df(pdf, median_map, feature_cols)\n",
    "#     for f in final_features:\n",
    "#         if f not in pdf_p.columns:\n",
    "#             pdf_p[f] = 0.0\n",
    "    \n",
    "#     # Convert to NumPy and predict\n",
    "#     x = pdf_p[final_features].to_numpy()\n",
    "\n",
    "#     \"\"\"\n",
    "#     added standard deviation based confidence adjustment\n",
    "#     to reduce allocation when uncertainty is high\n",
    "#     \"\"\"\n",
    "\n",
    "#     pred, std = model.predict(x, return_std=True)\n",
    "    \n",
    "#     # Compute rolling volatility estimate\n",
    "#     vol_est = np.std(_history_returns) or 1e-3\n",
    "#     confidence = 1 / (1 + std)\n",
    "#     alloc = float(np.clip(_best_k * pred * confidence / (vol_est + 1e-9), 0, 2))\n",
    "    \n",
    "#     # Update history (for volatility tracking)\n",
    "#     if 'lagged_forward_returns' in pl_df.columns:\n",
    "#         try:\n",
    "#             _history_returns.append(float(pl_df['lagged_forward_returns'][0]))\n",
    "#         except:\n",
    "#             _history_returns.append(0.0)\n",
    "#     else:\n",
    "#         _history_returns.append(0.0)\n",
    "    \n",
    "#     # Keep only the last VOL_WINDOW entries\n",
    "#     _history_returns = _history_returns[-VOL_WINDOW:]\n",
    "#     return alloc\n",
    "\n",
    "# # Instantiate the Kaggle inference server\n",
    "# server = kdeval.DefaultInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     server.serve()\n",
    "# else:\n",
    "#     server.run_local_gateway((str(DATA_DIR),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d9153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcbe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115cdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58021807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
