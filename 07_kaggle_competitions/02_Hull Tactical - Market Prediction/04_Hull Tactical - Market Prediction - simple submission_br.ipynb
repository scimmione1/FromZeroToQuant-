{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d70b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18d795b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8990, 98), (10, 99))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Configuration and Data Loading (kaggle_evaluation only)\n",
    "# import kaggle_evaluation.default_inference_server as kdeval\n",
    "# DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "\n",
    "## Configuration and Data Loading (local version only)\n",
    "DATA_DIR = Path(\"01_data\")\n",
    "\n",
    "# Read CSV files from data_path\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH  = DATA_DIR / 'test.csv'\n",
    "\n",
    "VALIDATION_SIZE = 2700          # days, approx. 30% of data\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "import random\n",
    "RANDOM_SEED = random.randint(1, 10000)\n",
    "\n",
    "VOL_MULTIPLIER_LIMIT = 1.2\n",
    "VOL_WINDOW = 20\n",
    "\n",
    "def time_split_train_val(df: pd.DataFrame, val_size: int = 2700):\n",
    "    df = df.sort_values('date_id').reset_index(drop=True)\n",
    "    train_df = df.iloc[:-val_size].copy()\n",
    "    val_df   = df.iloc[-val_size:].copy()\n",
    "    return train_df, val_df\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "941f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Preparation\n",
    "excluded = {'date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'}\n",
    "feature_cols = [c for c in train_raw.columns if c not in excluded]\n",
    "feature_cols = [c for c in feature_cols if c in test_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fc3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame, median_map: Dict[str, float], feature_cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in feature_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "            df[f'{c}_was_na'] = 1\n",
    "            continue\n",
    "        if df[c].dtype.kind in 'fiu':\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "        else:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cf47989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 188\n"
     ]
    }
   ],
   "source": [
    "## Train / Validation Split and Median Imputation\n",
    "train_df, val_df = time_split_train_val(train_raw, val_size=VALIDATION_SIZE)\n",
    "\n",
    "median_map = {c: float(train_df[c].median(skipna=True)) if train_df[c].dtype.kind in 'fiu' else 0.0 \n",
    "              for c in feature_cols}\n",
    "\n",
    "train_p = prepare_df(train_df, median_map, feature_cols)\n",
    "val_p   = prepare_df(val_df, median_map, feature_cols)\n",
    "test_p  = prepare_df(test_raw, median_map, feature_cols)\n",
    "\n",
    "final_features = [f for c in feature_cols for f in (c, f\"{c}_was_na\")]\n",
    "print(\"Number of features:\", len(final_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5935853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c9d2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 6290\n",
      "NaN values in y_train: 0\n",
      "Validation RMSE: 0.010272\n"
     ]
    }
   ],
   "source": [
    "# === Bayesian Ridge Training ===\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepara i dati (usando gli stessi DataFrame)\n",
    "X_train = train_p[final_features]\n",
    "y_train = train_p['forward_returns']\n",
    "X_val   = val_p[final_features]\n",
    "y_val   = val_p['forward_returns']\n",
    "\n",
    "# Check for NaN values and handle them\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "X_train = X_train.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "y_val = y_val.fillna(0)\n",
    "\n",
    "# Crea e allena il modello\n",
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione sul validation set\n",
    "val_pred = model.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"Validation RMSE: {rmse_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e627045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market annualized volatility: 0.1698\n",
      "Chosen scaling factor k=5.000 | Validation Sharpe=0.69\n"
     ]
    }
   ],
   "source": [
    "# === Volatility Scaling Calibration (BayesianRidge version) ===\n",
    "def strategy_stats(returns, exposures):\n",
    "    \"\"\"Compute Sharpe and volatility for a given exposure series.\"\"\"\n",
    "    strat = exposures * returns\n",
    "    mean = np.nanmean(strat)\n",
    "    std  = np.nanstd(strat)\n",
    "    sharpe = (mean / (std + 1e-9)) * np.sqrt(252)\n",
    "    vol = std * np.sqrt(252)\n",
    "    return {'sharpe': sharpe, 'vol': vol}\n",
    "\n",
    "# Ensure validation data has no NaN values\n",
    "val_features_clean = val_p[final_features].fillna(0)\n",
    "\n",
    "# Predict mean and std (Bayesian posterior uncertainty)\n",
    "val_pred_mean, val_pred_std = model.predict(val_features_clean, return_std=True)\n",
    "\n",
    "# Define market volatility for scaling reference\n",
    "market_vol = np.nanstd(train_p['forward_returns']) * np.sqrt(252)\n",
    "print(f\"Market annualized volatility: {market_vol:.4f}\")\n",
    "\n",
    "# We'll use a dynamic confidence weight: confidence = 1 / (1 + std)\n",
    "confidence = 1 / (1 + val_pred_std)\n",
    "val_conf_adj = val_pred_mean * confidence  # lower exposure when uncertainty is high\n",
    "\n",
    "# Grid search for best scaling factor k (Sharpe ratio under vol constraint)\n",
    "best_k, best_sharpe = 0.1, -1e9\n",
    "for k in np.linspace(0.01, 5.0, 100):\n",
    "    exposures = np.clip((k * val_conf_adj), 0, 2)\n",
    "    stats = strategy_stats(val_p['forward_returns'], exposures)\n",
    "    if stats['vol'] <= VOL_MULTIPLIER_LIMIT * market_vol and stats['sharpe'] > best_sharpe:\n",
    "        best_k = k\n",
    "        best_sharpe = stats['sharpe']\n",
    "\n",
    "print(f\"Chosen scaling factor k={best_k:.3f} | Validation Sharpe={best_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65262718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_br.csv\n"
     ]
    }
   ],
   "source": [
    "## Test Predictions + Smoothing\n",
    "test_features_clean = test_p[final_features].fillna(0)\n",
    "test_pred = model.predict(test_features_clean)\n",
    "\n",
    "alpha = 0.8\n",
    "smoothed_allocation = []\n",
    "prev = 0.0\n",
    "for x in np.clip(best_k * test_pred, 0, 2):\n",
    "    s = alpha * x + (1 - alpha) * prev\n",
    "    smoothed_allocation.append(s)\n",
    "    prev = s\n",
    "smoothed_allocation = np.array(smoothed_allocation)\n",
    "\n",
    "# replace in final submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'date_id': test_p['date_id'],\n",
    "    'prediction': smoothed_allocation  \n",
    "})\n",
    "# submission_df.to_csv(\"submission_br.csv\", index=False)\n",
    "print(\"Saved submission_br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb838fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kaggle Evaluation Metric:\n",
    "\n",
    "strategy_returns = risk_free_rate * (1 - position) + position * forward_returns\n",
    "\n",
    "if position = 0 → invest in risk-free asset,\n",
    "\n",
    "if position = 1 → invest like the market,\n",
    "\n",
    "if position = 2 → you are leveraged ×2 on the market.\n",
    "\n",
    "\n",
    "def score():\n",
    "\n",
    "strategy_returns = rf * (1 - pos) + pos * fwd_returns\n",
    "\n",
    "In the code, the calibration seeks the best Sharpe of the portfolio exposed to pos by calculating:\n",
    "\n",
    "strat = exposures * returns\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6b6992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Kaggle Inference Server Wrapper (BayesianRidge version) ===\n",
    "\n",
    "# _model = model                     # BayesianRidge fitted model\n",
    "# _best_k = best_k                   # scaling factor from validation calibration\n",
    "# _history_returns = list(train_p['forward_returns'].iloc[-VOL_WINDOW:].tolist())\n",
    "\n",
    "# def predict(pl_df: pl.DataFrame) -> float:\n",
    "#     \"\"\"Predict allocation for one timestep (Kaggle competition API).\"\"\"\n",
    "#     global _history_returns\n",
    "#     # Convert Polars → Pandas\n",
    "#     pdf = pl_df.to_pandas()\n",
    "    \n",
    "#     # Apply same preprocessing\n",
    "#     pdf_p = prepare_df(pdf, median_map, feature_cols)\n",
    "#     for f in final_features:\n",
    "#         if f not in pdf_p.columns:\n",
    "#             pdf_p[f] = 0.0\n",
    "    \n",
    "#     # Convert to NumPy and predict\n",
    "#     x = pdf_p[final_features].to_numpy()\n",
    "\n",
    "#     \"\"\"\n",
    "#     added standard deviation based confidence adjustment\n",
    "#     to reduce allocation when uncertainty is high\n",
    "#     \"\"\"\n",
    "\n",
    "#     pred, std = model.predict(x, return_std=True)\n",
    "    \n",
    "#     # Compute rolling volatility estimate\n",
    "#     vol_est = np.std(_history_returns) or 1e-3\n",
    "#     confidence = 1 / (1 + std)\n",
    "#     alloc = float(np.clip(_best_k * pred * confidence / (vol_est + 1e-9), 0, 2))\n",
    "    \n",
    "#     # Update history (for volatility tracking)\n",
    "#     if 'lagged_forward_returns' in pl_df.columns:\n",
    "#         try:\n",
    "#             _history_returns.append(float(pl_df['lagged_forward_returns'][0]))\n",
    "#         except:\n",
    "#             _history_returns.append(0.0)\n",
    "#     else:\n",
    "#         _history_returns.append(0.0)\n",
    "    \n",
    "#     # Keep only the last VOL_WINDOW entries\n",
    "#     _history_returns = _history_returns[-VOL_WINDOW:]\n",
    "#     return alloc\n",
    "\n",
    "# # Instantiate the Kaggle inference server\n",
    "# server = kdeval.DefaultInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     server.serve()\n",
    "# else:\n",
    "#     server.run_local_gateway((str(DATA_DIR),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d9153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcbe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115cdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58021807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
