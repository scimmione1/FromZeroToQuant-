{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# üß† HULL TACTICAL MARKET PREDICTION ‚Äî ENSEMBLE + SHARPE PENALTY\n",
    "# ================================================================\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from typing import Tuple, Dict\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# import kaggle_evaluation.default_inference_server as kdeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d614beb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 1Ô∏è‚É£ Data Loading\n",
    "# ================================================================\n",
    "\n",
    "# DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "\n",
    "## Configuration and Data Loading (local version only)\n",
    "DATA_DIR = Path(\"01_data\")\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_DIR}/train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_DIR}/test.csv\")\n",
    "\n",
    "TARGET = \"market_forward_excess_returns\"\n",
    "drop_cols = [\"date_id\", \"forward_returns\", \"risk_free_rate\"]\n",
    "features = [c for c in train.columns if c not in drop_cols + [TARGET]]\n",
    "\n",
    "train = train.fillna(0.0)\n",
    "test = test.fillna(0.0)\n",
    "\n",
    "X = train[features]\n",
    "y = train[TARGET]\n",
    "X_test = test[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e08be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 2Ô∏è‚É£ CatBoost Base Model (GridSearch + TimeSeriesSplit)\n",
    "# ================================================================\n",
    "\n",
    "print(\"‚è≥ Training CatBoost model with TimeSeries CV...\")\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "cbc = CatBoostRegressor(loss_function='RMSE', verbose=0, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'depth': [4, 6],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'iterations': [300, 500],\n",
    "    'l2_leaf_reg': [2, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=cbc,\n",
    "    param_grid=param_grid,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(X, y)\n",
    "best_cbc = grid.best_estimator_\n",
    "print(f\"‚úÖ Best Params: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed795b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 3Ô∏è‚É£ Neural Network Model (Feedforward Regressor)\n",
    "# ================================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "def build_nn(input_dim):\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "nn_model = build_nn(X_scaled.shape[1])\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# last 20% time-based validation\n",
    "date_cut = train[\"date_id\"].quantile(0.8)\n",
    "train_idx = train[\"date_id\"] <= date_cut\n",
    "val_idx = train[\"date_id\"] > date_cut\n",
    "\n",
    "X_train, y_train = X_scaled[train_idx], y[train_idx]\n",
    "X_val, y_val = X_scaled[val_idx], y[val_idx]\n",
    "\n",
    "nn_model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "             epochs=100, batch_size=256, verbose=0, callbacks=[es])\n",
    "print(\"‚úÖ Neural Network trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 4Ô∏è‚É£ Ensemble Prediction (0.4 √ó CatBoost + 0.6 √ó NN)\n",
    "# ================================================================\n",
    "\n",
    "val_cat = best_cbc.predict(X.loc[val_idx])\n",
    "val_nn = nn_model.predict(X_scaled[val_idx]).ravel()\n",
    "\n",
    "val_ensemble = 0.4 * val_cat + 0.6 * val_nn\n",
    "val_df = train.loc[val_idx].copy()\n",
    "val_df[\"pred\"] = val_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b696f134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 5Ô∏è‚É£ Sharpe Penalty Formula (Official Metric Proxy)\n",
    "# ================================================================\n",
    "\n",
    "def sharpe_ratio(returns):\n",
    "    mean = np.mean(returns)\n",
    "    vol = np.std(returns)\n",
    "    return (mean / (vol + 1e-9)) * np.sqrt(252)\n",
    "\n",
    "def sharpe_penalty_score(pred, fwd_ret, risk_free_rate, penalty_weight=0.1):\n",
    "    \"\"\"\n",
    "    Penalize models with excessive volatility relative to returns.\n",
    "    \"\"\"\n",
    "    strat_ret = pred * fwd_ret - risk_free_rate\n",
    "    raw_sharpe = sharpe_ratio(strat_ret)\n",
    "    vol = np.std(strat_ret)\n",
    "    penalty = penalty_weight * vol\n",
    "    adj_sharpe = raw_sharpe - penalty\n",
    "    return adj_sharpe, raw_sharpe, penalty\n",
    "\n",
    "adj_sharpe, raw_sharpe, penalty = sharpe_penalty_score(\n",
    "    val_df[\"pred\"], val_df[\"forward_returns\"], val_df[\"risk_free_rate\"]\n",
    ")\n",
    "\n",
    "print(f\"üìä Validation Sharpe: {raw_sharpe:.3f} | Penalty: {penalty:.4f} | Adjusted: {adj_sharpe:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23c741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 6Ô∏è‚É£ Competition-Compliant Inference Function\n",
    "# ================================================================\n",
    "\n",
    "_cat_model = best_cbc\n",
    "_nn_model = nn_model\n",
    "_scaler = scaler\n",
    "_feat_cols = features\n",
    "\n",
    "def predict(pl_df):\n",
    "    \"\"\"Competition inference function.\"\"\"\n",
    "    pdf = pl_df.to_pandas().fillna(0.0)\n",
    "    for f in _feat_cols:\n",
    "        if f not in pdf.columns:\n",
    "            pdf[f] = 0.0\n",
    "    Xp = pdf[_feat_cols].values\n",
    "    Xp_scaled = _scaler.transform(Xp)\n",
    "    pred_cat = _cat_model.predict(pdf[_feat_cols])\n",
    "    pred_nn = _nn_model.predict(Xp_scaled, verbose=0).ravel()\n",
    "    preds = 0.4 * pred_cat + 0.6 * pred_nn\n",
    "    lo, hi = np.percentile(preds, [5, 95])\n",
    "    weights = np.clip((preds - lo) / (hi - lo + 1e-9) * 2.0, 0, 2)\n",
    "    return pd.DataFrame({\"prediction\": weights.astype(\"float32\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf25c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# 7Ô∏è‚É£ Kaggle Evaluation Server\n",
    "# ================================================================\n",
    "\n",
    "server = kdeval.DefaultInferenceServer(predict)\n",
    "\n",
    "if os.getenv(\"KAGGLE_IS_COMPETITION_RERUN\"):\n",
    "    server.serve()\n",
    "else:\n",
    "    server.run_local_gateway((DATA_DIR,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eedb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d70b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Imports\n",
    "# import os\n",
    "# from pathlib import Path\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from typing import Tuple, Dict\n",
    "\n",
    "# import polars as pl\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18d795b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8990, 98), (10, 99))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Configuration and Data Loading (kaggle_evaluation only)\n",
    "# import kaggle_evaluation.default_inference_server as kdeval\n",
    "# DATA_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n",
    "\n",
    "## Configuration and Data Loading (local version only)\n",
    "DATA_DIR = Path(\"01_data\")\n",
    "\n",
    "# Read CSV files from data_path\n",
    "TRAIN_PATH = DATA_DIR / 'train.csv'\n",
    "TEST_PATH  = DATA_DIR / 'test.csv'\n",
    "\n",
    "VALIDATION_SIZE = 2700          # days, approx. 30% of data\n",
    "# RANDOM_SEED = 42\n",
    "\n",
    "import random\n",
    "RANDOM_SEED = random.randint(1, 10000)\n",
    "\n",
    "VOL_MULTIPLIER_LIMIT = 1.2\n",
    "VOL_WINDOW = 20\n",
    "\n",
    "def time_split_train_val(df: pd.DataFrame, val_size: int = 2700):\n",
    "    df = df.sort_values('date_id').reset_index(drop=True)\n",
    "    train_df = df.iloc[:-val_size].copy()\n",
    "    val_df   = df.iloc[-val_size:].copy()\n",
    "    return train_df, val_df\n",
    "\n",
    "train_raw = pd.read_csv(TRAIN_PATH)\n",
    "test_raw  = pd.read_csv(TEST_PATH)\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "941f378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature Preparation\n",
    "excluded = {'date_id', 'forward_returns', 'risk_free_rate', 'market_forward_excess_returns'}\n",
    "feature_cols = [c for c in train_raw.columns if c not in excluded]\n",
    "feature_cols = [c for c in feature_cols if c in test_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fc3e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df: pd.DataFrame, median_map: Dict[str, float], feature_cols: list) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in feature_cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0.0\n",
    "            df[f'{c}_was_na'] = 1\n",
    "            continue\n",
    "        if df[c].dtype.kind in 'fiu':\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "        else:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "            med = median_map.get(c, 0.0)\n",
    "            was_na = df[c].isna().astype(int)\n",
    "            df[c] = df[c].fillna(med)\n",
    "            df[f'{c}_was_na'] = was_na\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cf47989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 188\n"
     ]
    }
   ],
   "source": [
    "## Train / Validation Split and Median Imputation\n",
    "train_df, val_df = time_split_train_val(train_raw, val_size=VALIDATION_SIZE)\n",
    "\n",
    "median_map = {c: float(train_df[c].median(skipna=True)) if train_df[c].dtype.kind in 'fiu' else 0.0 \n",
    "              for c in feature_cols}\n",
    "\n",
    "train_p = prepare_df(train_df, median_map, feature_cols)\n",
    "val_p   = prepare_df(val_df, median_map, feature_cols)\n",
    "test_p  = prepare_df(test_raw, median_map, feature_cols)\n",
    "\n",
    "final_features = [f for c in feature_cols for f in (c, f\"{c}_was_na\")]\n",
    "print(\"Number of features:\", len(final_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5935853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c9d2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in X_train: 6290\n",
      "NaN values in y_train: 0\n",
      "Validation RMSE: 0.010272\n"
     ]
    }
   ],
   "source": [
    "# === Bayesian Ridge Training ===\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepara i dati (usando gli stessi DataFrame)\n",
    "X_train = train_p[final_features]\n",
    "y_train = train_p['forward_returns']\n",
    "X_val   = val_p[final_features]\n",
    "y_val   = val_p['forward_returns']\n",
    "\n",
    "# Check for NaN values and handle them\n",
    "print(f\"NaN values in X_train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"NaN values in y_train: {y_train.isnull().sum()}\")\n",
    "\n",
    "# Fill any remaining NaN values\n",
    "X_train = X_train.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "y_val = y_val.fillna(0)\n",
    "\n",
    "# Crea e allena il modello\n",
    "model = BayesianRidge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione sul validation set\n",
    "val_pred = model.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "print(f\"Validation RMSE: {rmse_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e627045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market annualized volatility: 0.1698\n",
      "Chosen scaling factor k=5.000 | Validation Sharpe=0.69\n"
     ]
    }
   ],
   "source": [
    "# === Volatility Scaling Calibration (BayesianRidge version) ===\n",
    "def strategy_stats(returns, exposures):\n",
    "    \"\"\"Compute Sharpe and volatility for a given exposure series.\"\"\"\n",
    "    strat = exposures * returns\n",
    "    mean = np.nanmean(strat)\n",
    "    std  = np.nanstd(strat)\n",
    "    sharpe = (mean / (std + 1e-9)) * np.sqrt(252)\n",
    "    vol = std * np.sqrt(252)\n",
    "    return {'sharpe': sharpe, 'vol': vol}\n",
    "\n",
    "# Ensure validation data has no NaN values\n",
    "val_features_clean = val_p[final_features].fillna(0)\n",
    "\n",
    "# Predict mean and std (Bayesian posterior uncertainty)\n",
    "val_pred_mean, val_pred_std = model.predict(val_features_clean, return_std=True)\n",
    "\n",
    "# Define market volatility for scaling reference\n",
    "market_vol = np.nanstd(train_p['forward_returns']) * np.sqrt(252)\n",
    "print(f\"Market annualized volatility: {market_vol:.4f}\")\n",
    "\n",
    "# We'll use a dynamic confidence weight: confidence = 1 / (1 + std)\n",
    "confidence = 1 / (1 + val_pred_std)\n",
    "val_conf_adj = val_pred_mean * confidence  # lower exposure when uncertainty is high\n",
    "\n",
    "# Grid search for best scaling factor k (Sharpe ratio under vol constraint)\n",
    "best_k, best_sharpe = 0.1, -1e9\n",
    "for k in np.linspace(0.01, 5.0, 100):\n",
    "    exposures = np.clip((k * val_conf_adj), 0, 2)\n",
    "    stats = strategy_stats(val_p['forward_returns'], exposures)\n",
    "    if stats['vol'] <= VOL_MULTIPLIER_LIMIT * market_vol and stats['sharpe'] > best_sharpe:\n",
    "        best_k = k\n",
    "        best_sharpe = stats['sharpe']\n",
    "\n",
    "print(f\"Chosen scaling factor k={best_k:.3f} | Validation Sharpe={best_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65262718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved submission_br.csv\n"
     ]
    }
   ],
   "source": [
    "## Test Predictions + Smoothing\n",
    "test_features_clean = test_p[final_features].fillna(0)\n",
    "test_pred = model.predict(test_features_clean)\n",
    "\n",
    "alpha = 0.8\n",
    "smoothed_allocation = []\n",
    "prev = 0.0\n",
    "for x in np.clip(best_k * test_pred, 0, 2):\n",
    "    s = alpha * x + (1 - alpha) * prev\n",
    "    smoothed_allocation.append(s)\n",
    "    prev = s\n",
    "smoothed_allocation = np.array(smoothed_allocation)\n",
    "\n",
    "# replace in final submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'date_id': test_p['date_id'],\n",
    "    'prediction': smoothed_allocation  \n",
    "})\n",
    "# submission_df.to_csv(\"submission_br.csv\", index=False)\n",
    "print(\"Saved submission_br.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb838fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Kaggle Evaluation Metric:\n",
    "\n",
    "strategy_returns = risk_free_rate * (1 - position) + position * forward_returns\n",
    "\n",
    "if position = 0 ‚Üí invest in risk-free asset,\n",
    "\n",
    "if position = 1 ‚Üí invest like the market,\n",
    "\n",
    "if position = 2 ‚Üí you are leveraged √ó2 on the market.\n",
    "\n",
    "\n",
    "def score():\n",
    "\n",
    "strategy_returns = rf * (1 - pos) + pos * fwd_returns\n",
    "\n",
    "In the code, the calibration seeks the best Sharpe of the portfolio exposed to pos by calculating:\n",
    "\n",
    "strat = exposures * returns\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6b6992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Kaggle Inference Server Wrapper (BayesianRidge version) ===\n",
    "\n",
    "# _model = model                     # BayesianRidge fitted model\n",
    "# _best_k = best_k                   # scaling factor from validation calibration\n",
    "# _history_returns = list(train_p['forward_returns'].iloc[-VOL_WINDOW:].tolist())\n",
    "\n",
    "# def predict(pl_df: pl.DataFrame) -> float:\n",
    "#     \"\"\"Predict allocation for one timestep (Kaggle competition API).\"\"\"\n",
    "#     global _history_returns\n",
    "#     # Convert Polars ‚Üí Pandas\n",
    "#     pdf = pl_df.to_pandas()\n",
    "    \n",
    "#     # Apply same preprocessing\n",
    "#     pdf_p = prepare_df(pdf, median_map, feature_cols)\n",
    "#     for f in final_features:\n",
    "#         if f not in pdf_p.columns:\n",
    "#             pdf_p[f] = 0.0\n",
    "    \n",
    "#     # Convert to NumPy and predict\n",
    "#     x = pdf_p[final_features].to_numpy()\n",
    "\n",
    "#     \"\"\"\n",
    "#     added standard deviation based confidence adjustment\n",
    "#     to reduce allocation when uncertainty is high\n",
    "#     \"\"\"\n",
    "\n",
    "#     pred, std = model.predict(x, return_std=True)\n",
    "    \n",
    "#     # Compute rolling volatility estimate\n",
    "#     vol_est = np.std(_history_returns) or 1e-3\n",
    "#     confidence = 1 / (1 + std)\n",
    "#     alloc = float(np.clip(_best_k * pred * confidence / (vol_est + 1e-9), 0, 2))\n",
    "    \n",
    "#     # Update history (for volatility tracking)\n",
    "#     if 'lagged_forward_returns' in pl_df.columns:\n",
    "#         try:\n",
    "#             _history_returns.append(float(pl_df['lagged_forward_returns'][0]))\n",
    "#         except:\n",
    "#             _history_returns.append(0.0)\n",
    "#     else:\n",
    "#         _history_returns.append(0.0)\n",
    "    \n",
    "#     # Keep only the last VOL_WINDOW entries\n",
    "#     _history_returns = _history_returns[-VOL_WINDOW:]\n",
    "#     return alloc\n",
    "\n",
    "# # Instantiate the Kaggle inference server\n",
    "# server = kdeval.DefaultInferenceServer(predict)\n",
    "\n",
    "# if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "#     server.serve()\n",
    "# else:\n",
    "#     server.run_local_gateway((str(DATA_DIR),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d9153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbcbe9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b115cdd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58021807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138d4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
